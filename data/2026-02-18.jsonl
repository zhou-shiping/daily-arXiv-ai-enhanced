{"id": "2602.15059", "pdf": "https://arxiv.org/pdf/2602.15059", "abs": "https://arxiv.org/abs/2602.15059", "authors": ["Chandrasekhar Gokavarapu", "Naveen Kumar Kakumanu", "Anjali Datla", "Githa Harshitha Noolu"], "title": "Certified Reduced-Order Surrogates and Stability Margins in Viscous Incompressible Flow and Fluid--Structure Interaction", "categories": ["math.NA", "math.AP", "math.RA"], "comment": null, "summary": "Let $(u,p)$ solve the incompressible Navier--Stokes equations in a regime in which an energy inequality is available and each constant in that inequality is computable from declared data. We construct a reduced-order model $u_n$ constrained so that its discrete evolution satisfies a certified energy inequality. This certificate yields global-in-time boundedness of the ROM energy and a regime-of-validity test that fails when a stated hypothesis fails.\n  It follows that one can attach a computable residual functional $\\mathcal{R}_n$ to the ROM trajectory. We prove an a posteriori bound of the form \\[ \\norm{u-u_n}_{\\mathsf{X}(0,T)} \\le C(\\text{declared data})\\,\\mathcal{R}_n, \\] with $C$ explicit and with $\\mathcal{R}_n$ computed from the ROM and the discretization operators. Conversely, if the certificate constraint is relaxed, the bound can fail even for stable full-order dynamics, by an explicit instability mechanism recorded in the text.\n  We then derive transition indicators from rigorous energy and enstrophy budgets in simplified geometries. Each indicator is an inequality involving declared quantities such as forcing norms, viscosity, Poincaré-type constants, and a computable resolvent surrogate. These inequalities provide thresholds that preclude transition, or else certify the presence of transient growth beyond a stated level.\n  Finally, for a class of fluid--structure interaction models, we identify a parameter regime that implies existence and uniqueness of weak solutions. We derive discrete coupled energy estimates that produce computable stability margins. These margins yield explicit constraints on time step and mesh parameters. They are stated as inequalities with constants determined by fluid viscosity, structure stiffness, density ratios, and interface trace bounds."}
{"id": "2602.15068", "pdf": "https://arxiv.org/pdf/2602.15068", "abs": "https://arxiv.org/abs/2602.15068", "authors": ["Salvador K. Dzimah", "Sonia Rubio Herranz", "Fernando Carlos Lopez Hernandez", "Antonio López Montes"], "title": "A Unified Benchmark of Physics-Informed Neural Networks and Kolmogorov-Arnold Networks for Ordinary and Partial Differential Equations", "categories": ["math.NA"], "comment": "23 pages, 9 figures", "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful mesh-free framework for solving ordinary and partial differential equations by embedding the governing physical laws directly into the loss function. However, their classical formulation relies on multilayer perceptrons (MLPs), whose fixed activation functions and global approximation biases limit performance in problems with oscillatory behavior, multiscale dynamics, or sharp gradients. In parallel, Kolmogorov-Arnold Networks (KANs) have been introduced as a functionally adaptive architecture based on learnable univariate transformations along each edge, providing richer local approximations and improved expressivity. This work presents a systematic and controlled comparison between standard MLP-based PINNs and their KAN-based counterparts, Physics-Informed Kolmogorov-Arnold Networks (PIKANs), using identical physics-informed formulations and matched parameter budgets to isolate the architectural effect. Both models are evaluated across a representative collection of ODEs and PDEs, including cases with known analytical solutions that allow direct assessment of gradient reconstruction accuracy. The results show that PIKANs consistently achieve more accurate solutions, converge in fewer iterations, and yield superior gradient estimates, highlighting their advantage for physics-informed learning. These findings underline the potential of KAN-based architectures as a next-generation approach for scientific machine learning and provide rigorous evidence to guide model selection in differential equation solving."}
{"id": "2602.15147", "pdf": "https://arxiv.org/pdf/2602.15147", "abs": "https://arxiv.org/abs/2602.15147", "authors": ["Lucca Schek", "Peter Lewintan", "Wolfgang Müller", "Ingo Muench", "Andreas Zilian", "Stéphane P. A. Bordas", "Patrizio Neff", "Adam Sky"], "title": "A structure-preserving & objective discretisation of SO(3)-matrix rotation fields for finite Cosserat micropolar continua", "categories": ["math.NA", "math-ph"], "comment": null, "summary": "We introduce a new method, dubbed \\textbf{\\textit{Geometric Structure-Preserving Interpolation (Γ-SPIN)}}, to simultaneously preserve physics-constraints inherent in the material parameter limits of the finite-strain Cosserat micropolar model, and satisfy objectivity under superimposed rigid body motions. The method advocates to interpolate the Cosserat rotation tensor using geodesic elements, which maintain objectivity and correctly represent curvature measures. At the same time, it proposes relaxing the interaction between the rotation tensor and the deformation tensor to alleviate locking effects. This relaxation is achieved in two steps. First, the regularity of the Cosserat rotation tensor is reduced by interpolating it into the Nédélec space. Second, the resulting field is projected back onto the Lie-group of rotations. Together, these steps define a lower-regularity projection-based interpolation. This construction allows the discrete Cosserat rotation tensor to match the polar part of the discrete deformation tensor while remaining objective. This ensures stable behaviour in the asymptotic regime as the Cosserat couple modulus tends to infinity, which constrains the model towards its couple-stress limit. We establish the consistency, stability, and optimality of the proposed method through several benchmark problems. The study culminates in a demonstration of its efficacy on a more intricate curved domain, contrasted with outcomes obtained from conventional interpolation techniques."}
{"id": "2602.15193", "pdf": "https://arxiv.org/pdf/2602.15193", "abs": "https://arxiv.org/abs/2602.15193", "authors": ["Simon Lemaire"], "title": "Equivalence of mixed and nonconforming methods on general polytopal partitions. Part I: Multiscale and projection methods", "categories": ["math.NA"], "comment": "21 pages", "summary": "We study equivalence, in the context of a variable diffusion problem, between (conforming) mixed methods and (primal) nonconforming methods defined on potentially general polytopal partitions. In this first paper of a series of two, we focus on multiscale and projection methods. For multiscale methods, we establish the first-level equivalence between four different (oversampling-free) approaches, thereby broadening the results of [Chaumont-Frelet, Ern, Lemaire, Valentin; M2AN, 2022]. For projection methods, in turn, we provide a simple criterion (to be checked in practice) for primal/mixed well-posedness and equivalence to hold true. In the process, we also shed a new light on some self-stabilized hybrid methods. Part II of this work will address (general) polytopal element methods."}
{"id": "2602.15041", "pdf": "https://arxiv.org/pdf/2602.15041", "abs": "https://arxiv.org/abs/2602.15041", "authors": ["Victor Windhab", "Andreas Adelmann", "Mohsen Sadr"], "title": "VR-PIC: An entropic variance-reduction method for particle-in-cell solutions of the Vlasov-Poisson equation", "categories": ["physics.comp-ph", "physics.plasm-ph", "stat.CO"], "comment": "Preprint", "summary": "We extend the recently developed entropic and conservative variance reduction framework [M. Sadr, N. G. Hadjiconstantinou, A variance-reduced direct Monte Carlo simulation method for solving the Boltzmann equation over a wide range of rarefaction, Journal of Computational Physics 472 (2023) 111677.] to the particle-in-cell (PIC) method of solving Vlasov-Poisson equation. We show that a zeroth-order approximation that freezes the importance weights during the velocity-space kick is stable at the expense of introducing bias. Then, we propose a correction for the weight distribution using maximum cross-entropy formulation to ensure conservation laws while minimizing the introduced bias. In several test cases including Sod's shock tube and Landau damping we show that the proposed method maintains the substantial speed-up of variance reduction method compared to the PIC simulations in the low signal regime with minimal changes to the simulation code."}
{"id": "2602.15152", "pdf": "https://arxiv.org/pdf/2602.15152", "abs": "https://arxiv.org/abs/2602.15152", "authors": ["Hyungjun Choi", "Matei P. Coiculescu"], "title": "A Two-Sink Solution to the Self-Similar Euler Equations", "categories": ["math.AP", "physics.flu-dyn"], "comment": "20 pages, 4 figures, 1 table", "summary": "We construct the first known example of a self-similar solution to the two-dimensional incompressible Euler equations whose pseudo-velocity has more than one stagnation point. The solution is also a homogeneous steady state of the Euler equations. In contrast, any homogeneous steady state with bounded vorticity necessarily admits only a single stagnation point at the origin. Our construction develops cusps in the velocity along two lines passing through the origin, thereby allowing stagnation points other than the origin."}
{"id": "2602.15084", "pdf": "https://arxiv.org/pdf/2602.15084", "abs": "https://arxiv.org/abs/2602.15084", "authors": ["Tobia Boschi", "Andrea Loreti", "Nicola C. Amorisco", "Rodrigo H. Ordonez-Hurtado", "Cécile Rousseau", "George K. Holt", "Eszter Székely", "Alexander Whittle", "Samuel Jackson", "Adriano Agnello", "Stanislas Pamela", "Alessandra Pascale", "Robert Akers", "Juan Bernabe Moreno", "Vassil Alexandrov", "Mykhaylo Zayats"], "title": "TokaMind: A Multi-Modal Transformer Foundation Model for Tokamak Plasma Dynamics", "categories": ["physics.plasm-ph", "cs.AI", "cs.LG"], "comment": null, "summary": "We present TokaMind, an open-source foundation model framework for fusion plasma modeling, based on a Multi-Modal Transformer (MMT) and trained on heterogeneous tokamak diagnostics from the publicly available MAST dataset. TokaMind supports multiple data modalities (time-series, 2D profiles, and videos) with different sampling rates, robust missing-signal handling, and efficient task adaptation via selectively loading and freezing four model components. To represent multi-modal signals, we use a training-free Discrete Cosine Transform embedding (DCT3D) and provide a clean interface for alternative embeddings (e.g., Variational Autoencoders - VAEs). We evaluate TokaMind on the recently introduced MAST benchmark TokaMark, comparing training and embedding strategies. Our results show that fine-tuned TokaMind outperforms the benchmark baseline on all but one task, and that, for several tasks, lightweight fine-tuning yields better performance than training the same architecture from scratch under a matched epoch budget. These findings highlight the benefits of multi-modal pretraining for tokamak plasma dynamics and provide a practical, extensible foundation for future fusion modeling tasks. Training code and model weights will be made publicly available."}
{"id": "2602.15271", "pdf": "https://arxiv.org/pdf/2602.15271", "abs": "https://arxiv.org/abs/2602.15271", "authors": ["Kamila Nurkhametova", "Reid J. Gomillion", "Amit N. Subrahmanya", "Adrian Sandu"], "title": "A Patankar predictor-corrector approach for positivity-preserving time integration", "categories": ["math.NA"], "comment": null, "summary": "Many natural processes, such as chemical reactions and wave dynamics, are modeled as production-destruction (PD) systems that obey positivity and linear conservation laws. Classical time integrators do not guarantee positivity and can produce negative or nonphysical numerical solutions. This paper presents a modular correction strategy that can be applied to implicit Runge-Kutta schemes, in particular SDIRK methods. The strategy combines stage-wise clipping with a ratio-based scaling that enforces invariants and is guaranteed to yield nonnegative, conservative solutions. We provide a theoretical analysis of the corrected schemes and characterize their worst-case order of accuracy relative to the underlying base method. Numerical experiments on stiff ODE systems (Robertson, MAPK, stratospheric chemistry) and a nonlinear PDE (the Korteweg-De Vries equation) demonstrate that the corrected SDIRK methods preserve positivity and invariants without significant loss of accuracy. Importantly, corrections applied only to the final stage are sufficient in practice, while applying them at all stages may distort dynamics in some cases. For explicit Runge-Kutta schemes, the correction maintained positivity but reduced convergence to first order. These results show that the proposed framework provides a simple and effective way to construct positivity-preserving integrators for stiff PD systems."}
{"id": "2602.15130", "pdf": "https://arxiv.org/pdf/2602.15130", "abs": "https://arxiv.org/abs/2602.15130", "authors": ["Brian A. Freno", "William J. McDoniel", "Christopher H. Moore", "Neil R. Matula"], "title": "Code-Verification Techniques for Particle-in-Cell Simulations with Direct Simulation Monte Carlo Collisions", "categories": ["physics.comp-ph", "math.NA", "physics.plasm-ph"], "comment": null, "summary": "Particle-in-cell methods with stochastic collision models are commonly used to simulate collisional plasma dynamics, with applications ranging from hypersonic flight to semiconductor manufacturing. Code verification of such methods is challenging due to the interaction between the spatial- and temporal-discretization errors, the statistical sampling noise, and the stochastic nature of the collision algorithm. In this paper, we introduce our code-verification approaches to apply the method of manufactured solutions to plasma dynamics, and we derive expected convergence rates for the different sources of discretization and statistical error. For the particles, we incorporate the method of manufactured solutions into the equations of motion. We manufacture the particle distribution function and inversely query the cumulative distribution function to obtain known particle positions and velocities at each time step. In doing so, we avoid modifying the particle weights, eliminating risks from potentially negative weights or modifications to weight-dependent collision algorithms. For the collision algorithm, we average independent outcomes at each time step and we derive a corresponding manufactured source term for the velocity change for each particle. By having known solutions for the particle positions and velocities, we are able to compute the error in these quantities directly instead of attempting to compute differences in distribution functions. These approaches are equally valid for particle-in-cell simulations with Monte Carlo collisions and direct simulation Monte Carlo simulations of neutral gas flows. We demonstrate the effectiveness of our approaches in three dimensions for different couplings between the particles and field, with and without binary elastic collisions, and with and without coding errors."}
{"id": "2602.15203", "pdf": "https://arxiv.org/pdf/2602.15203", "abs": "https://arxiv.org/abs/2602.15203", "authors": ["Alexandre Kirilov", "Wagner Augusto Almeida de Moraes", "Pedro Meyer Tokoro"], "title": "Solvability of a class of evolution operators on compact Lie groups", "categories": ["math.AP"], "comment": "17 pages", "summary": "This paper provides sufficient conditions for the solvability of a class of first-order evolution operators of Vekua-type on the product of a one-dimensional torus and a compact Lie group. The conditions are expressed in terms of the time-dependent coefficients and the spectral behavior of a normalized left-invariant vector field on the group. The three-sphere case is discussed in detail, leading to more explicit criteria, and the main results are further extended to operators defined on finite products of compact Lie groups."}
{"id": "2602.15431", "pdf": "https://arxiv.org/pdf/2602.15431", "abs": "https://arxiv.org/abs/2602.15431", "authors": ["H. Zhang", "M. Hoelzl", "I. Krebs", "A. Burckhart", "A. Bock", "S. Guenter", "V. Igochine", "K. Lackner", "D. Bonfiglio", "E. Fable", "F. Stefanelli", "R. Ramasamy", "H. Zohm", "JOREK TEAM", "ASDEX UPGRADE TEAM"], "title": "Flux pumping and bifurcated relaxations of helical core in 3D magnetohydrodynamic modelling of ASDEX Upgrade plasmas", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Flux pumping was achieved in recent hybrid scenario experiments in the ASDEX Upgrade (AUG) tokamak, which is characterized by a sawtooth-free helical quiescent state and the anomalous radial redistribution of toroidal current density and poloidal magnetic flux. In this article, the self-regulation mechanism of the AUG core plasma during flux pumping is investigated at realistic parameters using the JOREK code based on the two-temperature, nonlinear, full magnetohydrodynamic (MHD) model. A key milestone in AUG flux pumping modelling is achieved by quantitatively reproducing the clamped current density and safety factor profiles in the plasma core, demonstrating the effectiveness of the dynamo effect in sustaining the flux pumping state. The dynamo term, that is of particular interest, is primarily generated by the pressure-gradient driven m/n = 1/1 quasi-interchange-like MHD instability. The work systematically extrapolates the parameter regimes of flux pumping from the above AUG base case by scanning dissipation coefficients and plasma beta. The simulation results reveal bifurcated plasma behaviours at different Hartmann numbers, including distinct states such as flux pumping (helical core with a flat current density), sawteeth (periodic kink-cycling), single crash (without subsequent cycle), and quasi-stationary magnetic island (peaked current density). Transitions from marginal flux pumping state to sawteeth are observed in long-term simulations. The relationships between system dissipation, plasma beta, and different plasma states are carefully analyzed. For practical purposes, the potential operational window for flux pumping, as determined by plasma density and temperature, is estimated. The modelling efforts advance the understanding of flux pumping and facilitate the development of a fast surrogate model for efficient evaluation of flux pumping."}
{"id": "2602.15399", "pdf": "https://arxiv.org/pdf/2602.15399", "abs": "https://arxiv.org/abs/2602.15399", "authors": ["A. Hannukainen", "N. Hyvönen", "V. Toresen"], "title": "Total variation regularization with reduced basis in electrical impedance tomography", "categories": ["math.NA"], "comment": "24 pages, 6 figures", "summary": "This work considers using reduced basis techniques in connection to (smoothened) total variation regularization in electrical impedance tomography, but analogous ideas can also be used for other inverse elliptic boundary value problems. It is demonstrated that resorting to reduced bases can speed up a reconstruction algorithm based on combining the lagged diffusivity algorithm with sequential linearizations and preconditioned LSQR iteration without any significant loss of reconstruction quality or of the edge-enhancing nature of total variation regularization. The ideas are numerically tested in three dimensions on unstructured finite element meshes with both simulated and experimental data, resulting in online reconstruction times of only a few seconds on a standard laptop computer."}
{"id": "2602.15244", "pdf": "https://arxiv.org/pdf/2602.15244", "abs": "https://arxiv.org/abs/2602.15244", "authors": ["Maximiliano Dalinger", "Elia Merzari", "Saya Lee", "Alex Nellis"], "title": "Analysis of Fission Matrix Databases using Temperature Profiles obtained from High-Fidelity Multiphysics Simulations", "categories": ["physics.comp-ph"], "comment": "ANS Student Conference 2026", "summary": "The Fission Matrix method is used to perform fast and still accurate neutronics simulations. It relies on precalculated databases obtained through a Monte Carlo simulation. To represent every state of the reactor, multiple databases are required. The actual state of the reactor is obtained from those databases. In this paper, we analyze the effect of the temperature profiles selected to construct the databases. To do so, the Molten Salt Fast reactor is selected. Two sets of databases are studied: the first uses temperature profiles obtained from high-fidelity Multiphysics simulations with Cardinal, and the second uses uniform temperature profiles. Results showed improved multiplication factor and fission source distribution when the temperature profiles used to generate the databases were similar to those expected when solving the fission matrix."}
{"id": "2602.15394", "pdf": "https://arxiv.org/pdf/2602.15394", "abs": "https://arxiv.org/abs/2602.15394", "authors": ["Yazhou Chen", "Qiaolin He", "Dongjuan Niu", "Yi Peng", "Xiaoding Shi"], "title": "A Regularized Framework and Admissible Solutions for Liquid-Vapor Phase Transitions in Steady Compressible Flows", "categories": ["math.AP"], "comment": "28 pages, 3 figures", "summary": "We investigate the well-posedness of the periodic boundary value problem for the steady compressible isentropic Navier-Stokes system under the van der Waals equation of state. The main difficulty arises from the non-monotonicity of the pressure, which induces liquid-vapor phase transitions and consequently leads to both physical instabilities and mathematical non-uniqueness of solutions. It is shown that the occurrence of a phase transition is determined by whether the integral average of the specific volume lies inside the gas-liquid coexistence region defined by the Maxwell construction. By introducing an artificial viscosity, we construct an approximate system. When the integral average of the specific volume falls within the Maxwell region, the approximate solution converges, as the artificial viscosity tends to zero, to the equilibrium states given by Maxwell's construction, with the diffuse interface sharpening into a discontinuity. Conversely, if the integral average of the specific volume lies outside this region, the limiting solution remains outside as well, meaning that no phase transition occurs. These results demonstrate that the non-monotonicity of the pressure, combined with the condition that the integral average of the specific volume belongs to the Maxwell region, can act as a nucleation mechanism for phase transitions in the isentropic gas-liquid problem. Furthermore, the proposed approximation not only offers a regularized framework for describing phase transitions but also provides, from a rigorous mathematical viewpoint, a definition of admissible solutions related to phase transitions. The detailed proof relies on the artificial viscosity method, the calculus of variations, the anti-derivative technique, phase-plane analysis, and the level-set method."}
{"id": "2602.15500", "pdf": "https://arxiv.org/pdf/2602.15500", "abs": "https://arxiv.org/abs/2602.15500", "authors": ["Sanjeev Kumar", "Alessandro Munafo", "Blaine Vollmer", "Daniel J. Bodony", "Gregory S. Elliott", "Kelly A. Stephani", "Sean Kearney", "Marco Panesi"], "title": "From Coils to Surface Recession: Fully Coupled Simulation of Ablation in ICP Wind Tunnels", "categories": ["physics.plasm-ph"], "comment": "32 pages, 19 figures", "summary": "This work presents a fully coupled, multiphysics computational framework for predicting the thermo-chemical material response of thermal protection systems in inductively coupled plasma (ICP) wind tunnels. The framework integrates a high-fidelity Navier-Stokes plasma solver, an electromagnetic field solver, and a discontinuous-Galerkin material response solver using a partitioned coupling strategy. This enables an ab initio, end-to-end simulation of the 350 kW Plasmatron X facility at the University of Illinois Urbana-Champaign (UIUC), including plasma generation, electromagnetic heating, near-wall thermochemistry, and time-accurate material ablation. The model captures key ICP physics such as vortex-mode recirculation, Joule-heating-driven plasma formation, and Lorentz-force-induced flow confinement, and accurately predicts the transition from subsonic to supersonic jet behavior at low pressures. Validation against cold-wall calorimetry and graphite ablation experiments shows that predicted stagnation-point heat fluxes fall well within experimental uncertainty, while fully coupled simulations accurately reproduce measured stagnation temperature histories and recession rates with errors below 12% and 10%, respectively. Remaining discrepancies during early transient heating are attributed to uncertainties in power-coupling efficiency, equilibrium ablation modeling, and material property datasets. Overall, the framework demonstrates strong predictive capability for ICP wind tunnel environments and provides a foundation for improved design, interpretation, and planning of hypersonic material testing campaigns."}
{"id": "2602.15445", "pdf": "https://arxiv.org/pdf/2602.15445", "abs": "https://arxiv.org/abs/2602.15445", "authors": ["Attila Karsai", "Philipp Schulze"], "title": "A discrete gradient scheme for preserving QSR-dissipativity", "categories": ["math.NA", "math.DS", "math.OC"], "comment": null, "summary": "The notion of dissipative dynamical systems provides a formal description of processes that cannot generate energy internally. For these systems, changes in energy can only occur due to an external energy supply or dissipation effects. Unfortunately, dissipative properties tend to deteriorate in numerical computations, especially in nonlinear systems. Discrete gradient methods can help mitigate this problem. In this paper, we present a class of structure-preserving time discretization schemes based on discrete gradients for a special class of systems that are dissipative with respect to a quadratic supply rate."}
{"id": "2602.15632", "pdf": "https://arxiv.org/pdf/2602.15632", "abs": "https://arxiv.org/abs/2602.15632", "authors": ["Changhong Mou", "Binghang Lu", "Guang Lin"], "title": "Neural-POD: A Plug-and-Play Neural Operator Framework for Infinite-Dimensional Functional Nonlinear Proper Orthogonal Decomposition", "categories": ["physics.comp-ph", "cs.LG", "math.NA"], "comment": null, "summary": "The rapid development of AI for Science is often hindered by the \"discretization\", where learned representations remain restricted to the specific grids or resolutions used during training. We propose the Neural Proper Orthogonal Decomposition (Neural-POD), a plug-and-play neural operator framework that constructs nonlinear, orthogonal basis functions in infinite-dimensional space using neural networks. Unlike the classical Proper Orthogonal Decomposition (POD), which is limited to linear subspace approximations obtained through singular value decomposition (SVD), Neural-POD formulates basis construction as a sequence of residual minimization problems solved through neural network training. Each basis function is obtained by learning to represent the remaining structure in the data, following a process analogous to Gram--Schmidt orthogonalization. This neural formulation introduces several key advantages over classical POD: it enables optimization in arbitrary norms (e.g., $L^2$, $L^1$), learns mappings between infinite-dimensional function spaces that is resolution-invariant, generalizes effectively to unseen parameter regimes, and inherently captures nonlinear structures in complex spatiotemporal systems. The resulting basis functions are interpretable, reusable, and enabling integration into both reduced order modeling (ROM) and operator learning frameworks such as deep operator learning (DeepONet). We demonstrate the robustness of Neural-POD with different complex spatiotemporal systems, including the Burgers' and Navier-Stokes equations. We further show that Neural-POD serves as a high performance, plug-and-play bridge between classical Galerkin projection and operator learning that enables consistent integration with both projection-based reduced order models and DeepONet frameworks."}
{"id": "2602.15471", "pdf": "https://arxiv.org/pdf/2602.15471", "abs": "https://arxiv.org/abs/2602.15471", "authors": ["Rafael López-Soriano", "Francisco J. Reyes-Sánchez", "David Ruiz"], "title": "Conformal Metrics on the Disk with Prescribed Negative Gaussian Curvature and Boundary Geodesic Curvature", "categories": ["math.AP", "math.DG"], "comment": "25 pages and 1 figure", "summary": "We study the problem of prescribing the Gaussian curvature on the disk and the geodesic curvature on its boundary via a conformal change of the metric. In this paper the case of negative Gaussian curvature is treated, a regime for which the bubbling behavior of approximate solutions is not so well understood. This is due to the possible appearance of blow-up solutions with diverging length and area. We give an existence result under assumptions on the curvatures which are somewhat natural, in view of some obstructions inherent to the problem. Our strategy is variational and relies on the study of certain families of approximated problems. By performing a refined blow-up analysis for solutions with bounded Morse index, we conclude compactness."}
{"id": "2602.15041", "pdf": "https://arxiv.org/pdf/2602.15041", "abs": "https://arxiv.org/abs/2602.15041", "authors": ["Victor Windhab", "Andreas Adelmann", "Mohsen Sadr"], "title": "VR-PIC: An entropic variance-reduction method for particle-in-cell solutions of the Vlasov-Poisson equation", "categories": ["physics.comp-ph", "physics.plasm-ph", "stat.CO"], "comment": "Preprint", "summary": "We extend the recently developed entropic and conservative variance reduction framework [M. Sadr, N. G. Hadjiconstantinou, A variance-reduced direct Monte Carlo simulation method for solving the Boltzmann equation over a wide range of rarefaction, Journal of Computational Physics 472 (2023) 111677.] to the particle-in-cell (PIC) method of solving Vlasov-Poisson equation. We show that a zeroth-order approximation that freezes the importance weights during the velocity-space kick is stable at the expense of introducing bias. Then, we propose a correction for the weight distribution using maximum cross-entropy formulation to ensure conservation laws while minimizing the introduced bias. In several test cases including Sod's shock tube and Landau damping we show that the proposed method maintains the substantial speed-up of variance reduction method compared to the PIC simulations in the low signal regime with minimal changes to the simulation code."}
{"id": "2602.15517", "pdf": "https://arxiv.org/pdf/2602.15517", "abs": "https://arxiv.org/abs/2602.15517", "authors": ["Fernando Henriquez", "Matthias Schlottbom"], "title": "A Model Order Reduction Method for Seismic Applications Using the Laplace Transform", "categories": ["math.NA"], "comment": null, "summary": "We devise and analyze a reduced basis model order reduction (MOR) strategy for an abstract wave problem with vanishing initial conditions and a source term given by the product of a temporal Ricker wavelet and a spatial profile. Such wave problems comprise the acoustic and elastic wave equations, with applications in seismic modeling. Motivated by recent Laplace-domain MOR methodologies, we construct reduced bases that approximate the time-domain solution with exponential accuracy. We prove convergence bounds that are explicit and robust with respect to the parameters controlling the Ricker wavelet's shape and width and identify an intrinsic accuracy limit dictated by the wavelet's value at the initial time. In particular, the resulting error bound is independent of the underlying Galerkin discretization space and yields computable criteria for the regime in which exponential convergence is observed."}
{"id": "2602.15268", "pdf": "https://arxiv.org/pdf/2602.15268", "abs": "https://arxiv.org/abs/2602.15268", "authors": ["Jonas Hänseroth", "Max Großmann", "Malte Grunert", "Erich Runge", "Christian Dreßler"], "title": "High-throughput screening and mechanistic insights into solid acid proton conductors", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Proton-conducting solid acids could enable water-free operation of high-temperature fuel cells. However, systematic materials screening has, hitherto, been computationally prohibitive. Here, we introduce a two-stage high-throughput screening strategy that directly computes proton diffusion coefficients, enabled by machine-learned interatomic potentials fine-tuned to ab initio data. Starting from more than six million materials, our screening -- based on structural motifs rather than empirical descriptors -- identifies $27$ high-performing proton conductors, including over ten previously unexplored compounds. These include sustainable and commercially available materials, candidates that have not yet been synthesized, organic systems that fall outside conventional design rules, and known proton conductors that validate our approach. Importantly, our findings reveal a universal oxygen--oxygen distance of approximately $2.5$~Å at the moment of proton transfer across diverse chemistries, providing mechanistic insight and showing that macroscopic proton conductivity emerges from the interplay between anion rotational dynamics, hydrogen-bond network connectivity, and proton-transfer probability."}
{"id": "2602.15479", "pdf": "https://arxiv.org/pdf/2602.15479", "abs": "https://arxiv.org/abs/2602.15479", "authors": ["Daniel Alayón-Solarz"], "title": "A Degenerate Elliptic System Solvable by Transport: A Cautionary Example", "categories": ["math.AP", "math.CV", "math.NA"], "comment": "7 pages, 1 table. Comments are welcome", "summary": "We exhibit a one-parameter family of first-order real elliptic systems on the plane whose ellipticity constant degenerates to zero as $δ\\to 0$, with condition number $κ= O(δ^{-2})$. For any fixed elliptic solver operating at finite precision, the parameter $δ$ can be chosen small enough to defeat the solver; no uniform numerical scheme based on the ellipticity constant alone can handle the entire family. Despite this, every member of the family is explicitly solvable -- and its initial value problem well posed -- by elementary means once a transport-theoretic invariant is identified. The cost of the transport solution is independent of $δ$. The example serves as a cautionary tale: the ellipticity constant alone does not determine the practical difficulty of a first-order PDE. Before invoking an elliptic solver, one should compute the transport obstruction $G$; its vanishing -- or smallness -- signals structure that standard elliptic methods miss entirely."}
{"id": "2602.15130", "pdf": "https://arxiv.org/pdf/2602.15130", "abs": "https://arxiv.org/abs/2602.15130", "authors": ["Brian A. Freno", "William J. McDoniel", "Christopher H. Moore", "Neil R. Matula"], "title": "Code-Verification Techniques for Particle-in-Cell Simulations with Direct Simulation Monte Carlo Collisions", "categories": ["physics.comp-ph", "math.NA", "physics.plasm-ph"], "comment": null, "summary": "Particle-in-cell methods with stochastic collision models are commonly used to simulate collisional plasma dynamics, with applications ranging from hypersonic flight to semiconductor manufacturing. Code verification of such methods is challenging due to the interaction between the spatial- and temporal-discretization errors, the statistical sampling noise, and the stochastic nature of the collision algorithm. In this paper, we introduce our code-verification approaches to apply the method of manufactured solutions to plasma dynamics, and we derive expected convergence rates for the different sources of discretization and statistical error. For the particles, we incorporate the method of manufactured solutions into the equations of motion. We manufacture the particle distribution function and inversely query the cumulative distribution function to obtain known particle positions and velocities at each time step. In doing so, we avoid modifying the particle weights, eliminating risks from potentially negative weights or modifications to weight-dependent collision algorithms. For the collision algorithm, we average independent outcomes at each time step and we derive a corresponding manufactured source term for the velocity change for each particle. By having known solutions for the particle positions and velocities, we are able to compute the error in these quantities directly instead of attempting to compute differences in distribution functions. These approaches are equally valid for particle-in-cell simulations with Monte Carlo collisions and direct simulation Monte Carlo simulations of neutral gas flows. We demonstrate the effectiveness of our approaches in three dimensions for different couplings between the particles and field, with and without binary elastic collisions, and with and without coding errors."}
{"id": "2602.15130", "pdf": "https://arxiv.org/pdf/2602.15130", "abs": "https://arxiv.org/abs/2602.15130", "authors": ["Brian A. Freno", "William J. McDoniel", "Christopher H. Moore", "Neil R. Matula"], "title": "Code-Verification Techniques for Particle-in-Cell Simulations with Direct Simulation Monte Carlo Collisions", "categories": ["physics.comp-ph", "math.NA", "physics.plasm-ph"], "comment": null, "summary": "Particle-in-cell methods with stochastic collision models are commonly used to simulate collisional plasma dynamics, with applications ranging from hypersonic flight to semiconductor manufacturing. Code verification of such methods is challenging due to the interaction between the spatial- and temporal-discretization errors, the statistical sampling noise, and the stochastic nature of the collision algorithm. In this paper, we introduce our code-verification approaches to apply the method of manufactured solutions to plasma dynamics, and we derive expected convergence rates for the different sources of discretization and statistical error. For the particles, we incorporate the method of manufactured solutions into the equations of motion. We manufacture the particle distribution function and inversely query the cumulative distribution function to obtain known particle positions and velocities at each time step. In doing so, we avoid modifying the particle weights, eliminating risks from potentially negative weights or modifications to weight-dependent collision algorithms. For the collision algorithm, we average independent outcomes at each time step and we derive a corresponding manufactured source term for the velocity change for each particle. By having known solutions for the particle positions and velocities, we are able to compute the error in these quantities directly instead of attempting to compute differences in distribution functions. These approaches are equally valid for particle-in-cell simulations with Monte Carlo collisions and direct simulation Monte Carlo simulations of neutral gas flows. We demonstrate the effectiveness of our approaches in three dimensions for different couplings between the particles and field, with and without binary elastic collisions, and with and without coding errors."}
{"id": "2602.15345", "pdf": "https://arxiv.org/pdf/2602.15345", "abs": "https://arxiv.org/abs/2602.15345", "authors": ["Jigyasa Nigam", "Tess Smidt", "Geneviève Dusson"], "title": "Machine learning electronic structure and atomistic properties from the external potential", "categories": ["physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Electronic structure calculations remain a major bottleneck in atomistic simulations and, not surprisingly, have attracted significant attention in machine learning (ML). Most existing approaches learn a direct map from molecular geometries, typically represented as graphs or encoded local environments, to molecular properties or use ML as a surrogate for electronic structure theory by targeting quantities such as Fock or density matrices expressed in an atomic orbital (AO) basis.\n  Inspired by the Hohenberg-Kohn theorem, in this work, we propose an operator-centered framework in which the external (nuclear) potential, expressed in an AO basis, serves as the model input. From this operator, we construct hierarchical, body-ordered representations of atomic configurations that closely mirror the principles underlying several popular atom-centered descriptors. At the same time, the matrix-valued nature of the external potential provides a natural connection to equivariant message-passing neural networks. In particular, we show that successive products of the external potential provide a scalable route to equivariant message passing and enable an efficient description of long-range effects. We demonstrate that this approach can be used to model molecular properties, such as energies and dipole moments, from the external potential, or learn effective operator-to-operator maps, including mappings to the Fock matrix and the reduced density matrix from which multiple molecular observables can be simultaneously derived."}
{"id": "2602.15601", "pdf": "https://arxiv.org/pdf/2602.15601", "abs": "https://arxiv.org/abs/2602.15601", "authors": ["Dingqun Deng", "Shota Sakamoto"], "title": "Uniqueness and Zeroth-Order Analysis of Weak Solutions to the Non-cutoff Boltzmann equation", "categories": ["math.AP"], "comment": "84 pages. All comments are welcome", "summary": "We establish the uniqueness of large solutions to the non-cutoff Boltzmann equation with moderate soft potentials. Specifically, the weak solution $F=μ+μ^{\\frac{1}{2}}f$ is unique as long as it has finite energy, in the sense that the norm $\\|f\\|_{L^\\infty_t L^{r}_{x,v}}+\\|f\\|_{L^\\infty_t L^2_{x,v}}$ remains bounded (arbitrary large) for some sufficiently large $r>0$. Our approach applies dilated dyadic decompositions in phase space $(v,ξ,η)$ to capture hypoellipticity and to reduce the fractional derivative structure $(-Δ_v)^{s}$ of the Boltzmann collision operator to zeroth order. The difficulties posed by the large solution are overcome through the negative-order hypoelliptic estimate that gains integrability in $(t,x)$."}
{"id": "2602.15149", "pdf": "https://arxiv.org/pdf/2602.15149", "abs": "https://arxiv.org/abs/2602.15149", "authors": ["Mohammad Naqib Rahimi", "George Moutsanidis"], "title": "SoliDualSPHysics: An extension of DualSPHysics for solid mechanics with hyperelasticity, plasticity, and fracture", "categories": ["cs.CE", "math.NA"], "comment": null, "summary": "We introduce SoliDualSPHysics, a novel open-source and GPU-accelerated software that extends DualSPHysics to enable the numerical simulation of hyperelastic, finite-strain plastic, and brittle fracture behavior in deformable solids within a unified smoothed particle hydrodynamics (SPH) formulation. The software implements a total Lagrangian formulation for solid mechanics that allows direct application of external loads and boundary conditions, enabling independent solid mechanics simulations. Brittle fracture is modeled through a phase-field approach coupled with SPH, allowing crack initiation, propagation, and branching under dynamic loading without the need for additional criteria or local refinement. The framework also supports user-defined mathematical expressions to prescribe time- and space-dependent quantities, complementing the solid and fracture extensions and enhancing flexibility across existing and future DualSPHysics applications. Leveraging DualSPHysics' native CPU/GPU parallel architecture, the software achieves substantial computational acceleration for large-scale simulations, and the implementation is verified and validated against benchmark numerical problems and experimental data, demonstrating accuracy, robustness, and favorable scaling performance. Comprehensive implementation details and user documentation are provided to ensure reproducibility and to support further development by the community. The framework and source code are freely available through a public GitHub repository."}
{"id": "2602.15416", "pdf": "https://arxiv.org/pdf/2602.15416", "abs": "https://arxiv.org/abs/2602.15416", "authors": ["Ghanashyam K. C.", "Satyavrata Samavedi", "Harish N Dixit"], "title": "A Robust Truncated-Domain Approach for Cone--Jet Simulations in Electrospinning and Electrospraying", "categories": ["physics.flu-dyn", "cond-mat.soft", "physics.comp-ph"], "comment": "14 pages, 9 figures", "summary": "Direct numerical simulations of electrospinning and electrospraying are computationally demanding due to large-scale separation between the needle and the tip-to-collector distance. The cone-jet mode that occurs in the vicinity of the needle arises from a delicate balance between surface tension, viscous stresses, inertia, and electric stresses. This mode has a central role in determining the subsequent instabilities of the jet and the eventual outcomes on the collector. Truncated-domain simulations offer a viable alternative but depend critically on the accuracy of far-field electrostatic boundary conditions. Existing truncated-domain approaches based on analytical expressions for the electric potential systematically underestimate the electric field near the needle tip and require empirical tuning informed by prior experiments or full-domain simulations, thereby limiting their predictive capability. Here, we present a general truncated-domain framework for electrohydrodynamic (EHD) simulations of the cone-jet mode that avoids these limitations. Our approach exploits inexpensive full-domain electrostatic simulations to obtain the exact electric field and potential distributions near the needle, which are then imposed as boundary conditions in an EHD simulation carried out on a truncated domain. Comparisons with full-domain EHD simulations and experimental data demonstrate that the proposed approach accurately reproduces cone-jet shapes as well as key physical quantities, including electric currents, charge distributions, velocity fields, and Maxwell stresses, while converging at substantially smaller domain sizes. The formulation eliminates tunable parameters, does not require prior knowledge of the cone-jet configuration, and significantly reduces computational cost, providing a reliable and predictive framework for studying electrohydrodynamic cone-jet flows."}
{"id": "2602.15621", "pdf": "https://arxiv.org/pdf/2602.15621", "abs": "https://arxiv.org/abs/2602.15621", "authors": ["Alberto Cialdea", "Carmine Sebastiano Mare"], "title": "Completeness theorems on the boundary for a parabolic equation", "categories": ["math.AP"], "comment": "24 pages", "summary": "Let $\\{v_α\\}$ be a system of polynomial solutions of the parabolic equation $a_{hk}\\partial_{x_{h}x_{k}}u - \\partial_t u =0$ in a bounded $C^1$-cylinder $Ω_{T}$ contained in $\\mathbb{R}^{n+1}$. Here $a_{hk}\\partial_{x_{h}x_{k}}$ is an elliptic operator with real constant coefficients. We prove that $\\{v_α\\}$ is complete in $L^{p}(Σ')$, where $Σ'$ is the parabolic boundary of $Ω_{T}$. Similar results are proved for the adjoint equation $a_{hk}\\partial_{x_{h}x_{k}} u+ \\partial_t u =0$."}
{"id": "2602.15202", "pdf": "https://arxiv.org/pdf/2602.15202", "abs": "https://arxiv.org/abs/2602.15202", "authors": ["Shakir Showkat Sofi", "Charlotte Vermeylen", "Lieven De Lathauwer"], "title": "Tomography by Design: An Algebraic Approach to Low-Rank Quantum States", "categories": ["quant-ph", "cs.AI", "eess.SP", "math.NA", "stat.CO"], "comment": "5 pages, Submitted to EUSIPCO2026", "summary": "We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees."}
{"id": "2602.15442", "pdf": "https://arxiv.org/pdf/2602.15442", "abs": "https://arxiv.org/abs/2602.15442", "authors": ["Urban Čoko", "Tilen Potisk", "Matej Praprotnik"], "title": "Virtual ultrasound machine operating in a GHz to MHz frequency range for particle-based biomedical simulations", "categories": ["cond-mat.soft", "cond-mat.mes-hall", "physics.bio-ph", "physics.comp-ph"], "comment": null, "summary": "Ultrasound-matter interactions underpin numerous biomedical and soft-matter applications, yet simulating these phenomena is challenging due to the large separation of viscous and sonic time scales. Continuum methods capture large-scale wave propagation but cannot resolve microscale interactions, while particle-based approaches offer molecular resolution but struggle with efficiency and stability at larger scales. We introduce a particle-based virtual ultrasound machine that uses a novel smoothed dissipative particle dynamics variant with an implicit pressure solver and a negative-pressure stabilization scheme, required to mimic acoustic propagation across MHz-GHz frequencies. We demonstrate its capabilities by modeling the acoustophoresis of encapsulated microbubbles, a key mechanism in ultrasound-mediated drug delivery. Beyond this application, the approach establishes a generalizable platform for simulating wave-matter interactions in soft and biological materials, opening new directions for computational studies of acoustics-driven phenomena in science and engineering."}
{"id": "2602.15647", "pdf": "https://arxiv.org/pdf/2602.15647", "abs": "https://arxiv.org/abs/2602.15647", "authors": ["Alberto Cialdea", "Vita Leonessa"], "title": "On the Robin problem for the Laplace equation in multiply connected domains", "categories": ["math.AP"], "comment": "12 pages", "summary": "This paper complements the existing theory developed in [5] for the Dirichlet and Neumann problems for the Laplace equation, in multiply connected domains. Within the framework of layer potential methods, we study the Laplace equation under Robin boundary conditions, representing the solutions by means of a double layer potential. We observe that the classical approach searches the solutions in terms of a single layer potential."}
{"id": "2602.15218", "pdf": "https://arxiv.org/pdf/2602.15218", "abs": "https://arxiv.org/abs/2602.15218", "authors": ["L. Portella", "F. M. Bayer", "R. J. Cintra"], "title": "Multiplierless DFT Approximation Based on the Prime Factor Algorithm", "categories": ["eess.SP", "math.NA", "stat.CO"], "comment": "24 pages, 4 figures", "summary": "Matrix approximation methods have successfully produced efficient, low-complexity approximate transforms for the discrete cosine transforms and the discrete Fourier transforms. For the DFT case, literature archives approximations operating at small power-of-two blocklenghts, such as \\{8, 16, 32\\}, or at large blocklengths, such as 1024, which are obtained by means of the Cooley-Tukey-based approximation relying on the small-blocklength approximate transforms. Cooley-Tukey-based approximations inherit the intermediate multiplications by twiddled factors which are usually not approximated; otherwise the effected error propagation would prevent the overall good performance of the approximation. In this context, the prime factor algorithm can furnish the necessary framework for deriving fully multiplierless DFT approximations. We introduced an approximation method based on small prime-sized DFT approximations which entirely eliminates intermediate multiplication steps and prevents internal error propagation. To demonstrate the proposed method, we design a fully multiplierless 1023-point DFT approximation based on 3-, 11- and 31-point DFT approximations. The performance evaluation according to popular metrics showed that the proposed approximations not only presented a significantly lower arithmetic complexity but also resulted in smaller approximation error measurements when compared to competing methods."}
{"id": "2602.15536", "pdf": "https://arxiv.org/pdf/2602.15536", "abs": "https://arxiv.org/abs/2602.15536", "authors": ["Mehran Sharifi", "Gorka S. Larraona", "Alejandro Rivas"], "title": "Novel distance-based masking and adaptive alpha-shape methods for CNN-ready reconstruction of arbitrary 2D CFD flow domains", "categories": ["physics.flu-dyn", "math.MG", "physics.comp-ph"], "comment": "47 Pages, 19 Figures, 7 Tables", "summary": "Interpolating scattered CFD datasets onto a uniform Cartesian grid can distort the true geometry, producing a convex-hull type envelope and activating nonphysical regions. This work presents a reconstruction framework that recovers physically consistent masks before exporting CNN-ready fields. It introduces two novel strategies, distance-based masking and an adaptive alpha-shape formulation that normalizes alpha using local data resolution, and evaluates them against classical alpha-shape boundary recovery. A quantitative, topology-aware metric suite is introduced to assess retention, suppression of unsupported regions, overlap consistency, and connectivity. The novel distance-based method is robust across the geometries considered under the same threshold rule, with tau set to the minimum CFD grid spacing, and achieves 500-800 times speedups over classical alpha-shapes. The adaptive alpha-shape remains stable when its control parameter is set to 1 and is 1.7-2.6 times faster than the classical variant, which requires geometry-specific alpha tuning. A lightweight boundary inflation post-process using a minimal dilation further improves retention by up to 2.96% with negligible unsupported activation (less than 0.08%). Overall, the distance-based method is recommended as the default due to its accuracy, stability, minimal tuning, and low cost, while the adaptive alpha-shape is a strong alternative when grid-spacing information for threshold selection is unavailable. A companion web application operationalizes the workflow end to end, enabling 2D ASCII dataset upload, parameter tuning, mask and boundary generation, and export of CNN-ready outputs."}
{"id": "2602.15670", "pdf": "https://arxiv.org/pdf/2602.15670", "abs": "https://arxiv.org/abs/2602.15670", "authors": ["Luigi De Rosa", "Margherita Marcotullio"], "title": "Quantitative enstrophy bounds for measure vorticities", "categories": ["math.AP", "math-ph", "physics.flu-dyn"], "comment": "26 pages. Comments are welcome!", "summary": "We consider the two-dimensional incompressible Navier-Stokes equations with measure initial vorticity. By means of improved Nash inequalities, we establish quantitative estimates for the enstrophy depending on the absolute vorticity decay on balls. The bounds are optimal in several aspects and yield to a conjecturally sharp rate of the dissipation in the Delort's class."}
{"id": "2602.15390", "pdf": "https://arxiv.org/pdf/2602.15390", "abs": "https://arxiv.org/abs/2602.15390", "authors": ["Naoki Sakai", "Takashi Goda"], "title": "Space-filling lattice designs for computer experiments", "categories": ["stat.ME", "math.NA", "math.NT"], "comment": "24 pages, 5 figures", "summary": "This paper investigates the construction of space-filling designs for computer experiments. The space-filling property is characterized by the covering and separation radii of a design, which are integrated through the unified criterion of quasi-uniformity. We focus on a special class of designs, known as quasi-Monte Carlo (QMC) lattice point sets, and propose two construction algorithms. The first algorithm generates rank-1 lattice point sets as an approximation of quasi-uniform Kronecker sequences, where the generating vector is determined explicitly. As a byproduct of our analysis, we prove that this explicit point set achieves an isotropic discrepancy of $O(N^{-1/d})$. The second algorithm utilizes Korobov lattice point sets, employing the Lenstra--Lenstra--Lovász (LLL) basis reduction algorithm to identify the generating vector that ensures quasi-uniformity. Numerical experiments are provided to validate our theoretical claims regarding quasi-uniformity. Furthermore, we conduct empirical comparisons between various QMC point sets in the context of Gaussian process regression, showcasing the efficacy of the proposed designs for computer experiments."}
{"id": "2602.15592", "pdf": "https://arxiv.org/pdf/2602.15592", "abs": "https://arxiv.org/abs/2602.15592", "authors": ["Xiao Xue", "Tianyue Yang", "Mingyang Gao", "Leyu Pan", "Maida Wang", "Kewei Zhu", "Shuo Wang", "Jiuling Li", "Marco F. P. ten Eikelder", "Peter V. Coveney"], "title": "Uni-Flow: a unified autoregressive-diffusion model for complex multiscale flows", "categories": ["physics.flu-dyn", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Spatiotemporal flows govern diverse phenomena across physics, biology, and engineering, yet modelling their multiscale dynamics remains a central challenge. Despite major advances in physics-informed machine learning, existing approaches struggle to simultaneously maintain long-term temporal evolution and resolve fine-scale structure across chaotic, turbulent, and physiological regimes. Here, we introduce Uni-Flow, a unified autoregressive-diffusion framework that explicitly separates temporal evolution from spatial refinement for modelling complex dynamical systems. The autoregressive component learns low-resolution latent dynamics that preserve large-scale structure and ensure stable long-horizon rollouts, while the diffusion component reconstructs high-resolution physical fields, recovering fine-scale features in a small number of denoising steps. We validate Uni-Flow across canonical benchmarks, including two-dimensional Kolmogorov flow, three-dimensional turbulent channel inflow generation with a quantum-informed autoregressive prior, and patient-specific simulations of aortic coarctation derived from high-fidelity lattice Boltzmann hemodynamic solvers. In the cardiovascular setting, Uni-Flow enables task-level faster than real-time inference of pulsatile hemodynamics, reconstructing high-resolution pressure fields over physiologically relevant time horizons in seconds rather than hours. By transforming high-fidelity hemodynamic simulation from an offline, HPC-bound process into a deployable surrogate, Uni-Flow establishes a pathway to faster-than-real-time modelling of complex multiscale flows, with broad implications for scientific machine learning in flow physics."}
{"id": "2602.15701", "pdf": "https://arxiv.org/pdf/2602.15701", "abs": "https://arxiv.org/abs/2602.15701", "authors": ["Riikka Korte", "Sari Rogovin", "Nageswari Shanmugalingam", "Timo Takala"], "title": "Solving Dirichlet problem on unbounded uniform domains by using sphericalization techniques", "categories": ["math.AP", "math.MG"], "comment": "35 pages", "summary": "Within the setting of metric spaces equipped with a doubling measure and supporting a $p$-Poincaré inequality, establishing existence of solutions to Dirichlet problem in a bounded domain in such a metric space is accomplished via direct methods of calculus of variation and the use of a Maz'ya type inequality, which is a consequence of the Poincaré inequality. However, when the domain and its boundary are unbounded, such a method is unavailable. In this paper, using the technique of sphericalization developed in the prior paper~[32], we establish the existence of solutions to the Dirichlet boundary value problem for $p$-harmonic functions in unbounded uniform domains with unbounded boundary when $1<p<\\infty$. We also explore the issue of whether such solutions are unique by considering $p$-parabolicity and $p$-hyperbolicity properties of the domain."}
{"id": "2602.15479", "pdf": "https://arxiv.org/pdf/2602.15479", "abs": "https://arxiv.org/abs/2602.15479", "authors": ["Daniel Alayón-Solarz"], "title": "A Degenerate Elliptic System Solvable by Transport: A Cautionary Example", "categories": ["math.AP", "math.CV", "math.NA"], "comment": "7 pages, 1 table. Comments are welcome", "summary": "We exhibit a one-parameter family of first-order real elliptic systems on the plane whose ellipticity constant degenerates to zero as $δ\\to 0$, with condition number $κ= O(δ^{-2})$. For any fixed elliptic solver operating at finite precision, the parameter $δ$ can be chosen small enough to defeat the solver; no uniform numerical scheme based on the ellipticity constant alone can handle the entire family. Despite this, every member of the family is explicitly solvable -- and its initial value problem well posed -- by elementary means once a transport-theoretic invariant is identified. The cost of the transport solution is independent of $δ$. The example serves as a cautionary tale: the ellipticity constant alone does not determine the practical difficulty of a first-order PDE. Before invoking an elliptic solver, one should compute the transport obstruction $G$; its vanishing -- or smallness -- signals structure that standard elliptic methods miss entirely."}
{"id": "2602.15743", "pdf": "https://arxiv.org/pdf/2602.15743", "abs": "https://arxiv.org/abs/2602.15743", "authors": ["Matteo Ugliotti", "Brandon Choi", "Mateo Reynoso", "Daniel R. Gurevich", "Roman O. Grigoriev"], "title": "Physics-informed data-driven inference of an interpretable equivariant LES model of incompressible fluid turbulence", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "Restrictive phenomenological assumptions represent a major roadblock for the development of accurate subgrid-scale models of fluid turbulence. Specifically, these assumptions limit a model's ability to describe key quantities of interest, such as local fluxes of energy and enstrophy, in the presence of diverse coherent structures. This paper introduces a symbolic data-driven subgrid-scale model that requires no phenomenological assumptions and has no adjustable parameters, yet it outperforms leading LES models. A combination of a priori and a posteriori benchmarks shows that the model produces accurate predictions of various quantities including local fluxes across a broad range of two-dimensional turbulent flows. While the model is inferred using LES-style spatial coarse-graining, its structure is more similar to RANS models, as it employs an additional field to describe subgrid scales. We find that this field must have a rank-two tensor structure in order to correctly represent both the components of the subgrid-scale stress tensor and the various fluxes."}
{"id": "2602.15715", "pdf": "https://arxiv.org/pdf/2602.15715", "abs": "https://arxiv.org/abs/2602.15715", "authors": ["Kyeongbae Kim", "Simon Nowak", "Yannick Sire"], "title": "Fine regularity of fractional harmonic maps and applications", "categories": ["math.AP"], "comment": "37 pages", "summary": "In this paper, we derive several regularity results for harmonic mappings into Euclidean spheres associated with rather general energies related to fractional Sobolev spaces. These maps generalize families of maps introduced by Da Lio, Rivière and Schikorra and are related to harmonic maps with free boundaries. In our context, there is in general no monotonicity formula, which prevents the use of some classical methods. Despite this limitation, under natural assumptions on a Gagliardo-type energy, we succeed in proving a variety of small energy regularity results and improve on known results, even in the isotropic case for which some monotonicity formula is available. To this end, we exploit recent developments in the regularity theory of nonlocal equations and as a by-product, we explain how these results apply to classes of harmonic maps with free boundary and lead to new potential-theoretic estimates. As another application, we obtain higher differentiability results for the fractional harmonic map heat flow."}
{"id": "2602.15632", "pdf": "https://arxiv.org/pdf/2602.15632", "abs": "https://arxiv.org/abs/2602.15632", "authors": ["Changhong Mou", "Binghang Lu", "Guang Lin"], "title": "Neural-POD: A Plug-and-Play Neural Operator Framework for Infinite-Dimensional Functional Nonlinear Proper Orthogonal Decomposition", "categories": ["physics.comp-ph", "cs.LG", "math.NA"], "comment": null, "summary": "The rapid development of AI for Science is often hindered by the \"discretization\", where learned representations remain restricted to the specific grids or resolutions used during training. We propose the Neural Proper Orthogonal Decomposition (Neural-POD), a plug-and-play neural operator framework that constructs nonlinear, orthogonal basis functions in infinite-dimensional space using neural networks. Unlike the classical Proper Orthogonal Decomposition (POD), which is limited to linear subspace approximations obtained through singular value decomposition (SVD), Neural-POD formulates basis construction as a sequence of residual minimization problems solved through neural network training. Each basis function is obtained by learning to represent the remaining structure in the data, following a process analogous to Gram--Schmidt orthogonalization. This neural formulation introduces several key advantages over classical POD: it enables optimization in arbitrary norms (e.g., $L^2$, $L^1$), learns mappings between infinite-dimensional function spaces that is resolution-invariant, generalizes effectively to unseen parameter regimes, and inherently captures nonlinear structures in complex spatiotemporal systems. The resulting basis functions are interpretable, reusable, and enabling integration into both reduced order modeling (ROM) and operator learning frameworks such as deep operator learning (DeepONet). We demonstrate the robustness of Neural-POD with different complex spatiotemporal systems, including the Burgers' and Navier-Stokes equations. We further show that Neural-POD serves as a high performance, plug-and-play bridge between classical Galerkin projection and operator learning that enables consistent integration with both projection-based reduced order models and DeepONet frameworks."}
{"id": "2602.15059", "pdf": "https://arxiv.org/pdf/2602.15059", "abs": "https://arxiv.org/abs/2602.15059", "authors": ["Chandrasekhar Gokavarapu", "Naveen Kumar Kakumanu", "Anjali Datla", "Githa Harshitha Noolu"], "title": "Certified Reduced-Order Surrogates and Stability Margins in Viscous Incompressible Flow and Fluid--Structure Interaction", "categories": ["math.NA", "math.AP", "math.RA"], "comment": null, "summary": "Let $(u,p)$ solve the incompressible Navier--Stokes equations in a regime in which an energy inequality is available and each constant in that inequality is computable from declared data. We construct a reduced-order model $u_n$ constrained so that its discrete evolution satisfies a certified energy inequality. This certificate yields global-in-time boundedness of the ROM energy and a regime-of-validity test that fails when a stated hypothesis fails.\n  It follows that one can attach a computable residual functional $\\mathcal{R}_n$ to the ROM trajectory. We prove an a posteriori bound of the form \\[ \\norm{u-u_n}_{\\mathsf{X}(0,T)} \\le C(\\text{declared data})\\,\\mathcal{R}_n, \\] with $C$ explicit and with $\\mathcal{R}_n$ computed from the ROM and the discretization operators. Conversely, if the certificate constraint is relaxed, the bound can fail even for stable full-order dynamics, by an explicit instability mechanism recorded in the text.\n  We then derive transition indicators from rigorous energy and enstrophy budgets in simplified geometries. Each indicator is an inequality involving declared quantities such as forcing norms, viscosity, Poincaré-type constants, and a computable resolvent surrogate. These inequalities provide thresholds that preclude transition, or else certify the presence of transient growth beyond a stated level.\n  Finally, for a class of fluid--structure interaction models, we identify a parameter regime that implies existence and uniqueness of weak solutions. We derive discrete coupled energy estimates that produce computable stability margins. These margins yield explicit constraints on time step and mesh parameters. They are stated as inequalities with constants determined by fluid viscosity, structure stiffness, density ratios, and interface trace bounds."}
{"id": "2602.15300", "pdf": "https://arxiv.org/pdf/2602.15300", "abs": "https://arxiv.org/abs/2602.15300", "authors": ["Jose Antonio Villa"], "title": "Carleman Inequalities for the Heat Equation with Fourier Boundary Conditions: Applications to Null Controllability Problems", "categories": ["math.OC", "math.AP"], "comment": "19 pages", "summary": "In this work, we establish a Carleman inequality for the heat equation with Fourier boundary conditions of the form $\\partial_νy+by=f1_γ$, where the control acts on a small portion $γ$ of the boundary. We apply this inequality to address the null controllability problem with boundary control supported on this small region. An explicit solution to this problem is obtained via a system of coupled parabolic equations. Based on these results, we propose an iterative numerical method to solve the coupled system."}
{"id": "2602.15764", "pdf": "https://arxiv.org/pdf/2602.15764", "abs": "https://arxiv.org/abs/2602.15764", "authors": ["Ruiliang Li"], "title": "Quantitative local recovery of Kerr-de Sitter parameters from high-frequency equatorial quasinormal modes", "categories": ["math-ph", "gr-qc", "math.AP"], "comment": "68 pages. First paper in a series on inverse Kerr-de Sitter spectroscopy from high-frequency equatorial quasinormal modes", "summary": "We study an inverse resonance problem for the scalar wave equation on the Kerr-de Sitter family. In a compact subextremal slow-rotation regime and at a fixed overtone index, high-frequency quasinormal modes admit semiclassical quantization and a real-analytic labeling by angular momentum indices. Using this structure, we first prove that a finite equatorial high-frequency package of quasinormal-mode frequencies determines the mass and rotation parameter $(M,a)$ (for fixed cosmological constant $Λ>0$), with a quantitative stability estimate. As a key geometric input we compute explicit second-order (in $a$) corrections to the equatorial photon-orbit invariants which control the leading real and imaginary parts of the quasinormal modes. Finally, allowing $Λ$ to vary in a compact interval, we show that adding one damping observable (the scaled imaginary part of a single equatorial mode) yields a three-parameter inverse theorem: a finite package of three independent real observables determines $(M,a,Λ)$ locally in the slow-rotation regime away from $a=0$."}
{"id": "2602.15786", "pdf": "https://arxiv.org/pdf/2602.15786", "abs": "https://arxiv.org/abs/2602.15786", "authors": ["David Bick"], "title": "Timelike bounce hypersurfaces in charged null dust collapse", "categories": ["gr-qc", "math-ph", "math.AP", "math.DG"], "comment": "44 pages, 13 figures", "summary": "We establish results on the dynamics of interacting charged null fluids in general relativity, specifically in the context of the bouncing continuation proposed in [Ori91]. In this model - the setting for a number of prominent case studies on black hole formation - charged massless particles may instantaneously change direction (bounce) after losing all their 4-momentum due to electrostatic repulsion. We initiate the study of timelike bounce hypersurfaces in spherical symmetry: scenarios in which an incoming beam of charged null dust changes direction along a timelike surface $\\mathcal{B}$, which is the (free) boundary of an interacting 2-dust region. We identify a novel decoupling of the equations of motion in this region. First, it is shown that every timelike curve segment $γ$ in the spherically symmetric quotient of Minkowski or Reissner-Nordström spacetimes arises as the bounce hypersurface $\\mathcal{B}$ of a charged null dust beam incident from past null infinity $\\mathcal{I}^-$. We construct a spacetime $(\\mathcal{M},g_{μν})$ describing the full trajectory of the beam, which includes gluing to Reissner-Nordström and Vaidya regions. Across $\\mathcal{B}$ the metric has regularity $g_{μν}\\in C^{2,1}$ and satisfies Einstein's equation classically, while $C^\\infty$ gluing may be achieved across all other interfaces. We also obtain examples of timelike bounce hypersurfaces terminating in a null point. Since these constructions are teleological, we secondly consider a given charged incoming beam from past null infinity. We formulate and solve a free boundary problem which represents the formation of a timelike bounce hypersurface. The result is conditional, applying only in the exterior region of a Reissner-Nordström spacetime, and subject to a technical regularity condition."}
{"id": "2602.15805", "pdf": "https://arxiv.org/pdf/2602.15805", "abs": "https://arxiv.org/abs/2602.15805", "authors": ["Alain-Sol Sznitman", "Klaus Widmayer"], "title": "Inviscid limit and an effective energy-enstrophy diffusion process", "categories": ["math.PR", "math-ph", "math.AP"], "comment": "37 pages, 1 figure", "summary": "In this article we consider a stationary $N$-dimensional Galerkin-Navier-Stokes type evolution with Brownian forcing and random stirring (of arbitrarily small strength). We show that the stationary diffusion in an open two-dimensional cone constructed in a companion article, stands as the inviscid limit of the laws of the ``enstrophy-energy'' process of the $N$-dimensional diffusion process considered here, this regardless of the strength of the stirring. With the help of the quantitative condensation bounds of the companion article, we infer quantitative inviscid condensation bounds, which for suitable forcings show an attrition of all but the lowest modes in the inviscid limit."}
{"id": "2602.15810", "pdf": "https://arxiv.org/pdf/2602.15810", "abs": "https://arxiv.org/abs/2602.15810", "authors": ["Alain-Sol Sznitman", "Klaus Widmayer"], "title": "Effective energy-enstrophy diffusion process and condensation bound", "categories": ["math.PR", "math-ph", "math.AP"], "comment": "29 pages, 2 figures", "summary": "In this article we use Gaussian measure on $\\mathbb{R}^N$ to define the coefficients of an elliptic diffusion on an open cone of $\\mathbb{R}^2$. We prove the existence and uniqueness of a stationary distribution for this diffusion. In a companion article, we show that the diffusion constructed in this work is the inviscid limit of the laws of the ``enstrophy-energy'' process of a stationary $N$-dimensional Galerkin-Navier-Stokes type evolution with Brownian forcing and random stirring (the strength of which can be made to go to zero in the inviscid limit). In the present work, owing to the special properties of the coefficients constructed with the Gaussian measure, we bound the distance to $1$ of the ratio of the expected energy to the expected enstrophy (this ratio is at most $1$ with our normalization). Together with our companion article, this shows that for suitable Brownian forcings an inviscid condensation inducing an attrition of all but the lowest modes takes place."}
