<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 7]
- [math.AP](#math.AP) [Total: 21]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [cs.LG](#cs.LG) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cs.SC](#cs.SC) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [math.DG](#math.DG) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.MS](#cs.MS) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Reduced Order Model approach for First-Principles Molecular Dynamics Computations](https://arxiv.org/abs/2602.22390)
*Siu Wun Cheung,Youngsoo Choi,Jean-Luc Fattebert,Jonas Kaufman,Daniel Osei-Kuffuor*

Main category: math.NA

TL;DR: Data-driven framework bypasses iterative wavefunction optimization in DFT by constructing reduced basis from sampled configurations for efficient ground state determination.


<details>
  <summary>Details</summary>
Motivation: To leverage redundancy in electronic structure computations during molecular dynamics and avoid computationally expensive iterative wavefunction optimization in Kohn-Sham DFT.

Method: Sample representative atomic configurations, construct low-dimensional basis approximating electronic structure subspace, use reduced basis in direct solver for electronic density matrix to determine ground state without iterative optimization.

Result: Accurately reproduces key structural properties (bond lengths, bond angle) of water molecule in Born-Oppenheimer molecular dynamics compared to full first-principles simulations.

Conclusion: Demonstrates potential of data-driven approaches for developing efficient electronic structure solvers in first-principles simulations by bypassing traditional iterative wavefunction optimization.

Abstract: To leverage the redundancy between the electronic structure computed at each step of first-principles molecular dynamics, we present a data-driven modeling framework for Kohn-Sham Density Functional Theory that bypasses the explicit optimization of electronic wavefunctions. We sample a priori representative atomic configurations and construct a low-dimensional basis that efficiently approximates the electronic structure subspace. Subsequently, we employ this reduced basis in a direct solver for the electronic single particle density matrix, thereby enabling the efficient determination of ground state without iterative wavefunction optimization. We demonstrate the efficacy of our approach in a Born-Oppenheimer molecular dynamics of a water molecule, showing that the resulting simulations accurately reproduce key structural properties, such as bond lengths and bond angle, obtained from full first-principles molecular dynamics. This work highlights the potential of data-driven approaches to develop efficient electronic structure solvers for first-principles simulations.

</details>


### [2] [Error Analysis of Parameter Prediction via Gaussian Process Regression and Its Application to Weighted Jacobi Iteration](https://arxiv.org/abs/2602.22679)
*Tiantian Sun,Juan Zhang*

Main category: math.NA

TL;DR: Novel theoretical framework for Gaussian process regression error analysis using function-space decomposition, leading to a weighted Jacobi iterative method with GP-based parameter prediction and convergence analysis.


<details>
  <summary>Details</summary>
Motivation: To develop a more comprehensive error analysis framework for Gaussian process regression and create accelerated iterative methods by combining GP regression with traditional numerical techniques.

Method: Introduces a function-space decomposition framework for GP regression error analysis, then develops a weighted Jacobi iterative method that uses Gaussian process regression for parameter prediction, with convergence analysis and compatibility conditions with other error bounds.

Result: Experimental results demonstrate that parameters predicted using Gaussian process regression significantly accelerate the convergence speed of Jacobi iterations compared to traditional approaches.

Conclusion: The proposed framework successfully combines Gaussian process regression with iterative methods, providing both theoretical foundations and practical acceleration benefits for numerical computations.

Abstract: In this paper, we introduce a novel theoretical framework for Gaussian process regression error analysis, leveraging a function-space decomposition. Based on this framework, we develop a weighted Jacobi iterative method that utilizes Gaussian process regression for parameter prediction and provide a corresponding convergence analysis. Moreover, the convergence conditions are designed to be compatible with other error bounds, enabling a more general analysis. Experimental results show that the parameters predicted based on Gaussian process regression significantly accelerate the convergence speed of Jacobi iterations.

</details>


### [3] [Comparison of Structure-Preserving Methods for the Cahn-Hilliard-Navier-Stokes Equations](https://arxiv.org/abs/2602.22861)
*Jimmy Kornelije Gunnarsson,Robert Kl√∂fkorn*

Main category: math.NA

TL;DR: Structure-preserving DG methods for Cahn-Hilliard-Navier-Stokes with degenerate mobility using SWIPD-L and SIPGD-L formulations with edge-wise mobility treatments for better stability control.


<details>
  <summary>Details</summary>
Motivation: Need for structure-preserving numerical methods for Cahn-Hilliard-Navier-Stokes equations with degenerate mobility that maintain physical properties like mass conservation, energy dissipation, and maximum principle while achieving computational efficiency.

Method: Developed SWIPD-L and SIPGD-L discontinuous Galerkin methods with parametrized mobility fluxes and edge-wise mobility treatments for enhanced coercivity-stability control. Methods incorporate generalized trilinear forms with proven coercivity properties.

Result: Proved coercivity for generalized trilinear form, demonstrated optimal convergence rates while preserving mass conservation, energy dissipation, and discrete maximum principle. Comparisons show similar stability to existing SIPG-L and SWIP-L methods. Validation on hp-adaptive meshes shows significant computational savings without accuracy loss for both standalone Cahn-Hilliard and coupled systems.

Conclusion: The proposed structure-preserving DG methods successfully handle degenerate mobility in Cahn-Hilliard-Navier-Stokes equations while maintaining physical properties, achieving optimal convergence, and offering computational efficiency through hp-adaptive meshes.

Abstract: We develop structure-preserving discontinuous Galerkin methods for the Cahn-Hilliard-Navier-Stokes equations with degenerate mobility. The proposed SWIPD-L and SIPGD-L methods incorporate parametrized mobility fluxes with edge-wise mobility treatments for enhanced coercivity-stability control. We prove coercivity for the generalized trilinear form and demonstrate optimal convergence rates while preserving mass conservation, energy dissipation, and the discrete maximum principle. Comparisons with existing SIPG-L and SWIP-L methods confirm similar stability. Validation on $hp$-adaptive meshes for both standalone Cahn-Hilliard and coupled systems shows significant computational savings without accuracy loss.

</details>


### [4] [A Reduced Magnetic Vector Potential Approach with Higher-Order Splines](https://arxiv.org/abs/2602.22997)
*Merle Backmeyer,Laura A. M. D'Angelo,Brahim Ramdane,Sebastian Sch√∂ps*

Main category: math.NA

TL;DR: High-order isogeometric method for magnetoquasistatic eddy-current problems using Biot-Savart-driven source fields and finite-element reaction fields, avoiding coil meshing and enabling high-order accuracy.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient high-order formulation for magnetoquasistatic eddy-current problems that avoids the computational burden of coil meshing while supporting arbitrary winding paths and achieving high-order field approximation.

Method: Generalizes reduced magnetic vector potential framework to quasistatic regime using surface-only Biot-Savart evaluation, introduces consistent high-order spline discretization, and decomposes problem into Biot-Savart-driven source fields and finite-element reaction fields.

Result: Method achieves optimal convergence rates, avoids coil meshing, supports arbitrary winding paths, enables high-order field approximation in reduced computational domain, and identifies practical requirements for high-order accuracy recovery.

Conclusion: The presented high-order isogeometric formulation successfully addresses magnetoquasistatic eddy-current problems with improved computational efficiency and accuracy, with practical implementation requiring attention to geometric regularity, accurate kernel quadrature, and compatible trace spaces.

Abstract: This work presents a high-order isogeometric formulation for magnetoquasistatic eddy-current problems based on a decomposition into Biot-Savart-driven source fields and finite-element reaction fields. Building upon a recently proposed surface-only Biot-Savart evaluation, we generalize the reduced magnetic vector potential framework to the quasistatic regime and introduce a consistent high-order spline discretization. The resulting method avoids coil meshing, supports arbitrary winding paths, and enables high-order field approximation within a reduced computational domain. Beyond establishing optimal convergence rates, the numerical investigation identifies the requirements necessary to recover high-order accuracy in practice, including geometric regularity of the enclosing interface, accurate kernel quadrature, and compatible trace spaces for the source-reaction coupling.

</details>


### [5] [Nearest Reversible Markov Chains with Sparsity Constraints: An Optimization Approach](https://arxiv.org/abs/2602.23059)
*Stefano Cipolla,Fabio Durastante,Miryam Gnazzo,Beatrice Meini*

Main category: math.NA

TL;DR: The paper presents a method to approximate non-reversible Markov chains with reversible ones while preserving sparsity, formulated as a matrix nearness optimization problem.


<details>
  <summary>Details</summary>
Motivation: Many applications produce non-reversible Markov chains, but reversibility is crucial for algorithms like Metropolis-Hastings and MCMC methods. There's a need to approximate non-reversible chains with reversible ones with minimal modification.

Method: Formulates the problem as a matrix nearness problem for sparse transition matrices, resulting in a quadratic programming optimization problem.

Result: Numerical experiments demonstrate the effectiveness of the approach in approximating non-reversible chains with reversible ones while maintaining sparsity patterns.

Conclusion: The framework provides a principled way to enforce reversibility and sparsity in Markov chains, with applications in MCMC, computational chemistry, and data-driven modeling.

Abstract: Reversibility is a key property of Markov chains, central to algorithms such as Metropolis-Hastings and other MCMC methods. Yet many applications yield non-reversible chains, motivating the problem of approximating them by reversible ones with minimal modification. We formulate this task as a matrix nearness problem and focus on the practically relevant case of sparse transition matrices. The resulting optimization problem is a quadratic programming problem, and numerical experiments illustrate the effectiveness of the approach. This framework provides a principled way to enforce reversibility and sparsity patterns in Markov chains with applications in MCMC, computational chemistry, and data-driven modeling.

</details>


### [6] [A Hyperbolic Transport Model for Passenger Flow on Tram Networks](https://arxiv.org/abs/2602.23081)
*Thomas Schillinger*

Main category: math.NA

TL;DR: Framework for urban tram networks using hyperbolic PDE for passenger transport coupled with stochastic boarding processes, analyzed with measure-valued solutions and uncertainty assessment.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive mathematical model for urban tram networks that captures both deterministic passenger transport dynamics and stochastic boarding processes, while accounting for real-world uncertainties like delays and service interruptions.

Method: Hyperbolic partial differential equation for passenger transport along the network, coupled with family of stochastic processes for passenger boarding. Solutions considered in measure-valued sense. Extended with uncertainties through numerical study and assessed using risk measures.

Result: Developed modeling framework capable of representing urban tram network dynamics with both deterministic and stochastic components, with measure-valued solutions and numerical analysis of uncertainty impacts.

Conclusion: The framework provides a robust mathematical foundation for analyzing urban tram networks under uncertainty, with potential applications for network optimization, reliability assessment, and risk management in public transportation systems.

Abstract: We introduce a modeling framework for an urban tram network based on a hyperbolic partial differential equation describing the transport of passengers along the network, coupled with a family of stochastic processes representing passenger boarding. Solutions are considered in a measure-valued sense. The system is further extended and subjected to uncertainties such as delays and service interruptions through a numerical study. Its robustness is assessed using appropriate risk measures.

</details>


### [7] [On the choice of viscous discontinuous Galerkin discretization for entropy correction artificial viscosity methods](https://arxiv.org/abs/2602.23210)
*Samuel Q. Van Fleet,Jesse Chan*

Main category: math.NA

TL;DR: ECAV is an entropy-correcting artificial viscosity method that enforces entropy inequality with minimal viscosity, analyzed here with LDG discretization, showing O(h) coefficient bound and contact-preserving properties.


<details>
  <summary>Details</summary>
Motivation: To analyze the Entropy Correction Artificial Viscosity (ECAV) method when discretized using Local Discontinuous Galerkin (LDG) approach, examining its theoretical properties including time-step restrictions and contact preservation compared to traditional shock capturing methods.

Method: Theoretical analysis of ECAV with LDG discretization, proving mathematical bounds on the viscosity coefficient and demonstrating contact-preserving properties through analytical proofs and comparisons with traditional artificial viscosity methods.

Result: Proved O(h) upper bound on ECAV coefficient, showing it doesn't impose restrictive time-step conditions. Demonstrated ECAV is contact-preserving and compared favorably to traditional shock capturing artificial viscosity methods.

Conclusion: ECAV with LDG discretization provides an effective entropy-correcting artificial viscosity method with favorable theoretical properties: non-restrictive time-step conditions, contact preservation, and advantages over traditional shock capturing approaches.

Abstract: Entropy correction artificial viscosity (ECAV) is an approach for enforcing a semi-discrete entropy inequality through an entropy dissipative correction term. The resulting method can be implemented as an artificial viscosity with an extremely small viscosity coefficient. In this work, we analyze ECAV when the artificial viscosity is discretized using a local discontinuous Galerkin (LDG) method. We prove an $O(h)$ upper bound on the ECAV coefficient, indicating that ECAV does not result in a restrictive time-step condition. We additionally show that ECAV is contact preserving, and compare ECAV to traditional shock capturing artificial viscosity methods.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [8] [Weak Diffeomorphisms and Extremals for Scalar Conservation Laws](https://arxiv.org/abs/2602.22467)
*Prerona Dutta,Barbara Lee Keyfitz*

Main category: math.AP

TL;DR: The paper shows that particle paths (Lagrangian trajectories) for scalar conservation laws are geodesics in the space of diffeomorphisms, and extends this to some systems like isentropic gas dynamics.


<details>
  <summary>Details</summary>
Motivation: To establish a geometric interpretation of Lagrangian formulations for conservation laws, connecting particle paths to geodesic flows on diffeomorphism groups.

Method: Uses Lagrangian (particle path) formulation of conservation laws, analyzes the infinite-dimensional diffeomorphism group structure, and applies variational principles to show particle paths are extremals of action functionals.

Result: Proves that for scalar conservation laws, particle paths are geodesics in some metric on the diffeomorphism space. Extends this result to some systems including isentropic gas dynamics in 1D.

Conclusion: Lagrangian trajectories for conservation laws have a geometric interpretation as geodesics on diffeomorphism groups, providing a deeper connection between particle dynamics and geometric mechanics.

Abstract: Scalar conservation laws in one space variable allow a Lagrangian (particle path) formulation. The Lagrangian trajectory in the infinite-dimensional group of diffeomorphisms on the physical space can be written as a system of conservation laws. The relation between solutions of the Cauchy problem for the conservation law and solutions of the corresponding Cauchy problem on the diffeomorphism group extends to weak solutions of the coresponding problems. The correspondence between particle paths and transport equations is analogous to that between a Lie group and the corresponding Lie algebra.
  This paper establishes that for scalar conservation laws the particle paths are extremals of an action functional on the space of diffeomorphisms; that is, they are geodesics in some metric. In some examples of systems of conservation laws, including the physical example of isentropic gas dynamics in one space dimension, diffeomorphism representations also exist and may be interpreted as extremals of action functionals.

</details>


### [9] [The global well-posedness of the multi-dimensional compressible Euler system with damping in the $L^p$ critical Besov spaces for $p<2$](https://arxiv.org/abs/2602.22550)
*Jianzhong Zhang,Ying Sui,Xiliang Li*

Main category: math.AP

TL;DR: Global well-posedness of compressible Euler system with damping in L^p-type critical Besov spaces for 1‚â§p<2, using new product estimates in hybrid Besov spaces.


<details>
  <summary>Details</summary>
Motivation: To establish global-in-time well-posedness for the compressible Euler system with damping in critical Besov spaces, particularly for the challenging range 1‚â§p<2 where standard methods may fail.

Method: Develop new product estimates in L^2-L^p hybrid Besov spaces to handle the nonlinear terms, then apply these estimates to prove global existence and uniqueness for the damped compressible Euler system.

Result: Successfully established global-in-time well-posedness in L^p-type critical Besov spaces for 1‚â§p<2, overcoming technical difficulties in this parameter range.

Conclusion: The paper provides a complete well-posedness theory for damped compressible Euler equations in critical Besov spaces, including the previously challenging case of 1‚â§p<2, through innovative hybrid space techniques.

Abstract: In this paper, we study the Cauchy's problem of the compressible Euler system with damping and establish the global-in-time well-posedness in $L^p$-type critical Besov spaces for $1\leq p<2$. To achieve it, a new product estimate is established in $L^2$-$L^p$ hybrid Besov spaces.

</details>


### [10] [Global three-dimensional subsonic Euler flows past an axisymmetric obstacle with large vorticity](https://arxiv.org/abs/2602.22598)
*Dehua Wang,Tian-Yi Wang,Weiqiang Wang*

Main category: math.AP

TL;DR: Existence and uniqueness of subsonic Euler flows past axisymmetric obstacles with prescribed upstream axial velocities, requiring upstream density above critical threshold.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical foundations for subsonic steady Euler flows around axisymmetric obstacles, extending beyond previous two-dimensional results to handle flows with large vorticity.

Method: Combines strong maximum principle with refined continuity argument to prove non-degeneracy of axial velocity, uses uniform integral estimates for asymptotic behavior analysis.

Result: Proves existence and uniqueness of subsonic solutions for broad class of prescribed positive axial velocities, provided upstream density exceeds critical threshold; accommodates flows with large vorticity under structural condition.

Conclusion: Establishes rigorous mathematical framework for axisymmetric subsonic Euler flows, extending previous two-dimensional results and allowing for significant vorticity effects.

Abstract: In this paper, we prove the existence and uniqueness of subsonic solutions to the steady Euler flows past a smooth, axisymmetric obstacle. Specifically, for a broad class of prescribed positive axial velocities in the upstream, the subsonic Euler flow exists provided that the upstream density exceeds a critical threshold. The non-degeneracy of the axial velocity is rigorously established by combining the strong maximum principle with a refined continuity argument. The asymptotic behavior of the flow is obtained from uniform integral estimates for the difference between the flow and the upstream state. In addition, this result accommodates flows with large vorticity under a structural condition, thereby differing from previous results in the two-dimensional case.

</details>


### [11] [Uniform Stability of Oscillatory Shocks for KdV-Burgers Equation](https://arxiv.org/abs/2602.22652)
*Geng Chen,Namhyun Eun,Moon-Jin Kang,Yannan Shen*

Main category: math.AP

TL;DR: The paper analyzes viscous-dispersive shock profiles with infinite oscillations in the KdVB equation, establishing structural properties and proving L¬≤ contraction under large perturbations with time-dependent shifts.


<details>
  <summary>Details</summary>
Motivation: To understand the detailed structure and stability properties of shock wave solutions in the Korteweg-de Vries-Burgers equation, particularly focusing on infinite oscillations and establishing uniform stability results.

Method: First establishes detailed structures of shock waves including convergence rates of local extrema, then exploits these structural properties to prove L¬≤ contraction under large perturbations with time-dependent shifts.

Result: Proves L¬≤ contraction property of shock profiles under arbitrarily large perturbations (with time-dependent shifts), implying both time-asymptotic stability and uniform stability with respect to viscosity and dispersion coefficients, leading to zero viscosity-dispersion limits.

Conclusion: The detailed structural analysis enables rigorous stability results for KdVB shock profiles, providing uniform stability that yields important zero viscosity-dispersion limits.

Abstract: In this paper, we study the viscous-dispersive shock profile with infinite oscillations of the Korteweg-de Vries-Burgers (KdVB) equation. First, we establish detail structures of the shock wave, including the rate at which the local extrema converge to the left end state towards the left far field. Then, by exploiting the structural properties of the shock, we show the $L^2$ contraction property of the shock profile under arbitrarily large perturbations, up to a time-dependent shift. This result implies both time-asymptotic stability and uniform stability with respect to the viscosity and dispersion coefficients. This uniformity yields zero viscosity-dispersion limits.

</details>


### [12] [Circle-like concentrated solutions for two-component Bose-Einstein condensates](https://arxiv.org/abs/2602.22672)
*Qidong Guo,Qiaoqiao Hua,Chongyang Tian*

Main category: math.AP

TL;DR: Existence of synchronized normalized solutions for two-component BEC system with L¬≤ constraint, concentrating on high-dimensional subsets via finite-dimensional reduction and local Pohozaev identities.


<details>
  <summary>Details</summary>
Motivation: To study normalized solutions of two-component Bose-Einstein condensates systems with L¬≤ constraint, addressing the gap in existing research for high-dimensional concentrated normalized solutions in such systems.

Method: Finite-dimensional reduction method combined with local Pohozaev identities to construct vector radial solutions that concentrate on circles as a specific parameter ratio tends to zero.

Result: Established existence of synchronized solutions concentrating on high-dimensional subsets of ‚Ñù¬≤ for various parameter ranges (Œ±>0, Œ≥>0, Œ≤ in specific intervals), constructing vector radial solutions that concentrate on circles.

Conclusion: Fills the research gap for high-dimensional concentrated normalized solutions in two-component BEC systems, providing existence results for synchronized solutions with specific concentration behavior.

Abstract: We investigate the normalized solutions of the following two-component Bose-Einstein condensates (BEC) system
  \begin{equation}\left\{ \begin{split}
  -Œîu + (Œª+P(x))u &= Œ±u^3 +Œ≤uv^2, && \text{in } \mathbb{R}^2,\\-Œîv + (Œª+Q(x))v &= Œ≥v^3 +Œ≤u^2 v, && \text{in } \mathbb{R}^2, \end{split} \right.\end{equation}
  with $L^2$-constraint $$\int_{\mathbb{R}^2}(u^2+v^2)\,dx = 1.$$ For any $Œ±>0$, $Œ≥> 0$ and $\ Œ≤\in (-\sqrt{Œ±Œ≥},0)\cup(0,\min \{Œ±,Œ≥\})\cup \left(\max \{Œ±,Œ≥\} , + \infty\right)$, we establish the existence of synchronized solutions concentrating on high-dimensional subsets of $\mathbb{R}^2$ by employing a finite-dimensional reduction method combined with some local Pohozaev identities. More precisely, we construct vector radial solutions that concentrate on circles when $ \frac{Œ±+ Œ≥- 2Œ≤}{Œ±Œ≥- Œ≤^2}$ tends to zero. Our results fill the blank in the system for high-dimensional concentrated normalized solutions.

</details>


### [13] [Generically sharp decay and blowing up at infinity for a weak null wave system](https://arxiv.org/abs/2602.22749)
*Shijie Dong,Siyuan Ma,Yue Ma,Xu Yuan*

Main category: math.AP

TL;DR: The paper establishes sharp pointwise decay estimates for semilinear wave equations satisfying the weak null condition, showing both upper and lower bounds for small data solutions, with applications to energy blow-up and frequency cascade.


<details>
  <summary>Details</summary>
Motivation: The system serves as a simplified model for Einstein vacuum equations. The goal is to understand precise decay behavior of solutions and investigate energy dynamics, particularly potential energy blow-up at infinity and frequency cascade phenomena.

Method: Study semilinear wave equations satisfying the weak null condition. Establish precise pointwise decay estimates (both lower and upper bounds) for small data solutions. Analyze the difference between solutions and their leading-order terms, focusing on decay rates in retarded time variable u = t - r.

Result: 1) Sharp pointwise decay estimates showing the solution minus its leading-order term decays faster in u. 2) Energy of one component generically grows to infinity as t ‚Üí +‚àû ("blowing up at infinity"). 3) That component exhibits energy cascade from high to low frequencies.

Conclusion: The weak null condition wave equations exhibit rich dynamics: while solutions decay pointwise, energy can blow up at infinity and undergo frequency cascade. The estimates are sharp for generic small initial data, providing insights for Einstein vacuum equations.

Abstract: We study a system of semilinear wave equations satisfying the weak null condition, which can be regarded as a simplified model for the Einstein vacuum equations. The main objective is to establish precise pointwise decay estimates, as both lower and upper bounds of decay, for small data solutions. Specifically, we show that the difference between the solution and its leading-order term is dominated by lower-order terms that decay faster in the retarded time variable $u=t-r$. Moreover, we prove that these pointwise decay estimates are sharp for a generic class of small initial data decaying sufficiently fast.
  As applications of these estimates, we demonstrate that the energy of one component of the solution admits a lower bound that generically grows to infinity as $t\to +\infty$, which can be interpreted as ``blowing up at infinity." Furthermore, we verify that this component generically exhibits an energy cascade from high to low frequencies.

</details>


### [14] [The regularity of the boundary of vortex patches for the quasi-geostrophic shallow-water equations](https://arxiv.org/abs/2602.22767)
*Marc Maga√±a,Joan Mateu,Joan Orobitg*

Main category: math.AP

TL;DR: The paper proves that vortex patches maintain smooth boundaries in the quasi-geostrophic shallow-water equations and shows convergence to Euler solutions as the Rossby radius parameter approaches zero.


<details>
  <summary>Details</summary>
Motivation: The QGSW equations generalize the Euler equations with an additional parameter (Rossby radius), and understanding the persistence of boundary smoothness for vortex patches in this more complex system is important for geophysical fluid dynamics applications.

Method: The authors use mathematical analysis techniques to prove two main results: 1) persistence of boundary smoothness for vortex patches in QGSW equations, and 2) convergence of QGSW solutions to Euler solutions as Œµ‚Üí0 in little H√∂lder spaces.

Result: Two key results: 1) Boundary smoothness of vortex patches is preserved for QGSW equations, and 2) QGSW solutions converge locally in time to Euler solutions as the Rossby radius parameter Œµ‚Üí0 in little H√∂lder spaces.

Conclusion: The QGSW equations maintain important regularity properties similar to Euler equations, and they properly reduce to Euler equations in the limit of large Rossby radius, establishing a rigorous mathematical connection between these fluid models.

Abstract: We prove the persistence of boundary smoothness of vortex patches for the quasi-geostrophic shallow-water (QGSW) equations. The QGSW equations generalize the Euler equations by including an additional parameter, the Rossby radius $\varepsilon^{-1}$, which modifies the relationship between the streamfunction and the (potential) vorticity. In addition, we prove that solutions of the QGSW equations converge locally in time to the corresponding Euler solutions as $\varepsilon \to 0$ in little H√∂lder spaces.

</details>


### [15] [Long finite time bubble trees for two co-rotational wave maps](https://arxiv.org/abs/2602.22825)
*Joachim Krieger,Jos√© M. Palacios*

Main category: math.AP

TL;DR: The paper constructs n-bubble solutions for the energy critical Wave Maps equation in co-rotational setting, showing arbitrarily large numbers of concentrating concentric bubbles with alternating signs.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that all cases postulated in the soliton resolution theorem for finite time blow-up indeed occur, specifically showing that concentric collapsing bubbles with alternating signs can form arbitrarily large numbers of bubble profiles.

Method: Construct n-bubble solutions for the energy critical Wave Maps equation from ‚Ñù¬≤‚Å∫¬π into ùïä¬≤ in k=2 co-rotational setting, with bubbles concentrating at scales Œª‚ÇÅ(t) ‚â´ Œª‚ÇÇ(t) ‚â´ ... ‚â´ Œª‚Çô(t), where Œª‚Çô(t) = t‚Åª¬π|log t|·µù and Œª‚±º(t) ‚â≥ exp(‚à´‚Çú·µó‚Å∞ Œª‚±º‚Çä‚ÇÅ(s)ds) for j < n.

Result: Successfully constructed arbitrarily large numbers of concentrating concentric n-bubble profiles with alternating signs, where Œ≤ > 3/2 can be chosen arbitrarily, demonstrating the full range of finite time blow-up scenarios predicted by soliton resolution theorem.

Conclusion: The entire spectrum of finite time blow-up cases postulated in the soliton resolution theorem indeed occurs for the energy critical Wave Maps equation, provided the concentric collapsing bubbles have alternating signs, establishing the existence of arbitrarily complex multi-bubble blow-up solutions.

Abstract: We show that the energy critical Wave Maps equation from $\mathbb{R}^{2+1}$ into $\mathbb{S}^2$, restricted to the $k=2$ co-rotational setting, admits arbitrarily large numbers of concentrating concentric $n$ bubble profiles. For any $n\in\mathbb{N}$, we construct an $n$-bubble solution concentrating at scales $Œª_1(t)\gg Œª_2(t)\gg \ldots\gg Œª_n(t)$, where $Œª_n(t)=t^{-1}\vert \log t\vert^Œ≤$, and $Œª_j(t)\gtrsim \exp( \int_t^{t_0} Œª_{j+1}(s)ds)$, for any $j<n$. Here $Œ≤>\tfrac32$ is a parameter that can be chosen arbitrarily. This shows that, as far as finite time blow-up case is concerned, the entirety of cases postulated in the soliton resolution theorem indeed occur, provided the concentric collapsing bubbles have alternating signs.

</details>


### [16] [Long-time propagation of coherent states in a normally hyperbolic setting](https://arxiv.org/abs/2602.22834)
*Rom√©o Taboada*

Main category: math.AP

TL;DR: Extends semiclassical coherent state evolution beyond the logarithmic time barrier by combining WKB states in hyperbolic directions with squeezed states along slow invariant submanifolds.


<details>
  <summary>Details</summary>
Motivation: Previous work (Combescure and Robert) showed coherent states can be approximated by squeezed states only up to times |t| ‚â§ |log h|/(6Œª‚ÇÄ). Need to extend validity to longer times (e.g., Ehrenfest time |log h|/(2Œª‚ÇÄ)) when wavepackets spread to macroscopic scales.

Method: Work near a normally hyperbolic invariant submanifold K where dynamics is slow along K and hyperbolic in transverse directions. Represent propagated state as WKB state in transverse (hyperbolic) directions and squeezed state along K. This yields wavefunctions microlocalized on isotropic submanifolds rather than points.

Result: Obtains representation of propagated coherent states valid up to times |t| ‚â§ C|log h| with larger C (e.g., Ehrenfest time). Shows evolved states should be viewed as microlocalized on isotropic submanifolds corresponding to transverse unstable directions.

Conclusion: For longer semiclassical evolution times, propagated coherent states require hybrid WKB-squeezed representations that account for anisotropic spreading, with microlocalization shifting from points to isotropic submanifolds in phase space.

Abstract: We present a method to find asymptotics for the evolution of coherent states (or Gaussian wavepackets with standard deviation $\sqrt{h}$) under semiclassical Schr√∂dinger's equation for a given Hamiltonian. These results extend the work of Combescure and Robert, in which the evolution of coherent states can be approximated in the limit $h\to 0$ with deformed Gaussian wavepackets called squeezed coherent states. The description with squeezed states holds for times $t$ that can go to infinity as $h\to 0$, under the constraint $|t|\leq |\log h|/(6Œª_0)$ where $Œª_0$ is the maximal Lyapunov exponent of the classical dynamics. The breakdown of this approximation at time $|\log h|/(6Œª_0)$ is related to the bending of evolved wavepackets: once propagated states spread at a scale $h^{1/3}$, squeezed states no longer provide an appropriate description. To obtain a representation of propagated states valid up to times $|t|\leq C|\log h|$ with a larger $C$ (for instance, up to Ehrenfest's time $|\log h|/(2Œª_0)$ where spreading on macroscopic scales is allowed), we make additional assumptions on the flow $Œ¶_t$ associated to the classical dynamics, imposing constraints on directions of elongation. Namely, we work in a neighborhood of a normally hyperbolic $Œ¶_t$-invariant submanifold $K$, on which the dynamics is considered as slow in comparison with its transverse directions, along which $Œ¶_t$ is assumed to be hyperbolic. In this context, we describe the propagated state as a WKB state in transverse directions and a squeezed state along $K$. This description emphasizes the fact that propagated states should no longer be thought of as microlocalized on a point, but rather on an isotropic submanifold (corresponding to transverse unstable directions). Guillemin, Uribe, and Wang presented a similar class of wavefunctions microlocalized on an isotropic submanifold.

</details>


### [17] [Orbital stability of monostable waves for reaction-diffusion systems](https://arxiv.org/abs/2602.22907)
*Louis Gar√©naux*

Main category: math.AP

TL;DR: Proves convergence to shifted profiles for monostable waves with weakly localized perturbations using resolvent kernel estimates, handling cases where translational eigenvalue isn't associated with Evans function zeros.


<details>
  <summary>Details</summary>
Motivation: To establish stability results for monostable reaction-diffusion waves under optimal topology conditions, particularly when dealing with weakly localized perturbations and cases where traditional Evans function approaches have limitations.

Method: Uses explicit resolvent kernel estimates to handle weakly localized perturbations, enabling phase shift construction even when translational eigenvalue isn't associated with Evans function zeros. Distinguishes between Evans and Fourier eigenmodes for marginal group velocities directed toward wave interface.

Result: Proves convergence to shifted wave profiles when initial conditions are close to fast wave profiles in optimal topology, establishing stability results for monostable waves with weakly localized perturbations.

Conclusion: The approach provides a robust framework for analyzing stability of monostable waves, overcoming limitations of Evans function methods and handling cases with directed marginal group velocities toward the wave interface.

Abstract: We study stability of monostable waves for reaction-diffusion systems. When the solution is initially close to a fast wave profile in optimal topology, we prove convergence to a shifted profile. The proof relies on explicit resolvent kernels estimates, allowing to handle weakly localized perturbations. It allows phase shift construction even when the translational eigenvalue is not associated to a zero of the Evans function.
  We further discuss distinction between Evans and Fourier eigenmodes when the marginal group velocity are directed towards the wave interface.

</details>


### [18] [Optimal sets for a geometric oscillation energy](https://arxiv.org/abs/2602.22910)
*Matteo Novaga,Fumihiko Onoue,Emanuele Paolini*

Main category: math.AP

TL;DR: Study of nonlocal energy based on p-oscillation of normal/tangent vectors for hypersurfaces/curves, establishing optimal geometric inequalities and characterizing extremal shapes under constraints.


<details>
  <summary>Details</summary>
Motivation: To understand geometric properties of hypersurfaces and curves through a nonlocal energy functional that measures oscillation of their normal/tangent vectors, aiming to establish optimal inequalities and characterize extremal configurations.

Method: Analyze the p-oscillation energy functional, solve variational problems over probability measures on spheres to determine optimal constants, prove existence of optimal sets under perimeter and volume constraints, and characterize their geometric shapes.

Result: Established geometric inequalities with optimal constants c(n,p) and C(n,p) determined by variational problems on sphere measures, proved existence of optimal sets under constraints, and characterized extremal shapes that depend critically on p value.

Conclusion: The p-oscillation energy provides a meaningful geometric functional with optimal inequalities, where extremal measures and optimal shapes exhibit critical dependence on parameter p, offering insights into geometric optimization problems.

Abstract: We investigate the nonlocal energy corresponding to the $p$-oscillation of the unit normal vector for hypersurfaces, or the unit tangent vector for curves. The energy satisfies geometric inequalities with optimal constants $c(n,p)$ and $C(n,p)$ which are determined by a variational problem over the probability measures on the sphere. The extremal measures for such problem depend critically on the value of $p$. We prove existence of optimal sets for this energy under perimeter and volume constraint, and characterize their shape.

</details>


### [19] [Refined wave breaking for the generalized Fornberg-Whitham equation](https://arxiv.org/abs/2602.22924)
*Jean-Claude Saut,Yuexun Wang*

Main category: math.AP

TL;DR: The paper studies blow-up solutions for weakly dispersive perturbations of the inviscid Burgers equation, constructing a specific blowup solution with wave breaking singularity at a single point that converges to a stable self-similar Burgers solution.


<details>
  <summary>Details</summary>
Motivation: To refine understanding of finite-time blow-up (shock formation) in non-local equations that are weakly dispersive perturbations of the inviscid Burgers equation, particularly focusing on the Fornberg-Whitham equation as a special case.

Method: Constructs a blowup solution that exhibits 'wave breaking' singularity at a single point, analyzes its asymptotic convergence in self-similar variables to a stable self-similar solution of the inviscid Burgers equation, and examines its regularity properties.

Result: Successfully constructs a blowup solution with shock-like singularity at one point, demonstrates its asymptotic convergence to a stable self-similar Burgers solution, and shows it possesses H√∂lder C^{1/3} regularity at the blowup point.

Conclusion: The work provides precise characterization of blow-up behavior in weakly dispersive Burgers perturbations, showing how solutions develop wave breaking singularities while maintaining specific regularity and converging to stable self-similar profiles of the inviscid Burgers equation.

Abstract: This paper considers a class of non-local equations that are weakly dispersive perturbations of the inviscid Burgers equation, which includes the Fornberg-Whitham equation as a special case. We precise the known results on finite time blow-up (shock formation) by constructing a blowup solution which displays a `shock-like' singularity (called wave breaking) at one single point. Moreover, this solution converges asymptotically in the self-similar variables to a stable self-similar solution of the inviscid Burgers equation, and also possesses a H√∂lder $C^{1/3}$ regularity at the blowup point.

</details>


### [20] [Blow-Up Theory and Liouville-Type Theorem for Solutions of a Class of Generalized Camassa-Holm-Kadomtsev-Petviashvili Equations](https://arxiv.org/abs/2602.22933)
*Xueli Ke,Jiamin Wang,Aibin Zang*

Main category: math.AP

TL;DR: The paper studies blow-up behavior and Liouville-type theorems for generalized CH-KP equations with nonlinear term g(u), establishing blow-up criteria, weighted blow-up results, and uniqueness theorems under various conditions on g(u).


<details>
  <summary>Details</summary>
Motivation: To understand the blow-up behavior and establish Liouville-type theorems for solutions to generalized Camassa-Holm-Kadomtsev-Petviashvili (CH-KP) equations with general nonlinear terms, extending results beyond classical cases.

Method: Uses continuation method for blow-up criterion independent of initial data regularity. Employs characteristic lines, a priori estimates, and Riccati inequality for blow-up theorems. Extends results to polynomially controlled g'(u) and establishes Liouville-type uniqueness theorem.

Result: Established blow-up criterion independent of initial data regularity. Proved blow-up theorem and weighted blow-up result for uniformly bounded g'(u). Extended results to polynomially controlled g'(u) including classical CH-KP nonlinearities. Established Liouville-type uniqueness theorem under condition g(u) ‚â• Œ≥u¬≤ with g(u) > Œ≥u¬≤ for u ‚â† 0.

Conclusion: The paper provides comprehensive analysis of blow-up behavior and uniqueness properties for generalized CH-KP equations, establishing important criteria and theorems that apply to broad classes of nonlinear terms including classical CH-KP cases.

Abstract: We investigate the blow-up behavior and Liouville-type theorems of solutions to a class of generalized Camassa-Holm-Kadomtsev-Petviashvili (CH-KP) equations with a generally smooth nonlinear term $g(u)$. First, using the continuation method, we establish a blow-up criterion that is independent of the regularity index of initial data. Under the assumption that $ g'(u)$ is uniformly bounded, we prove the blow-up theorem and a weighted blow-up result by means of characteristic lines, a priori estimates and the Riccati inequality. Moreover, we extend these blow-up results to the setting where $g'(u)$ is polynomially controlled, which includes typical nonlinearities such as $ g(u)=Œ∫u+3u^2 $ for the classical CH-KP equations. Furthermore, a Liouville-type uniqueness theorem is established under the condition $g(u) \geq Œ≥u^2$ with $u \neq 0$, $g(u)>Œ≥u^2$.

</details>


### [21] [Local boundedness for weak solutions to fractional porous medium equation](https://arxiv.org/abs/2602.23001)
*Filomena De Filippis*

Main category: math.AP

TL;DR: Local boundedness established for fractional porous medium-type equations in fast diffusion regime with optimal tail assumptions.


<details>
  <summary>Details</summary>
Motivation: To extend regularity theory for fractional porous medium equations, particularly addressing the fast diffusion case where solutions may exhibit different behavior than slow diffusion regimes.

Method: Analysis of fractional porous medium-type equations using techniques from nonlocal PDEs, focusing on the fast diffusion regime and establishing local boundedness under minimal tail conditions.

Result: Proves local boundedness for solutions to fractional porous medium-type equations in fast diffusion regime, achieving optimal tail assumptions for the result.

Conclusion: The paper establishes fundamental regularity properties for fractional porous medium equations in fast diffusion, providing optimal conditions for local boundedness that extend previous results.

Abstract: We establish local boundedness for solutions to fractional porous medium-type equations in the fast diffusion regime, under optimal tail assumptions.

</details>


### [22] [Unique Determination of Variable Order in Subdiffusion from a Single Measurement](https://arxiv.org/abs/2602.23037)
*Jiho Hong,Bangti Jin,Yavar Kian*

Main category: math.AP

TL;DR: Unique recovery of piecewise constant variable orders in time-fractional diffusion from boundary flux measurement without monotonicity assumptions.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the inverse problem of identifying heterogeneous media in anomalous diffusion processes by recovering spatially dependent variable orders from boundary measurements. This has applications in material characterization and diffusion modeling.

Method: Combines properties of harmonic functions, linearization technique in the Laplace domain, and tools from complex, asymptotic, and geometrical analysis. Focuses on piecewise constant variable orders without monotonicity conditions.

Result: Establishes several new uniqueness results for the inverse problem, weakens regularity assumptions on problem data, and extends analysis to higher-dimensional settings.

Conclusion: The approach successfully demonstrates unique identifiability of piecewise constant variable orders in time-fractional diffusion models from single boundary excitation measurements, advancing the theoretical foundation for heterogeneous media identification.

Abstract: We study the inverse problem of recovering a spatially dependent variable order in a time-fractional diffusion model from the boundary flux measurement generated by a single boundary excitation. It arises in the identification of heterogeneous media in anomalous diffusion processes. In this work, we establish several new uniqueness results for the inverse problem in the case of piecewise constant variable orders, without any monotonicity condition. The analysis follows a new approach that combines properties of harmonic functions, a linearization technique in the Laplace domain, and tools from complex, asymptotic, and geometrical analysis. In addition, we weaken the regularity assumptions on the problem data and extend the analysis of previous contributions to higher-dimensional settings.

</details>


### [23] [A Single Equation Explains Go-or-Grow Dynamics in Cyclic Hypoxia](https://arxiv.org/abs/2602.23042)
*Gopinath Sadhu,Philip K Maini,Mohit Kumar Jolly*

Main category: math.AP

TL;DR: A minimal mathematical framework describes tumor cell go-or-grow dynamics with two phenotypes: migratory (diffusive) and proliferative (oxygen-dependent). The model connects distinct phenotypic populations to a reduced single-population model with oxygen-dependent diffusion and proliferation under fast phenotypic switching.


<details>
  <summary>Details</summary>
Motivation: To develop a minimal mathematical framework that captures the essential dynamics of tumor cell go-or-grow behavior, where cells switch between migratory and proliferative phenotypes based on oxygen availability, and to explore whether this two-population model can be reduced to a simpler single-population formulation.

Method: Proposes a mathematical model with two coupled phenotype-specific equations: one for migratory cells undergoing linear diffusion, and another for proliferative cells with oxygen-dependent proliferation. Local oxygen concentration governs phenotype transitions. The study investigates whether these equations can be reduced to a single mixed-phenotype equation under cyclic hypoxia conditions.

Result: Establishes a connection between the minimal go-or-grow model with distinct phenotypic populations and a reduced model describing a single-cell population with oxygen-dependent diffusion and proliferation in the fast-phenotypic-switching regime. The theoretical reduction is validated through numerical simulations.

Conclusion: The study demonstrates that complex go-or-grow dynamics with distinct phenotypic populations can be mathematically reduced to a simpler single-population model with oxygen-dependent parameters under fast phenotypic switching, providing a theoretical foundation for simplified modeling of tumor cell behavior.

Abstract: We propose a minimal mathematical framework to describe the go-or-grow dynamics of tumor cells comprising two phenotypically distinct populations. One population is migratory and undergoes linear diffusion, while the other proliferates in an oxygen-dependent manner. The local oxygen concentration governs transitions between these phenotypes. We then ask whether these two coupled phenotype-specific equations can be reduced to a single mixed-phenotype equation under cyclic hypoxia. We establish a connection between the minimal go-or-grow model with distinct phenotypic populations and a reduced model describing a single-cell population with oxygen-dependent diffusion and proliferation in the fast-phenotypic-switching regime. This theoretical reduction is validated through numerical simulations.

</details>


### [24] [Local Invariant Structures in the Dynamics of Capillary Water Jet](https://arxiv.org/abs/2602.23064)
*Chengyang Shao,Haocheng Yang*

Main category: math.AP

TL;DR: The paper mathematically proves the Rayleigh-Plateau instability phenomenon for capillary water jets, showing that long-wave perturbations lead to exponential instability while short-wave perturbations remain stable, confirming experimental observations through rigorous analysis of Eulerian free-boundary systems.


<details>
  <summary>Details</summary>
Motivation: To provide mathematical justification for experimental observations of the Rayleigh-Plateau instability in capillary water jets, where long-wave perturbations cause exponential instability while short-wave perturbations remain stable, and to answer Lin-Zeng's question about invariant manifolds for Eulerian free-boundary systems.

Method: Models water jet motion using irrotational Eulerian free-boundary system governed by surface tension. Proves that (un)stable directions in linearized system correspond to invariant manifolds in nonlinear system. Major innovation: constructs "paradifferential propagator" for linear paradifferential hyperbolic systems along elliptic directions, enabling Lyapunov-Perron type arguments while balancing regularity loss in quasilinear problems.

Result: Successfully proves that long-wave perturbations correspond to (un)stable invariant manifolds in the full nonlinear system, while short-wave perturbations correspond to center invariant sets. This mathematically justifies experimental observations of Rayleigh-Plateau instability and answers Lin-Zeng's question positively.

Conclusion: The paper provides rigorous mathematical foundation for Rayleigh-Plateau instability phenomenon, demonstrating how invariant manifold theory applies to Eulerian free-boundary systems. The paradifferential propagator method effectively handles quasilinear regularity issues and can be generalized to broader classes of PDEs.

Abstract: Physical experiments show that a capillary water jet is exponentially unstable under long-wave perturbations, while remaining stable under short-wave perturbations. Measurements further indicate that the exponential growth rate in the long-wave regime agrees quantitatively with the classical predictions of Rayleigh and Plateau. This phenomenon is known as the \emph{Rayleigh-Plateau instability}. In this paper, we provide a mathematical justification of these experimental observations. The motion of the water jet is modeled by an irrotational Eulerian free-boundary system governed by surface tension. We prove that the (un)stable directions in the linearized system, corresponding to long-wave perturbations, are indeed tangent to an (un)stable invariant manifold of the full nonlinear system. On the other hand, the elliptic directions, corresponding to short-wave perturbations, are indeed tangent to a center invariant set in a generalized sense. These results give a positive answer to the question raised by Lin-Zeng concerning the existence of invariant manifolds for Eulerian free-boundary systems. The major methodological contribution is the construction of ``paradifferential propagator" corresponding to linear paradifferential hyperbolic systems along elliptic directions, making Lyapunov-Perron type arguments applicable. The method effectively balances the loss of regularity in quasilinear problems and can be generalized to a broader class of PDEs.

</details>


### [25] [Viscous vortex crystals](https://arxiv.org/abs/2602.23134)
*Michele Dolce,Martin Donati*

Main category: math.AP

TL;DR: Analysis of 2D Navier-Stokes solutions from co-rotating vortex crystals, controlling solutions up to sub-diffusive timescales before vortex merging.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of incompressible Navier-Stokes equations with initial conditions consisting of Dirac masses in co-rotating vortex crystal configurations, particularly studying how these vortex structures evolve before they merge.

Method: Exploiting symmetries and stability properties of the system to describe and control solutions. Focuses on polygonal vortex crystals with or without a central vortex, analyzing their evolution up to sub-diffusive time scales.

Result: Successfully describes and controls the solution up to sub-diffusive time scales prior to the expected onset of vortex merging, providing insight into the intermediate dynamics of vortex crystals.

Conclusion: The study demonstrates that co-rotating vortex crystal configurations in 2D Navier-Stokes equations can be analytically controlled for extended time periods before merging occurs, revealing important stability properties of these symmetric vortex arrangements.

Abstract: We study the solution to the two-dimensional incompressible Navier-Stokes equations arising from a sum of Dirac masses in a particular co-rotating configuration. This configuration consists of a polygonal vortex crystal with or without a central vortex. By exploiting the symmetries and stability properties of the system, we describe and control the solution up to sub-diffusive time scales, prior to the expected onset of vortex merging.

</details>


### [26] [Remarks on the Pogorelov type estimate for the degenerate $k$-Hessian equation](https://arxiv.org/abs/2602.23185)
*Yasheng Lyu*

Main category: math.AP

TL;DR: The paper establishes a Pogorelov-type estimate for the k-Hessian equation under new conditions on the degenerate right-hand side function f.


<details>
  <summary>Details</summary>
Motivation: To extend Pogorelov-type estimates to k-Hessian equations with degenerate right-hand sides, addressing regularity issues in fully nonlinear elliptic equations.

Method: Develops new analytical techniques and conditions for the degenerate function f to derive Pogorelov-type interior estimates for k-Hessian equations.

Result: Obtains Pogorelov-type estimates under the new condition on f, extending previous results to more general degenerate cases.

Conclusion: The new condition on f enables Pogorelov-type estimates for k-Hessian equations, contributing to regularity theory for degenerate fully nonlinear elliptic equations.

Abstract: This paper investigates the Pogorelov type estimate for the $k$-Hessian equation under a new condition on the degenerate right-hand side $f$.

</details>


### [27] [Low-Mach-number limit of a compressible two-phase flow system with algebraic closure](https://arxiv.org/abs/2602.23189)
*Cassandre Lebot*

Main category: math.AP

TL;DR: Analysis of low Mach number limit for bi-fluid compressible Navier-Stokes system showing convergence to incompressible non-homogeneous fluid system with transported volume fractions.


<details>
  <summary>Details</summary>
Motivation: To rigorously analyze the low Mach number limit for a bi-fluid isentropic compressible Navier-Stokes system with equal pressure and single velocity, establishing convergence from compressible to incompressible regime.

Method: Introduction of suitable modulated quantities and novel relative entropy functional adapted to two-phase structure, with original comparison of L1 and L2 norms of partial densities using special bi-fluid structure and variant of Csiszar-Kullback-Pinsker inequality.

Result: As Mach number tends to zero, partial densities converge to constant states, velocity field converges to divergence-free vector field, recovering incompressible non-homogeneous fluid system with nontrivial volume fractions transported by limit flow.

Conclusion: The method rigorously justifies convergence of weak solutions of compressible system toward solutions of corresponding incompressible limit system in low Mach number regime for bi-fluid two-phase framework.

Abstract: We analyse a bi-fluid isentropic compressible Navier-Stokes system with barotropic pressure laws in a two-phase framework with equal pressure and single velocity. We focus on the rigorous analysis of the low Mach number limit under well-prepared initial data. Our main result shows that, as the Mach number tends to zero, the partial densities converge to constant states while the velocity field converges to a divergence-free vector field, and we recover the incompressible non-homogenous fluid system. The volume fractions remain nontrivial and are transported by the limit flow. Our method is based on the introduction of suitable modulated quantities and a novel relative entropy functional adapted to the two-phase structure. The key novelty lies in an original comparison of L1 and L2 norms of the partial densities, exploiting the special structure of the bi-fluid system, together with a variant of Csiszar-Kullback- Pinsker inequality. It allows us to rigorously justify the convergence of weak solutions of the compressible system toward solutions of the corresponding incompressible limit system in the low Mach number regime.

</details>


### [28] [Properties of hypersurface singular sets of solutions to the $œÉ_k$-Yamabe equation in the negative cone](https://arxiv.org/abs/2602.23190)
*Jonah A. J. Duncan,Luc Nguyen*

Main category: math.AP

TL;DR: The paper studies conformally flat Lipschitz viscosity solutions to the œÉ_k-Yamabe equation with smooth hypersurface singularities, establishing PDE conditions for trace/normal derivatives and showing minimality of hypersurfaces for k=2.


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand the behavior of solutions to the œÉ_k-Yamabe equation near singular hypersurfaces, particularly in the negative cone case, which arises naturally in geometric problems like the œÉ_k-Loewner-Nirenberg problem on annuli.

Method: The authors use conformal geometry and PDE techniques to analyze Lipschitz viscosity solutions with smooth hypersurface singularities. They first prove that under natural regularity assumptions, the trace and normal derivatives satisfy a specific PDE. For k=2, they employ additional geometric analysis to show minimality of the hypersurface and study formal expansions near the singularity.

Result: 1) For solutions with smooth hypersurface singularities, the trace and normal derivatives satisfy a certain PDE. 2) For k=2, the hypersurface is minimal with respect to the Lipschitz solution. 3) The paper addresses questions about formal expansions of solutions near hypersurfaces.

Conclusion: The work provides important insights into the structure of singular solutions to œÉ_k-Yamabe equations, establishing connections between the PDE behavior at singularities and geometric properties of the hypersurfaces, particularly minimality in the k=2 case.

Abstract: We consider conformally flat Lipschitz viscosity solutions to the $œÉ_k$-Yamabe equation in the negative cone which admit smooth hypersurface singularities. Under natural regularity assumptions (that are satisfied by solutions to the $œÉ_k$-Loewner-Nirenberg problem on annuli, for example), we first prove that the trace and normal derivatives of such a solution along the hypersurface satisfy a certain PDE. For $k=2$, we also show that the hypersurface is minimal with respect to the Lipschitz solution and address some questions related to the formal expansion of the solution near the hypersurface.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [29] [Adaptive Patching for Tensor Train Computations](https://arxiv.org/abs/2602.22372)
*Gianluca Grosso,Marc K. Ritter,Stefan Rohshap,Samuel Badr,Anna Kauch,Markus Wallerberger,Jan von Delft,Hiroshi Shinaoka*

Main category: physics.comp-ph

TL;DR: Adaptive patching scheme for Quantics Tensor Train (QTT) that exploits block-sparse structures to reduce computational costs for large bond dimensions through divide-and-conquer partitioning.


<details>
  <summary>Details</summary>
Motivation: QTT operations like matrix product operator contractions become prohibitively expensive for large bond dimensions, limiting practical large-scale QTT-based computations.

Method: Adaptive patching scheme that exploits block-sparse QTT structures, using divide-and-conquer approach to partition tensors into smaller patches with reduced bond dimensions.

Result: Demonstrated substantial improvements for sharply localized functions and showed efficient computation of bubble diagrams and Bethe-Salpeter equations.

Conclusion: The method opens the door to practical large-scale QTT-based computations that were previously beyond reach due to computational cost limitations.

Abstract: Quantics Tensor Train (QTT) operations such as matrix product operator contractions are prohibitively expensive for large bond dimensions. We propose an adaptive patching scheme that exploits block-sparse QTT structures to reduce costs through divide-and-conquer, adaptively partitioning tensors into smaller patches with reduced bond dimensions. We demonstrate substantial improvements for sharply localized functions and show efficient computation of bubble diagrams and Bethe-Salpeter equations, opening the door to practical large-scale QTT-based computations previously beyond reach.

</details>


### [30] [Discovery of Interpretable Physical Laws in Materials via Language-Model-Guided Symbolic Regression](https://arxiv.org/abs/2602.22967)
*Yifeng Guan,Chuyi Liu,Dongzhan Zhou,Lei Bai,Wan-jian Yin,Jingyuan Li,Mao Su*

Main category: physics.comp-ph

TL;DR: A framework using large language models to guide symbolic regression for discovering interpretable physical laws from high-dimensional data, validated on perovskite materials with 10^5 reduction in search space.


<details>
  <summary>Details</summary>
Motivation: Traditional symbolic regression methods often produce complex, unphysical formulas when searching vast spaces of possible forms for physical laws from high-dimensional data.

Method: A framework that leverages the embedded scientific knowledge of large language models to guide the search process for identifying physical laws efficiently.

Result: Reduced effective search space by ~10^5 factor, identified novel formulas for perovskite properties (bulk modulus, band gap, oxygen evolution reaction activity) that outperform previous formulas in accuracy and simplicity.

Conclusion: The LLM-guided approach successfully discovers interpretable physical laws, mitigates combinatorial explosion in symbolic regression, and provides meaningful physical insights while improving accuracy and simplicity.

Abstract: Discovering interpretable physical laws from high-dimensional data is a fundamental challenge in scientific research. Traditional methods, such as symbolic regression, often produce complex, unphysical formulas when searching a vast space of possible forms. We introduce a framework that guides the search process by leveraging the embedded scientific knowledge of large language models, enabling efficient identification of physical laws in the data. We validate our approach by modeling key properties of perovskite materials. Our method mitigates the combinatorial explosion commonly encountered in traditional symbolic regression, reducing the effective search space by a factor of approximately $10^5$. A set of novel formulas for bulk modulus, band gap, and oxygen evolution reaction activity are identified, which not only provide meaningful physical insights but also outperform previous formulas in accuracy and simplicity.

</details>


### [31] [Ceci n'est pas un committor, yet it samples like one: efficient sampling via approximated committor functions](https://arxiv.org/abs/2602.23236)
*Enrico Trizio,Giorgia Rossi,Michele Parrinello*

Main category: physics.comp-ph

TL;DR: Simplified committor-based enhanced sampling method using descriptor-space learning criterion, avoiding costly coordinate gradients while maintaining robust sampling performance.


<details>
  <summary>Details</summary>
Motivation: Original committor-based enhanced sampling method requires neural networks trained with computationally expensive gradients with respect to atomic coordinates, limiting practical applications for complex reactive processes.

Method: Propose simplified learning criterion formulated entirely in descriptor space, bypassing explicit coordinate gradients. This provides relaxed upper bound to original variational principle while retaining sampling performance.

Result: New approach significantly reduces computational costs while maintaining robust sampling performance, enabling study of processes that would be unfeasible with original formulation.

Conclusion: Descriptor-space learning criterion offers practical alternative to exact committor learning, making enhanced sampling more accessible for complex reactive processes without sacrificing sampling effectiveness.

Abstract: Atomistic simulations are widely used to investigate reactive processes but are often limited by the rare event problem due to kinetic bottlenecks. We recently introduced an enhanced sampling approach based on the committor function, machine-learned following a variational principle. This method combines a transition-state-oriented bias potential, expressed as a functional of the committor, with a metadynamics-like bias along a committor-based collective variable, enabling uniform exploration of reaction pathways. In its original formulation, the committor is represented by a neural network that takes physical descriptors as input and is trained by minimizing a functional involving gradients with respect to atomic coordinates, which can be computationally demanding in some cases. Here, we propose a simplified learning criterion formulated entirely in the descriptor space, which bypasses the need for explicit and costly coordinate gradients and provides a relaxed upper bound to the original variational principle. Although this approach does not formally target the exact committor, we show that it retains robust sampling performance while significantly reducing computational costs, thus enabling the study of processes that would be practically unfeasible using the original formulation.

</details>


### [32] [mrfmsim: a modular, extendable, and readable simulation platform for magnetic resonance force microscopy experiments](https://arxiv.org/abs/2602.23337)
*Peter Sun,Corinne E. Isaac,Michael C. Boucher,Eric W. Moore,Zhen Wang,John A. Marohn*

Main category: physics.comp-ph

TL;DR: mrfmsim is an open-source package for designing, simulating, and validating magnetic resonance force microscopy experiments using DAGs with flexible post-definition customization.


<details>
  <summary>Details</summary>
Motivation: To address challenges in building simulation packages for continuously evolving experiments in graduate research settings, particularly overcoming issues with one-off approaches that yielded erroneous results.

Method: Uses directed acyclic graphs (DAGs) to model experiments with a plugin system for adding custom experiments and functionalities, allowing flexible customization post-definition without rewriting internal models.

Result: The modular, extendable, and readable platform enabled correct results and significantly accelerated development cycles compared to previous one-off approaches.

Conclusion: mrfmsim provides an effective solution for MRFM experiment simulation that addresses the challenges of continuous development in research environments through its flexible DAG-based architecture.

Abstract: We present mrfmsim, an open-source package that facilitates the design, simulation, and signal validation of magnetic resonance force microscopy experiments. The mrfmsim package uses directed acyclic graphs (DAGs) to model experiments and employs a plugin system that enables adding custom experiments and functionalities. Unlike common DAG-powered workflow packages, mrfmsim allows flexible customization of experiments post-definition, such as optimized looping, without requiring rewriting the internal model. In this paper, we highlight the challenges of building simulation packages for experiments that undergo continuous development in a graduate research setting. We demonstrate how a one-off approach to experimental simulation yielded erroneous results, and how the modularity, extendibility, and readability of the new platform enabled correct results and a significantly accelerated development cycle.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [33] [The Effect of Magnetization on Electron Heating in Low-Density Ultracold Neutral Plasmas](https://arxiv.org/abs/2602.22370)
*Ryan C. Baker,Bridget O'Mara,Jacob L. Roberts*

Main category: physics.plasm-ph

TL;DR: Study examines electron heating mechanisms in ultracold magnetized plasmas, finding disorder-induced heating persists throughout plasma lifetime and achieving record-low electron temperatures of 0.52K.


<details>
  <summary>Details</summary>
Motivation: Ultracold neutral plasmas enable laboratory study of extreme plasma physics regimes characterized by coupling strength and magnetization. Understanding electron heating mechanisms is crucial for determining achievable coupling strengths.

Method: Used experimentally informed simulations to examine early-lifetime electron heating dominated by disorder-induced heating and Rydberg atom formation in moderately coupled, strongly magnetized plasmas.

Result: Found disorder-induced heating significantly influences electron temperature throughout plasma lifetime. Achieved electron temperatures as low as 0.52K at electron density of 6.1√ó10¬π¬≤ m‚Åª¬≥, determining maximum coupling strength for experimental conditions.

Conclusion: Disorder-induced heating plays a major role in electron temperature evolution in ultracold magnetized plasmas, and the achieved low temperatures define the limits of coupling strength achievable in these experimental systems.

Abstract: Ultracold neutral plasmas provide a useful system for studying extreme parameter regimes plasma physics in an accessible laboratory setting. The parameter space of plasma physics can be characterized in part by coupling strength and degree of magnetization. The range of achievable strong coupling is determined in part by the lowest possible temperatures that can be achieved. This work examines the early-lifetime electron heating of moderately coupled, strongly magnetized plasmas. This heating is dominated by disorder-induced heating and heating due to Rydberg atom formation. By using experimentally informed simulations, it is found that disorder-induced heating has a large influence in electron temperature well into the plasma lifetime. Additionally, the dependence of the minimum achievable electron temperature on magnetization and initial electron energy is examined. In this work, we find electron temperatures as low as $0.52^{+.10}_{-.05}\ \mathrm{K}$ (for electron density, $n_{e}$, of $6.1 \times 10^{12}\ \mathrm{m^{-3}}$), which determines the maximum coupling strength for the measured experimental conditions.

</details>


### [34] [Nonlinear entropy transfer via zonal flows in gyrokinetic plasma turbulence](https://arxiv.org/abs/2602.22653)
*Motoki Nakata,Tomo-Hiko Watanabe,Hideo Sugama*

Main category: physics.plasm-ph

TL;DR: The paper investigates nonlinear entropy transfer processes in toroidal ITG and ETG turbulence using gyrokinetic entropy balance relations, revealing different entropy transfer mechanisms between ITG and ETG turbulence that affect turbulent transport regulation.


<details>
  <summary>Details</summary>
Motivation: To understand how nonlinear entropy transfer processes between zonal and non-zonal modes regulate turbulent transport in toroidal ITG and ETG driven turbulence, which is crucial for plasma confinement in fusion devices.

Method: Uses gyrokinetic entropy balance relations for zonal and non-zonal modes, introduces a "triad" entropy transfer function for spectral analysis, and examines nonlinear interactions through entropy transfer functions as kinetic extensions of zonal-flow production via Reynolds stress.

Result: ITG turbulence shows substantial entropy transfer from non-zonal to zonal modes during saturation phase, but weak transfer in steady state where zonal flows mediate transfer from low-k to high-k non-zonal modes. ETG turbulence shows dominant entropy transfer among low-wavenumber non-zonal modes in both saturation and steady phases.

Conclusion: Different entropy transfer mechanisms exist between ITG and ETG turbulence: ITG turbulence uses zonal flows to cascade entropy to higher wavenumbers for transport regulation, while ETG turbulence relies on direct transfer among low-wavenumber non-zonal modes.

Abstract: Nonlinear entropy transfer processes in toroidal ion temperature gradient (ITG) and electron temperature gradient (ETG) driven turbulence are investigated based on the gyrokinetic entropy balance relations for zonal and non-zonal modes, which are coupled through the entropy transfer function regarded as a kinetic extension of the zonal-flow production due to the Reynolds stress. Spectral analyses of the "triad" entropy transfer function introduced in this study reveal not only the nonlinear interactions among the zonal and non-zonal modes, but also their effects on the turbulent transport level. Different types of the entropy transfer processes between the ITG and ETG turbulence are found: The entropy transfer from non-zonal to zonal modes is substantial in the saturation phase of the ITG instability, while, once the strong zonal flow is generated, the entropy transfer to the zonal modes becomes quite weak in the steady turbulence state. Instead, the zonal flows mediate the entropy transfer from non-zonal modes with low radial-wavenumbers (with contribution to the heat flux) to the other non-zonal modes with higher radial-wavenumbers (but with less contribution to the heat flux) through the triad interaction. The successive entropy transfer processes to the higher radial-wavenumber modes are associated with transport regulation in the steady turbulence state. In contrast, in both the instability-saturation and steady phases of the ETG turbulence, the entropy transfer processes among low-wavenumber non-zonal modes are dominant rather than the transfer via zonal modes.

</details>


### [35] [Isotope Effects on TEM-driven Turbulence and Zonal Flows in Helical and Tokamak Plasmas](https://arxiv.org/abs/2602.22655)
*Motoki Nakata,Masanori Nunami,Hideo Sugama,Tomo-Hiko Watanabe*

Main category: physics.plasm-ph

TL;DR: Isotope ion mass affects TEM turbulence and zonal flows in fusion plasmas, with collisional stabilization and enhanced zonal flows causing transport reduction opposite to conventional gyro-Bohm scaling.


<details>
  <summary>Details</summary>
Motivation: To understand how isotope ion mass influences trapped electron mode (TEM) driven turbulence and zonal flows in magnetically confined fusion plasmas, particularly for hydrogen isotopes in fusion reactors.

Method: First-ever gyrokinetic simulations of TEM-driven turbulence in 3D LHD plasmas with hydrogen isotope ions and real-mass kinetic electrons, analyzing linear and nonlinear isotope and collisional effects.

Result: Combined collisional TEM stabilization by isotope ions and increased steady zonal flow impacts near marginal stability lead to significant transport reduction with opposite ion mass dependence compared to gyro-Bohm scaling.

Conclusion: Isotope effects on TEM turbulence and zonal flows are universal across various toroidal plasma configurations (tokamaks and helical/stellarator systems), revealing important physics for fusion reactor optimization.

Abstract: Impacts of isotope ion mass on trapped electron mode (TEM) driven turbulence and zonal flows in magnetically confined fusion plasmas are investigated. Gyrokinetic simulations of TEM-driven turbulence in three-dimensional magnetic configuration of LHD plasmas with hydrogen isotope ions and real-mass kinetic electrons are realized for the first time, and the linear and the nonlinear nature of the isotope and collisional effects on the turbulent transport and zonal-flow generation is clarified. It is newly found that combined effects of the collisional TEM stabilization by the isotope ions and the associated increase in the impacts of the steady zonal flows at the near-marginal linear stability lead to the significant transport reduction with the opposite ion mass dependence in comparison to the conventional gyro-Bohm scaling. The universal nature of the isotope effects on the TEM-driven turbulence and zonal flows is verified for a wide variety of toroidal plasmas, e.g., axisymmetric tokamak and non-axisymmetric helical/stellarator systems.

</details>


### [36] [Gyrokinetic turbulent transport simulations on steady burning condition in D-T-He plasmas](https://arxiv.org/abs/2602.22656)
*Motoki Nakata,Mitsuru Honda*

Main category: physics.plasm-ph

TL;DR: Gyrokinetic simulations reveal turbulent transport imbalances in ITER-like plasmas, identifying profile regimes that satisfy steady burning conditions with He-ash exhaust and D-T fuel pinch.


<details>
  <summary>Details</summary>
Motivation: To investigate ion temperature gradient (ITG) and trapped electron mode (TEM) driven turbulent transport in ITER-like plasmas, moving beyond conventional zero-dimensional power balance analysis to evaluate steady burning conditions with realistic particle transport.

Method: Multi-species gyrokinetic Vlasov simulations with D, T, He, and real-mass kinetic electrons including inter-species collisions, evaluating steady burning conditions with He-ash exhaust and D-T fuel inward pinch.

Result: Significant imbalance appears in turbulent particle flux for D and T fuel ions depending on D-T density ratio and He-ash accumulation; several profile regimes satisfying Reiter's steady burning condition are identified; impacts of zonal flows and nonthermal He-ash on optimal regimes are examined.

Conclusion: Gyrokinetic simulations successfully demonstrate evaluation of steady burning conditions in ITER-like plasmas, revealing complex turbulent transport dynamics and identifying viable operational regimes for fusion reactors.

Abstract: Ion temperature gradient(ITG) and trapped electron modes(TEM) driven turbulent transport in an ITER-like plasma is investigated by means of multi-species gyrokinetic Vlasov simulations with D, T, He, and real-mass kinetic electrons including their inter-species collisions. Beyond the conventional zero-dimensional power balance analysis presuming the global energy and particle confinement times, gyrokinetic-simulation-based evaluation of a steady burning condition with He-ash exhaust and D-T fuel inward pinch is demonstrated. It is clarified that a significant imbalance appears in the turbulent particle flux for the fuel ions of D and T, depending on the D-T density ratio and the He-ash accumulation. Then several profile regimes to satisfy Reiter's steady burning condition are, for the first time, identified by the gyrokinetic simulation. Also, the impacts of zonal flows and nonthermal He-ash on the optimal profile regimes are examined.

</details>


### [37] [Experimental Demonstration of Beam-Driven Wakefield Acceleration in Laser-Plasma Filament](https://arxiv.org/abs/2602.22841)
*M. Galletti,L. Verra,A. Biagioni,M. Carillo,L. Crincoli,R. Demitra,G. Parise,G. Di Pirro,R. Pompili,F. Stocchi,F. Villa,A. Zigler,M. Ferrario*

Main category: physics.plasm-ph

TL;DR: Experimental demonstration of electron acceleration using laser-generated plasma filaments, achieving >250 MV/m accelerating fields with improved reliability and kHz repetition rate potential.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of conventional plasma wakefield acceleration schemes that rely on mechanically confined or preformed plasma channels, which require more energy and have lower reproducibility due to stochastic breakdown processes.

Method: Using self-guided femtosecond laser pulses propagating in low-pressure gas to generate plasma filaments through intrinsic non-linear light-matter interaction, then performing beam-driven wakefield acceleration of electron bunches in these filaments.

Result: Successful proof-of-principle demonstration with accelerating field exceeding 250 MV/m, excellent agreement with numerical simulations, and complete physical picture of the process.

Conclusion: Laser-based plasma formation offers improved reliability, control, and reproducibility over conventional methods, bridging laser filamentation physics with compact accelerator technologies for sustainable, high-repetition-rate plasma facilities.

Abstract: Self-guided femtosecond laser pulses propagating in low-pressure gas can generate plasma filaments, establishing a new framework for plasma wakefield acceleration. Unlike conventional schemes relying on mechanically confined or preformed plasma channels, this method exploits the intrinsic non-linear light-matter interaction, greatly reducing the energy required to generate plasma. This, in turn, allows to realise tunable stages, potentially operating above kHz repetition rate and with meter-scale interaction lengths and transverse sizes down to a few tens of micrometres. Moreover, the laser-plasma filament reproducibility is intrinsically higher than state-of-the-art discharge-plasmas, where the breakdown process is initiated in a stochastic and uncontrolled manner. As a result, laser-based plasma formation offers improved reliability and control over plasma parameters. Here we report a proof-of-principle experimental demonstration of beam-driven wakefield acceleration of electron bunches with an accelerating field exceeding 250 MV/m in a laser-generated plasma filament. The results are cross-checked with numerical simulation, showing an excellent agreement and providing a complete picture of the physical process. Beyond particle acceleration, the concept bridges laser filamentation physics, advanced plasma photonics and compact accelerator technologies, offering a promising route towards sustainable, high-repetition-rate plasma-based facilities.

</details>


### [38] [Merging of zonal flows in gyrofluid resistive drift-wave turbulence](https://arxiv.org/abs/2602.23007)
*Fabian Grander,Tobias Gr√∂fler,Franz Ferdinand Locker,Manuel Rinner,Alexander Kendl*

Main category: physics.plasm-ph

TL;DR: The paper investigates non-linear dynamics of zonal flows in gyrofluid modified Hasegawa-Wakatani model, focusing on zonal flow merging and chaotic development patterns.


<details>
  <summary>Details</summary>
Motivation: To understand the non-linear dynamics of zonal flows, particularly merging phenomena and chaotic development patterns, which are important for plasma turbulence and transport in fusion devices.

Method: Uses gyrofluid modified Hasegawa-Wakatani model, derives conservation equations for zonal flow momentum and energy with consistent FLR effects, and performs numerical simulations to analyze zonal flow mergers.

Result: Nonlinear local Reynolds stress transfer (rather than viscous dissipation) is identified as the main cause of zonal flow merging. The paper also discusses applicability of phase transition concepts to zonal flow transition hysteresis.

Conclusion: The study provides insights into zonal flow merging dynamics, highlighting the role of Reynolds stress transfer and questioning strict thermodynamic phase transition concepts for zonal flow transitions.

Abstract: Non-linear dynamics of zonal flows is investigated in the context of the gyrofluid modified Hasegawa-Wakatani model. Merging of zonal flows and the chaotic developement of the initial zonal flow pattern is explored. Conservation equations for zonal flow momentum and energy with consistent finite Larmor radius (FLR) effects are derived and used for a quantitative analysis of zonal flow mergers in numerical simulations. The nonlinear local Reynolds stress transfer as opposed to (hyper)viscous dissipation is found to be the main cause of merging. The applicability of the concept of a phase transition in the strict thermodynamical sense is discussed in context of zonal flow transition hysteresis.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [39] [Learning geometry-dependent lead-field operators for forward ECG modeling](https://arxiv.org/abs/2602.22367)
*Arsenii Dokuchaev,Francesca Bonizzoni,Stefano Pagani,Francesco Regazzoni,Simone Pezzuto*

Main category: cs.LG

TL;DR: A shape-informed neural surrogate model for fast, accurate ECG simulations that doesn't require full torso imaging and scales efficiently with electrode density.


<details>
  <summary>Details</summary>
Motivation: Current ECG computational models face three key challenges: 1) difficulty achieving high anatomical torso fidelity in clinical practice (imaging often focuses only on heart), 2) computational cost of lead-field method scaling linearly with electrode count, limiting high-density recordings, and 3) no existing approach simultaneously achieves high anatomical fidelity, low data requirements, and computational efficiency.

Method: Two-component framework: 1) geometry-encoding module that maps anatomical shapes into low-dimensional latent space, and 2) geometry-conditioned neural surrogate that predicts lead-field gradients from spatial coordinates, electrode positions, and latent codes. This creates a drop-in replacement for full-order forward ECG models.

Result: High accuracy in approximating lead fields (mean angular error 5¬∞ within torso, accurate inside heart), resulting in highly accurate ECG simulations (relative mean squared error <2.5%). Consistently outperforms widely used pseudo lead-field approximation while preserving negligible inference cost.

Conclusion: The method enables high-fidelity ECG simulations in data-limited clinical settings without requiring full torso segmentation, thanks to compact latent representation. It overcomes limitations of existing approaches by combining anatomical fidelity, low data requirements, and computational efficiency.

Abstract: Modern forward electrocardiogram (ECG) computational models rely on an accurate representation of the torso domain. The lead-field method enables fast ECG simulations while preserving full geometric fidelity. Achieving high anatomical accuracy in torso representation is, however, challenging in clinical practice, as imaging protocols are typically focused on the heart and often do not include the entire torso. In addition, the computational cost of the lead-field method scales linearly with the number of electrodes, limiting its applicability in high-density recording settings. To date, no existing approach simultaneously achieves high anatomical fidelity, low data requirements and computational efficiency. In this work, we propose a shape-informed surrogate model of the lead-field operator that serves as a drop-in replacement for the full-order model in forward ECG simulations. The proposed framework consists of two components: a geometry-encoding module that maps anatomical shapes into a low-dimensional latent space, and a geometry-conditioned neural surrogate that predicts lead-field gradients from spatial coordinates, electrode positions and latent codes. The proposed method achieves high accuracy in approximating lead fields both within the torso (mean angular error 5¬∞) and inside the heart, resulting in highly accurate ECG simulations (relative mean squared error <2.5%. The surrogate consistently outperforms the widely used pseudo lead-field approximation while preserving negligible inference cost. Owing to its compact latent representation, the method does not require a fully detailed torso segmentation and can therefore be deployed in data-limited settings while preserving high-fidelity ECG simulations.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [40] [Imprints of primordial magnetic fields on the late-time Universe](https://arxiv.org/abs/2602.23263)
*Jennifer Schober,Molly Abramson,Sayan Mandal,Salome Mtchedlidze,Tina Kahniashvili*

Main category: astro-ph.CO

TL;DR: Primordial magnetic fields can survive structure formation on certain scales, with turbulence during gravitational collapse triggering small-scale dynamo amplification below Jeans scale.


<details>
  <summary>Details</summary>
Motivation: To understand which spatial scales retain primordial magnetic field signatures despite nonlinear structure formation processes, and to investigate PMF evolution during gravitational collapse.

Method: High-resolution direct numerical simulations of self-gravitating, magnetized halos with varying viscosity to probe different Reynolds-number regimes, studying coupled evolution of gravitational collapse and magnetohydrodynamic turbulence.

Result: At high Reynolds numbers, turbulence during collapse triggers small-scale dynamo that amplifies magnetic energy below Jeans scale and modifies magnetic energy spectrum. Dynamo dominance depends on competition between dynamo growth time and free-fall time.

Conclusion: Resolving Jeans scale and turbulent inertial range is crucial in cosmological MHD simulations to accurately capture gravitational compression-dynamo interplay and determine which structures retain primordial field memory.

Abstract: Primordial magnetic fields (PMFs) generated in the early Universe may leave observable imprints in the present-day large-scale structure. However, it remains unclear on which spatial scales primordial signatures can survive the nonlinear processes accompanying structure formation. The aim of this study is to investigate the evolution of PMFs during gravitational collapse and to determine the spatial scales on which primordial signatures can persist. We perform a suite of high-resolution direct numerical simulations of self-gravitating, magnetized halos. By varying the viscosity, we probe different Reynolds-number regimes and follow the coupled evolution of gravitational collapse and magnetohydrodynamic turbulence. At sufficiently high Reynolds numbers, turbulence generated during collapse triggers the onset of a small-scale dynamo, which amplifies magnetic energy below the Jeans scale and modifies the magnetic energy spectrum significantly. Whether dynamo amplification dominates the magnetic field evolution is determined by the competition between the dynamo growth time and the free-fall time. Our results highlight the importance of resolving the Jeans scale and the associated turbulent inertial range in cosmological MHD simulations to accurately capture the interplay between gravitational compression and dynamo amplification and to assess which structures retain memory of primordial fields.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [41] [A Lorentz-Covariant Spectral Universality of Stochastic Fields](https://arxiv.org/abs/2602.23195)
*Alexander G. Tevzadze*

Main category: astro-ph.HE

TL;DR: Lorentz-covariant spectral universality shows temporal and spatial power spectra cannot be related by covariant local mappings in >1D, with temporal index symmetry-protected and offset from spatial index by universal geometric factor.


<details>
  <summary>Details</summary>
Motivation: To establish a Lorentz-covariant framework for analyzing spectral properties of stationary stochastic fields in Minkowski spacetime, addressing limitations of non-covariant spectral analysis in relativistic contexts.

Method: Derivation of Lorentz-covariant spectral universality principles, analysis of covariant local mappings between temporal and spatial power spectra, examination of Lorentz homogeneous spectra, and investigation of breakdown conditions for anisotropic scaling and dispersion dominated spectra.

Result: No covariant local mapping can relate temporal and spatial power spectra in more than one spatial dimension; for Lorentz homogeneous spectra, temporal index is symmetry-protected, observer invariant, and offset from spatial index by universal geometric factor determined by effective momentum space dimensionality.

Conclusion: Spectral universality breaks down for anisotropic scaling and dispersion dominated spectra, establishing the necessity of a Lorentz-covariant formulation of relativistic spectral inference for proper analysis of stochastic fields in Minkowski spacetime.

Abstract: We derive a Lorentz-covariant spectral universality for stationary stochastic fields in Minkowski spacetime. We show that no covariant local mapping can relate temporal and spatial power spectra in more than one spatial dimension. For Lorentz homogeneous spectra, the temporal index is symmetry protected, observer invariant, and offset from the spatial index by a universal geometric factor set by effective momentum space dimensionality. We show how spectral universality breaks down for anisotropic scaling and dispersion dominated spectra, establishing the necessity of a Lorentz-covariant formulation of relativistic spectral inference.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [42] [Quadratization of Autonomous Partial Differential Equations: Theory and Algorithms](https://arxiv.org/abs/2602.22371)
*Albani Olivieri,Gleb Pogudin,Boris Kramer*

Main category: cs.SC

TL;DR: QuPDE is the first computational algorithm for quadratizing spatially one-dimensional polynomial/rational PDEs, finding low-order quadratic transformations with fewer auxiliary variables than previous manual methods.


<details>
  <summary>Details</summary>
Motivation: Quadratization transforms nonquadratic PDEs into quadratic form using auxiliary variables, which simplifies analysis, simulation, and control of nonlinear PDE models across diverse fields. However, there was no computational tool to automate this transformation process.

Method: The paper presents QuPDE algorithm based on symbolic computation and discrete optimization that outputs quadratizations for any spatially one-dimensional polynomial or rational PDE. It includes rigorous definition of PDE quadratization and theoretical results on existence and complexity.

Result: QuPDE successfully quadratized 14 nonquadratic PDEs from fluid mechanics, space physics, chemical engineering, and biological processes. It found quadratic transformations with fewer auxiliary variables than previous literature for some examples, and quadratized systems that had never been transformed before.

Conclusion: QuPDE is the first computational tool for PDE quadratization, enabling automated transformation of nonquadratic PDEs into quadratic form, which can significantly simplify analysis and simulation of complex PDE models across scientific domains.

Abstract: Quadratization for partial differential equations (PDEs) is a process that transforms a nonquadratic PDE into a quadratic form by introducing auxiliary variables. This symbolic transformation has been used in diverse fields to simplify the analysis, simulation, and control of nonlinear and nonquadratic PDE models. This paper presents a rigorous definition of PDE quadratization, theoretical results for the PDE quadratization problem of spatially one-dimensional PDEs-including results on existence and complexity-and introduces QuPDE, an algorithm based on symbolic computation and discrete optimization that outputs a quadratization for any spatially one-dimensional polynomial or rational PDE. This algorithm is the first computational tool to find quadratizations for PDEs to date. We demonstrate QuPDE's performance by applying it to fourteen nonquadratic PDEs in diverse areas such as fluid mechanics, space physics, chemical engineering, and biological processes. QuPDE delivers a low-order quadratization in each case, uncovering quadratic transformations with fewer auxiliary variables than those previously discovered in the literature for some examples, and finding quadratizations for systems that had not been transformed to quadratic form before.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [43] [Fluctuations in the weakly coupled 4D Anderson Hamiltonian](https://arxiv.org/abs/2602.22509)
*Simon Gabriel,Tommaso Rosati*

Main category: math.PR

TL;DR: The paper proves Gaussian fluctuations for the Anderson Hamiltonian in critical dimension d=4, with explicit effective variance up to a critical coupling constant where a phase transition is expected.


<details>
  <summary>Details</summary>
Motivation: To understand the weak coupling limit behavior of the Anderson Hamiltonian in the critical dimension d=4, particularly the structure of fluctuations around the Laplacian's Green's function and the existence of a phase transition at a critical coupling constant.

Method: Combinatorial analysis of Feynman diagrams combined with detailed study of BPHZ renormalization of the model. The approach characterizes limiting distributions in terms of primitive blow-ups and shows no Laplacian renormalization is needed.

Result: Proves Gaussian fluctuations about the Green's function of the Laplacian with explicit effective variance, up to a critical value of the coupling constant where a phase transition is expected in the fluctuation structure.

Conclusion: The weak coupling limit of the Anderson Hamiltonian in d=4 exhibits Gaussian fluctuations described by an explicit effective variance, with the approach being applicable to a broad class of equations beyond this specific model.

Abstract: We study the weak coupling limit of the Anderson Hamiltonian in the critical dimension $d=4$. In a perturbative sense, we prove Gaussian fluctuations about the Green's function of the Laplacian. The fluctuations are described by an explicit effective variance, up to a critical value of the coupling constant at which we expect a phase transition in the structure of the fluctuations. The proof is based on a combinatorial analysis of Feynman diagrams, and on a detailed study of the BPHZ renormalisation of the model. We characterise the limiting distribution in terms of primitive blow-ups, and prove that no Laplacian renormalisation is present. Our approach seems applicable to a broad class of equations.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [44] [Optimizing Doppler laser cooling protocols for quantum sensing with 3D ion crystals in a Penning trap](https://arxiv.org/abs/2602.22541)
*John Zaris,Wes Johnson,Athreya Shankar,John J. Bollinger,Allison L. Carter,Daniel H. E. Dubin,Scott E. Parker*

Main category: quant-ph

TL;DR: Developed efficient numerical framework to simulate laser cooling of up to 100,000 ions in Penning traps, enabling optimization of 3D ellipsoidal crystal cooling with new pathways for enhanced cooling.


<details>
  <summary>Details</summary>
Motivation: Large 3D trapped ion crystals improve quantum sensing sensitivity but current numerical techniques are inefficient for studying laser cooling as crystal size increases, limiting practical implementation.

Method: Developed powerful numerical framework to simulate laser cooling of up to 10^5 ions in Penning traps, applied to characterize and optimize cooling of ellipsoidal 3D crystals with specific trap and laser beam parameters.

Result: Discovered new pathways to enhanced cooling via axial component addition to E√óB modes, achieved perpendicular kinetic energy cooling below 1 mK in prolate crystals, enabling simplified cooling beam setup.

Conclusion: Demonstrates feasibility of preparing large 3D crystals for high-sensitivity quantum science protocols, providing specific optimal parameters for future experimental implementation.

Abstract: Large, 3D trapped ion crystals offer improved sensitivity in quantum sensing protocols, and are expected to be implemented as platforms in near-future experiments. However, numerical techniques used to study the laser cooling of such crystals are inefficient as the number of ions, $N$, in the crystal increases. Here we develop a powerful numerical framework to simulate laser cooling of up to $10^5$ ions stored in a Penning trap. We apply this framework to characterize and optimize the cooling of ellipsoidal 3D crystals. We document new pathways to enhanced cooling based on the addition of an axial component to the potential energy-dominated $\boldsymbol{E}\times\boldsymbol{B}$ modes. Furthermore, we observe greatly enhanced cooling of the perpendicular kinetic energy to below 1 mK in prolate ion crystals, enabling a simplified cooling beam setup for such crystals. We propose specific values of trap and laser beam parameters which lead to optimal cooling in a variety of examples. This work illustrates the feasibility of preparing large 3D crystals for high-sensitivity quantum science protocols, motivating their use in future experiments.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [45] [Calibrations for the Sasaki volume on odd spheres and the no-gap problem](https://arxiv.org/abs/2602.22961)
*Jonas Matuzas*

Main category: math.DG

TL;DR: The paper establishes a universal calibrated lower bound for the Sasaki volume functional on odd-dimensional spheres, analyzes equality cases, constructs recovery sequences, and proves no Lavrentiev gap exists.


<details>
  <summary>Details</summary>
Motivation: To study the Sasaki volume functional on smooth unit tangent vector fields on odd-dimensional spheres, establish optimal lower bounds using calibration theory, and understand the existence and properties of minimizers in both smooth and relaxed settings.

Method: Uses the Brito-Chacon-Naveira calibration œâ on the unit tangent bundle, analyzes calibrated graphs and their rigidity properties, constructs explicit smooth recovery sequences, and employs integral current theory for the relaxed setting.

Result: Proves universal lower bound Vol^S(V) ‚â• c(m;1)vol(S^n) with optimal constant c(m;1)=4^m/binom(2m,m). Shows the infimum equals this bound (no Lavrentiev gap), analyzes equality cases revealing rigidity properties, and constructs explicit recovery sequences.

Conclusion: The Sasaki volume functional on odd spheres has a sharp calibrated lower bound, no Lavrentiev gap exists, and minimizers exhibit specific geometric rigidity. The optimal constant is achieved in the relaxed setting but not by smooth unit vector fields for dimensions ‚â•5.

Abstract: For each odd sphere $S^{n}$ with $n=2m+1\ge 5$, we consider the Sasaki volume functional $\mathrm{Vol}^S(V)=\int_{S^{n}}\sqrt{\det(I+(\nabla V)^{\top}(\nabla V))}\,d\mathrm{vol}$ on smooth unit tangent vector fields $V$. Using the Brito--Chacon--Naveira calibration $œâ=a\wedgeŒò$ on the unit tangent bundle $E=UTS^{n}$, we establish the universal calibrated lower bound $\mathrm{Vol}^S(V)\ge c(m;1)\,\mathrm{vol}(S^{n})$, where $c(m;1)=4^{m}/\binom{2m}{m}$. In the relaxed (integral-current) setting, we show that the section-constrained stable mass in $E$ equals the calibration value and is attained by an $œâ$-calibrated mass-minimizing integral $n$-cycle in the section class.
  We also analyze the equality case on smooth graphs. If a smooth graph is $œâ$-calibrated on an open set, then it satisfies the rigidity system $\nabla_V V=0$ and $\nabla_X V=ŒªX$ for all $X\perp V$, hence is locally a radial distance-gradient field. In particular, for $m\ge 2$ there is no smooth unit field on $S^n$ whose graph is $œâ$-calibrated everywhere.
  Finally, we construct an explicit smooth recovery sequence (presented in detail for $S^5$ and then extended to all odd dimensions) and prove a uniform nonvanishing estimate for the polar-shell normalization in the patching construction. As a consequence, $\inf_{V}\,\mathrm{Vol}^S(V)=c(m;1)\,\mathrm{vol}(S^{n})$, so there is no Lavrentiev gap.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [46] [HELIOS: A surface integral equation software for light scattering in homogeneous, periodic, and stratified environments](https://arxiv.org/abs/2602.23097)
*Parmenion S. Mavrikakis,Olivier J. F. Martin*

Main category: physics.optics

TL;DR: HELIOS is an open-source surface integral equation software for modeling light scattering by particles in homogeneous/layered media and periodic backgrounds, implementing PMCHWT formulation with RWG basis functions and efficient computational techniques.


<details>
  <summary>Details</summary>
Motivation: To provide a versatile, open-source computational tool for solving complex light scattering problems involving particles in various media types (homogeneous, layered, periodic) that are important in photonics, metamaterials, and optical engineering applications.

Method: Uses PMCHWT surface integral equation formulation with triangular mesh discretization and RWG basis functions. For periodic structures, employs Ewald's transformation for 2D lattice series. For layered media, uses matrix-friendly approach with Sommerfeld integrals and tabulation-interpolation acceleration. C++ backend with Python interface.

Result: Developed a comprehensive, open-source software package (HELIOS) that demonstrates accuracy and versatility through various examples covering all its functionalities for modeling light scattering in different media configurations.

Conclusion: HELIOS provides a reliable, efficient, and versatile computational framework for solving complex light scattering problems across various media types, with potential applications in photonics, metamaterials design, and optical engineering research.

Abstract: We present HELIOS (HomogEneous and Layered medIa Optical Scattering), an open-source surface integral equation (SIE) software designed for modeling light scattering by particles embedded in homogeneous or layered media and periodic backgrounds. The code implements the Poggio-Miller-Chang-Harrington-Wu-Tsai (PMCHWT) formulation that has demonstrated exceptional reliability in solving scattering problems with penetrable objects. Domain boundaries are discretized using triangular meshes, upon which the electric and magnetic surface current densities are expanded using the Rao-Wilton-Glisson (RWG) basis functions. For periodic structures, such as photonic crystals and metasurfaces, HELIOS employs Ewald's transformation to efficiently evaluate the infinite series associated with 2D lattices. Regarding stratified media, the code utilizes a matrix-friendly approach for the layered media Green's tensor, computing Sommerfeld integrals and accelerating calculations through a tabulation-interpolation scheme. The source code is implemented in C++, while a Python interface manages the workflow, including simulation setup, solver run, and post-processing. The accuracy and versatility of HELIOS are demonstrated through various examples that cover all its functionalities.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [47] [First-principles and tight-binding analysis of thermoelectricity in irradiated WSe$_2$](https://arxiv.org/abs/2602.22789)
*Cynthia Ihuoma Osuala,Tanu Choudhary,Raju K. Biswas,Sudin Ganguly,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: Light irradiation enhances thermoelectric performance in WSe2 nanoribbons through Floquet engineering, achieving ZT > 1 over broad temperature range.


<details>
  <summary>Details</summary>
Motivation: To investigate how monochromatic light irradiation can enhance thermoelectric properties in 2D transition metal dichalcogenide nanoribbons by modifying electronic transport and reducing thermal conductivity.

Method: Combines tight-binding electronic structure with spin-orbit coupling, Floquet theory for light-matter interaction, Landauer-B√ºttiker formalism for coherent transport, and DFT+phonon Boltzmann equation for lattice thermal conductivity.

Result: Light-induced hopping renormalization modifies band dispersion and transmission near Fermi level, combined with spin-orbit band splitting and reduced lattice thermal conductivity, achieving thermoelectric figure of merit ZT > 1 over broad temperature range.

Conclusion: Floquet engineering via light irradiation is an effective strategy to enhance thermoelectric performance in 2D materials by simultaneously optimizing electronic transport and suppressing thermal conductivity.

Abstract: Electronic and thermoelectric transport in zigzag monolayer WSe$_2$ nanoribbons are studied under monochromatic irradiation. The electronic structure is described within a six-orbital tight-binding framework constructed from the relevant tungsten and selenium orbitals, with atomic spin-orbit coupling included explicitly. Periodic driving is incorporated via the Peierls substitution, and in the high-frequency limit the system is mapped onto an effective static Floquet Hamiltonian with polarization-dependent renormalized hoppings. Coherent transport is evaluated using wave-function matching within the Landauer-B√ºttiker formalism. The lattice thermal conductivity is obtained independently from density functional perturbation theory combined with an iterative solution of the phonon Boltzmann transport equation. Light-induced hopping renormalization reshapes the band dispersion and transmission spectrum near the Fermi level, modifying the Landauer transport integrals that determine electrical and thermal conductances and the Seebeck coefficient. Together with spin-orbit-driven band splitting and reduced lattice thermal conductivity from enhanced anharmonic scattering, this leads to a thermoelectric figure of merit $ZT$ exceeding unity over a broad temperature range.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [48] [A Multi-Diagnostic Observational Framework for Magnetosonic Solitary Waves During Geomagnetic Storms in Solar Cycles 24 and 25 using Cluster II Mission](https://arxiv.org/abs/2602.22614)
*Murchana Khusroo,Yimnasangla*

Main category: astro-ph.SR

TL;DR: Magnetosonic solitons observed during geomagnetic storms may serve as precursor signatures of enhanced geomagnetic activity, occurring predominantly in early storm intervals before the main phase.


<details>
  <summary>Details</summary>
Motivation: While solitons are abundant in space plasmas, their observation during geomagnetic storms remains limited. The study aims to investigate magnetosonic soliton signatures during geomagnetic storms to understand their occurrence patterns and potential role as storm precursors.

Method: Used high-resolution in-situ magnetic field measurements from Cluster II mission during Solar Cycles 24 and 25. Developed a comprehensive multi-diagnostic observational framework with state-of-the-art analytical techniques to reliably detect and characterize magnetosonic solitons.

Result: Solitary structures in both storms predominantly occur during early storm intervals, prior to the main phase. This suggests they may serve as potential precursor signatures of enhanced geomagnetic activity.

Conclusion: Magnetosonic solitons observed during geomagnetic storms could be valuable early indicators of geomagnetic disturbances, providing potential warning capabilities for space weather events.

Abstract: Solitary structures, commonly known as solitons, are a class of nonlinear plasma waves that are abundantly found in near-Earth plasmas and planetary magnetospheres. They are nonlinear, localized plasma waves that maintain their shape and velocity over time and distance. While their occurrence in various space plasma environments has been extensively reported, their observation during geomagnetic storms, large-scale disturbances driven by interactions between the solar wind and Earth's magnetosphere, remains limited. In this study, we present a comparative investigation of magnetosonic soliton signatures during geomagnetic storms associated with Solar Cycles 24 and 25. Using high-resolution in-situ magnetic field measurements from the Cluster II mission, we systematically examine the plasma conditions favorable for soliton generation and their evolution during storm-time dynamics. A comprehensive multi-diagnostic observational framework, incorporating several state-of-the-art analytical techniques, is developed to reliably detect and characterize magnetosonic solitons. The results demonstrate that solitary structures in both storms predominantly occur during the early storm intervals, prior to the main phase, suggesting that they may serve as potential precursor signatures of enhanced geomagnetic activity.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [49] [Fluctuating polytropic processes, turbulence, and heating](https://arxiv.org/abs/2602.22272)
*G. Livadiotis,D. J. McComas*

Main category: physics.space-ph

TL;DR: Fluctuating polytropic processes cause net heating in particle systems like solar wind plasma, with turbulent heating described by these fluctuations and nonturbulent heating by nonfluctuating processes.


<details>
  <summary>Details</summary>
Motivation: To understand how turbulent heating in systems like solar wind plasma can be thermodynamically described through fluctuating polytropic processes, and to connect this to observed subadiabatic cooling in solar wind protons.

Method: Derived thermodynamic expressions for fluctuating polytropic processes, applied to solar wind plasma, derived radial profiles of polytropic index, temperature, and heating rates, and compared with turbulent heating models and pickup ion energy transfer.

Result: Polytropic fluctuations cause net heating even when nonfluctuating process is adiabatic; solar wind proton temperature decreases less than adiabatic cooling (subadiabatic cooling proportional to fluctuation variance); analytical profiles of fluctuating polytropic heating match turbulent heating; derived PUI heating rates fit observations well.

Conclusion: Turbulence heats plasma by fluctuating polytropic processes; fluctuating polytropic thermodynamics successfully describes turbulent heating in solar wind plasma and pickup ion energy transfer, with derived expressions matching observations.

Abstract: This paper explores the thermodynamics of fluctuating polytropic processes and their connection to turbulence. It is shown that random fluctuations of polytropic processes produce a nonzero overall heating of a particle system, e.g., solar wind plasma flowing out through the heliosphere; while any nonturbulent heating can be thermodynamically described by typical nonfluctuating polytropic processes, turbulent heating can be thermodynamically described through fluctuating polytropic processes. First, we derive the expression of the overall process and find that polytropic fluctuations lead to heat entering the system even if the respective nonfluctuating process is adiabatic. The temperature of the solar wind plasma protons decreases with heliospheric distance less than the adiabatic cooling, again, similar to when heating enters the system; this subadiabatic cooling is proportional to the variance of the fluctuations. We derive the heliospheric radial profiles of the thermodynamic expressions of the polytropic index, temperature, and heating rates. Then, we show that the analytical profiles of heating of fluctuating polytropic processes and of turbulent heating are identical, suggesting that turbulence heats plasma particle populations by fluctuating their polytropic processes. We apply the thermodynamics of fluctuating polytropic processes to the energy transfer from pickup ions (PUIs) to solar wind plasma protons, and derive the analytical expressions of PUI turbulent and nonturbulent heating rates, which are well fitted to the respective observations. Finally, we apply the thermodynamic model to the radial profile of PUI energy transfer to the solar wind plasma protons, where we derive the portion of PUI turbulent vs. nonturbulent heating rates.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [50] [QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition](https://arxiv.org/abs/2602.22639)
*Daniel Miao,Gilad Lerman,Joe Kileel*

Main category: cs.CV

TL;DR: New framework recovers multiple cameras from quadrifocal tensors using Tucker decomposition, challenging the belief that quadrifocal tensors are impractical for structure from motion.


<details>
  <summary>Details</summary>
Motivation: Quadrifocal tensors capture more information than essential matrices but have been considered impractical. The authors challenge this belief by showing quadrifocal tensors can be practically used for camera recovery.

Method: Form block quadrifocal tensor with Tucker decomposition (rank 4√ó4√ó4√ó4), develop synchronization algorithm using Tucker decomposition, ADMM, and iteratively reweighted least squares. Also establish relationships between quadrifocal, trifocal, and bifocal tensors for joint synchronization.

Result: Numerical experiments demonstrate effectiveness on modern datasets, showing potential of higher-order information in synchronization tasks.

Conclusion: Quadrifocal tensors are practical and important for structure from motion, providing a viable alternative to pairwise methods with better information capture.

Abstract: In structure from motion, quadrifocal tensors capture more information than their pairwise counterparts (essential matrices), yet they have often been thought of as impractical and only of theoretical interest. In this work, we challenge such beliefs by providing a new framework to recover $n$ cameras from the corresponding collection of quadrifocal tensors. We form the block quadrifocal tensor and show that it admits a Tucker decomposition whose factor matrices are the stacked camera matrices, and which thus has a multilinear rank of (4,~4,~4,~4) independent of $n$. We develop the first synchronization algorithm for quadrifocal tensors, using Tucker decomposition, alternating direction method of multipliers, and iteratively reweighted least squares. We further establish relationships between the block quadrifocal, trifocal, and bifocal tensors, and introduce an algorithm that jointly synchronizes these three entities. Numerical experiments demonstrate the effectiveness of our methods on modern datasets, indicating the potential and importance of using higher-order information in synchronization.

</details>


### [51] [Multidimensional Task Learning: A Unified Tensor Framework for Computer Vision Tasks](https://arxiv.org/abs/2602.23217)
*Alaa El Ichi,Khalide Jbilou*

Main category: cs.CV

TL;DR: MTL is a tensor-based framework using GE-MLPs that unifies computer vision tasks through tensor algebra, overcoming matrix-based limitations.


<details>
  <summary>Details</summary>
Motivation: Current computer vision architectures are constrained by matrix-based thinking that requires flattening operations, restricting the space of naturally expressible tasks and preventing unified treatment of different vision tasks.

Method: Introduces Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via Einstein product, using tensor-valued parameters instead of matrix-valued weights and vector-valued biases, allowing explicit control over dimension preservation/contraction.

Result: Shows that classification, segmentation, and detection are special cases of MTL differing only in dimensional configuration; proves the task space is strictly larger than matrix-based formulations can express, enabling principled spatiotemporal and cross-modal predictions.

Conclusion: Provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through tensor algebra, offering a unified framework that overcomes limitations of conventional matrix-based approaches.

Abstract: This paper introduces Multidimensional Task Learning (MTL), a unified mathematical framework based on Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via the Einstein product. We argue that current computer vision task formulations are inherently constrained by matrix-based thinking: standard architectures rely on matrix-valued weights and vectorvalued biases, requiring structural flattening that restricts the space of naturally expressible tasks. GE-MLPs lift this constraint by operating with tensor-valued parameters, enabling explicit control over which dimensions are preserved or contracted without information loss. Through rigorous mathematical derivations, we demonstrate that classification, segmentation, and detection are special cases of MTL, differing only in their dimensional configuration within a formally defined task space. We further prove that this task space is strictly larger than what matrix-based formulations can natively express, enabling principled task configurations such as spatiotemporal or cross modal predictions that require destructive flattening under conventional approaches. This work provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through the lens of tensor algebra.

</details>


<div id='cs.MS'></div>

# cs.MS [[Back]](#toc)

### [52] [TorchLean: Formalizing Neural Networks in Lean](https://arxiv.org/abs/2602.22631)
*Robert Joseph George,Jennifer Cruden,Xiangru Zhong,Huan Zhang,Anima Anandkumar*

Main category: cs.MS

TL;DR: TorchLean is a framework in Lean 4 that provides unified semantics for neural network execution and verification, bridging the gap between programming environments and formal analysis.


<details>
  <summary>Details</summary>
Motivation: Neural networks are deployed in safety-critical systems, but verification results are often produced outside the programming environment, creating a semantic gap that undermines guarantees due to implicit conventions about operator semantics, tensor layouts, preprocessing, and floating-point behavior.

Method: TorchLean provides: (1) PyTorch-style verified API with eager/compiled modes lowering to shared op-tagged SSA/DAG IR, (2) explicit Float32 semantics via executable IEEE-754 binary32 kernel and proof-relevant rounding models, (3) verification via IBP and CROWN/LiRPA-style bound propagation with certificate checking.

Result: Validated on certified robustness, physics-informed residual bounds for PINNs, Lyapunov-style neural controller verification, and mechanized theoretical results including universal approximation theorem.

Conclusion: TorchLean demonstrates a semantics-first infrastructure for fully formal, end-to-end verification of learning-enabled systems, treating models as first-class mathematical objects with precise shared semantics for both execution and verification.

Abstract: Neural networks are increasingly deployed in safety- and mission-critical pipelines, yet many verification and analysis results are produced outside the programming environment that defines and runs the model. This separation creates a semantic gap between the executed network and the analyzed artifact, so guarantees can hinge on implicit conventions such as operator semantics, tensor layouts, preprocessing, and floating-point corner cases. We introduce TorchLean, a framework in the Lean 4 theorem prover that treats learned models as first-class mathematical objects with a single, precise semantics shared by execution and verification. TorchLean unifies (1) a PyTorch-style verified API with eager and compiled modes that lower to a shared op-tagged SSA/DAG computation-graph IR, (2) explicit Float32 semantics via an executable IEEE-754 binary32 kernel and proof-relevant rounding models, and (3) verification via IBP and CROWN/LiRPA-style bound propagation with certificate checking. We validate TorchLean end-to-end on certified robustness, physics-informed residual bounds for PINNs, and Lyapunov-style neural controller verification, alongside mechanized theoretical results including a universal approximation theorem. These results demonstrate a semantics-first infrastructure for fully formal, end-to-end verification of learning-enabled systems.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [53] [Growth-controlled photochromism in yttrium oxyhydride thin films deposited by HiPIMS and pulsed-DC magnetron sputtering](https://arxiv.org/abs/2602.22951)
*M. Zubkins,E. Letko,E. Strods,V. Vibornijs,D. Moldarev,K. Sarakinos,K. Mizohata,K. Kundzins,J. Purans*

Main category: cond-mat.mtrl-sci

TL;DR: Comparison of photochromic YHO thin films deposited by HiPIMS vs pulsed-DCMS shows different plasma characteristics, pressure requirements, and resulting film properties affecting photochromic performance.


<details>
  <summary>Details</summary>
Motivation: To investigate how different sputtering techniques (HiPIMS vs pulsed-DCMS) affect the photochromic, optical, and structural properties of yttrium hydride oxide (YHO) thin films, understanding the role of deposition conditions on material performance.

Method: Deposited YHO thin films using reactive HiPIMS and pulsed-DCMS, analyzed plasma characteristics with optical emission spectroscopy, measured critical working pressure requirements, and characterized films using optical transmittance, photochromic contrast, optical band gap, and structural analysis.

Result: HiPIMS showed strong Y‚Å∫ emission indicating high yttrium ionization, required higher critical pressure (1.0 Pa vs 0.5 Pa), produced films with lower photochromic contrast (9% vs 34%), higher band gap (2.94 eV vs 2.70 eV), and different microstructure (polycrystalline vs <100> preferred orientation).

Conclusion: Beyond chemical composition, thin-film growth conditions and microstructure significantly influence photochromic performance of YHO, with pulsed-DCMS producing superior photochromic properties under the studied conditions.

Abstract: The present study investigates photochromic oxygen-containing yttrium hydride (YHO) thin films deposited by reactive high power impulse magnetron sputtering (HiPIMS) and compares their photochromic, optical, and structural properties with those of films synthesized by reactive pulsed direct current magnetron sputtering (pulsed-DCMS). Optical emission spectroscopy reveals that, unlike pulsed-DCMS where Ar$^{+}$ ions dominate, HiPIMS discharges are characterised by strong Y$^{+}$ emission, evidencing high yttrium ionisation and substantial self-sputter recycling. The critical working pressure (P$_c$) required to obtain transparent and photochromic films is higher for HiPIMS (Pc $\approx$ 1.0 Pa) than for pulsed-DCMS (Pc $\approx$ 0.5 Pa). Although films deposited near Pc exhibit similar solar transmittance (~72 %) and lattice parameters (5.38--5.39 √Ö), the pulsed-DCMS film shows a substantially higher relative photochromic contrast (34 %) and a lower optical band gap (2.70 eV) compared with the HiPIMS film (9 % contrast and 2.94 eV). This difference is partly attributed to a lower oxygen-to-hydrogen atomic ratio in the pulsed-DCMS film. Structurally, HiPIMS films are largely polycrystalline with random out-of-plane crystallographic orientation, whereas pulsed-DCMS films exhibit a pronounced <100> out-of-plane preferred orientation. These results demonstrate that, beyond composition, thin-film growth conditions and microstructure play a crucial role in governing the photochromic performance of YHO.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [54] [The AI Research Assistant: Promise, Peril, and a Proof of Concept](https://arxiv.org/abs/2602.22842)
*Tan Bui-Thanh*

Main category: cs.AI

TL;DR: AI can meaningfully accelerate mathematical discovery through human-AI collaboration, as demonstrated by discovering novel error representations and bounds for Hermite quadrature rules, but requires rigorous human verification and domain expertise.


<details>
  <summary>Details</summary>
Motivation: To investigate whether AI can truly contribute to creative mathematical research beyond routine calculations, and to understand the potential and limitations of human-AI collaboration in mathematical discovery.

Method: A detailed case study using systematic human-AI collaboration with multiple AI assistants to discover novel error representations and bounds for Hermite quadrature rules, documenting the complete research workflow with transparency.

Result: Extended results beyond manual work, formulating and proving several theorems with AI assistance. AI excelled at algebraic manipulation, systematic proof exploration, literature synthesis, and LaTeX preparation, but every step required human verification, mathematical intuition, and strategic direction.

Conclusion: When used with appropriate skepticism and verification protocols, AI tools can meaningfully accelerate mathematical discovery, but demand careful human oversight and deep domain expertise, revealing both remarkable capabilities and critical limitations in human-AI collaboration.

Abstract: Can artificial intelligence truly contribute to creative mathematical research, or does it merely automate routine calculations while introducing risks of error? We provide empirical evidence through a detailed case study: the discovery of novel error representations and bounds for Hermite quadrature rules via systematic human-AI collaboration.
  Working with multiple AI assistants, we extended results beyond what manual work achieved, formulating and proving several theorems with AI assistance. The collaboration revealed both remarkable capabilities and critical limitations. AI excelled at algebraic manipulation, systematic proof exploration, literature synthesis, and LaTeX preparation. However, every step required rigorous human verification, mathematical intuition for problem formulation, and strategic direction.
  We document the complete research workflow with unusual transparency, revealing patterns in successful human-AI mathematical collaboration and identifying failure modes researchers must anticipate. Our experience suggests that, when used with appropriate skepticism and verification protocols, AI tools can meaningfully accelerate mathematical discovery while demanding careful human oversight and deep domain expertise.

</details>
