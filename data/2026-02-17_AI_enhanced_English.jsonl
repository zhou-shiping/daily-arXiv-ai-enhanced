{"id": "2602.13786", "pdf": "https://arxiv.org/pdf/2602.13786", "abs": "https://arxiv.org/abs/2602.13786", "authors": ["Mukul Dwivedi", "Andreas Rupp"], "title": "A hybridizable discontinuous Galerkin method for the Ostrovsky equation", "categories": ["math.NA"], "comment": null, "summary": "This paper develops the hybridizable discontinuous Galerkin (HDG) method for the Ostrovsky equation, a nonlinear dispersive wave equation featuring both third-order dispersion and a nonlocal antiderivative term with Coriolis effect. On a bounded interval, the nonlocal operator $\\partial_x^{-1}$ is localized through an auxiliary variable $v$ satisfying $v_x=u$ together with an additional boundary constraint that ensures uniqueness. We employ a mixed first-order formulation to decompose the dispersive operator and to localize the nonlocal term, and we couple the resulting semi-discrete HDG scheme with a $\u03b8$-time stepping method for $\u03b8\\in [1/2,1]$. We prove $L^2$-stability for suitable stabilization parameters and derive an {\\it a priori} $L^2(\u03a9)$ error estimate for smooth solutions that explicitly accounts for the nonlinear convective flux.\n  Numerical examples illustrate the convergence properties and demonstrate the scheme's capability to handle smooth and non-smooth solutions, including solitary wave propagation and peaked solitary wave (peakon) propagation in the zero dispersive limit regime.", "AI": {"tldr": "HDG method developed for Ostrovsky equation with third-order dispersion and nonlocal Coriolis term, using mixed formulation and \u03b8-time stepping, with stability analysis and error estimates.", "motivation": "The Ostrovsky equation combines nonlinear convection, third-order dispersion, and a nonlocal antiderivative term with Coriolis effect, presenting challenges for numerical methods due to the nonlocal operator and dispersive nature.", "method": "Hybridizable Discontinuous Galerkin (HDG) method with mixed first-order formulation to decompose dispersive operator and localize nonlocal term using auxiliary variable v (v_x=u) with boundary constraint, coupled with \u03b8-time stepping (\u03b8\u2208[1/2,1]).", "result": "Proved L\u00b2-stability for suitable stabilization parameters, derived a priori L\u00b2(\u03a9) error estimate for smooth solutions accounting for nonlinear convective flux, demonstrated convergence for smooth/non-smooth solutions including solitary waves and peakons.", "conclusion": "The HDG method effectively handles the Ostrovsky equation's challenges, providing stable and accurate numerical solutions for both smooth and non-smooth wave phenomena including peakons in dispersive limit regimes."}}
{"id": "2602.13841", "pdf": "https://arxiv.org/pdf/2602.13841", "abs": "https://arxiv.org/abs/2602.13841", "authors": ["Nils Margenberg", "Markus Bause"], "title": "A Monolithic hp Space-Time Multigrid Preconditioned Newton-Krylov Solver for Space-Time FEM applied to the Incompressible Navier-Stokes Equations", "categories": ["math.NA"], "comment": "26 pages, 3 figures, 5 tables", "summary": "We present a monolithic hp space-time multigrid method (hp-STMG) for tensor-product space-time finite element discretizations of the incompressible Navier-Stokes equations. We employ mapped inf-sup stable pairs $\\mathbb Q_{r+1}/\\mathbb P_{r}^{\\mathrm{disc}}$ in space and a slabwise discontinuous Galerkin DG($k$) discretization in time. The resulting fully coupled nonlinear systems are solved by Newton-GMRES preconditioned with hp-STMG, combining geometric coarsening in space with polynomial coarsening in space and time. Our main contribution is an hp-robust and practically efficient extension of space-time multigrid to Navier-Stokes: matrix-free operator evaluation is retained via column-wise, state-dependent spatial kernels; the nonlinear convective term is handled by a reduced, order-preserving time quadrature. Robustness is ensured by an inexact space-time Vanka smoother based on patch models with single time point evaluation. The method is implemented in the matrix-free multigrid framework of deal.II and demonstrates h- and p-robust convergence with robust solver performance across a range of Reynolds numbers, as well as high throughput in large-scale MPI-parallel experiments.", "AI": {"tldr": "Monolithic hp space-time multigrid method for incompressible Navier-Stokes using tensor-product space-time FEM with Newton-GMRES and hp-STMG preconditioning.", "motivation": "Develop an efficient and robust solver for fully coupled nonlinear systems arising from space-time discretizations of incompressible Navier-Stokes equations that maintains matrix-free evaluation and handles high Reynolds numbers.", "method": "Uses tensor-product space-time FEM with inf-sup stable Q_{r+1}/P_r^disc pairs in space and slabwise DG(k) in time. Solves nonlinear systems with Newton-GMRES preconditioned by hp-STMG, combining geometric coarsening in space with polynomial coarsening in space/time. Features matrix-free operator evaluation via column-wise spatial kernels, reduced time quadrature for convection, and inexact space-time Vanka smoother with patch models.", "result": "Method demonstrates h- and p-robust convergence with robust solver performance across Reynolds numbers, and achieves high throughput in large-scale MPI-parallel experiments using deal.II framework.", "conclusion": "Successfully extends space-time multigrid to Navier-Stokes with hp-robustness and practical efficiency while maintaining matrix-free evaluation and handling nonlinear convection effectively."}}
{"id": "2602.13843", "pdf": "https://arxiv.org/pdf/2602.13843", "abs": "https://arxiv.org/abs/2602.13843", "authors": ["Nils Margenberg", "Marius Paul Bruchh\u00e4user", "Bernhard Endtmayer"], "title": "Anisotropic hp space-time adaptivity and goal-oriented error control for convection-dominated problems", "categories": ["math.NA", "physics.comp-ph"], "comment": "38 pages, 13 figures, 4 tables", "summary": "We present an anisotropic goal-oriented error estimator based on the Dual Weighted Residual (DWR) method for time-dependent convection-dominated problems. Using elementwise p-anisotropic finite element spaces, the estimator is elementwise separated with respect to the single directions in space and time. This naturally leads to adaptive, anisotropic hp-refinement (h-anisotropic refinement and elementwise anisotropic p-enrichment). We employ discontinuous elements in space and time, which are well suited for problems with high Peclet numbers. Efficiency and robustness of the underlying algorithm are demonstrated for different goal functionals. The directional error indicators quantify anisotropy of the solution with respect to the goal, and produce hp-refinements that efficiently capture sharp layers. Numerical examples in up to three spatial dimensions demonstrate the superior performance of the proposed method compared to isotropic h and hp adaptive refinement using established benchmarks for convection-dominated transport.", "AI": {"tldr": "An anisotropic goal-oriented error estimator using Dual Weighted Residual method for time-dependent convection-dominated problems with directional error indicators for adaptive hp-refinement.", "motivation": "Convection-dominated problems with high Peclet numbers are challenging to solve accurately. Traditional isotropic refinement methods are inefficient for capturing sharp layers and anisotropic features in solutions. There's a need for adaptive methods that can quantify directional errors and perform anisotropic refinement to improve computational efficiency.", "method": "Developed an anisotropic goal-oriented error estimator based on Dual Weighted Residual (DWR) method. Uses elementwise p-anisotropic finite element spaces with directional separation in space and time. Employs discontinuous elements in both space and time. The estimator produces directional error indicators that quantify anisotropy with respect to goal functionals, enabling adaptive anisotropic hp-refinement (h-anisotropic refinement and elementwise anisotropic p-enrichment).", "result": "The method demonstrates efficiency and robustness for different goal functionals. Directional error indicators successfully quantify solution anisotropy with respect to goals and produce hp-refinements that efficiently capture sharp layers. Numerical examples in up to 3D show superior performance compared to isotropic h and hp adaptive refinement on established convection-dominated transport benchmarks.", "conclusion": "The proposed anisotropic goal-oriented error estimator with DWR method provides an effective approach for convection-dominated problems. It enables adaptive anisotropic hp-refinement that outperforms traditional isotropic methods by better capturing solution features and improving computational efficiency for problems with high Peclet numbers."}}
{"id": "2602.14268", "pdf": "https://arxiv.org/pdf/2602.14268", "abs": "https://arxiv.org/abs/2602.14268", "authors": ["L. Banas", "D. Breit", "A. Chaudhary", "A. Prohl"], "title": "A Higher Order Discretization for the Stochastic Navier--Stokes equations with additive Noise", "categories": ["math.NA", "math.AP", "math.PR"], "comment": null, "summary": "We propose a new higher-order time discretization scheme for the stochastic Navier--Stokes equations with additive noise, where its velocity and pressure approximates converge at strong rate $1.5$ in probability. The construction rests on its reformulation as a random PDE for the transform $y = u- \u03a6W$, and different higher order numerical quadrature rules for the diffusion and the drift part. The theoretical findings are supported by numerical simulations.", "AI": {"tldr": "Higher-order time discretization scheme for stochastic Navier-Stokes equations with additive noise achieving strong convergence rate 1.5 in probability for velocity and pressure approximations.", "motivation": "Need for improved numerical methods for stochastic Navier-Stokes equations with better convergence rates, particularly for velocity and pressure approximations in the presence of additive noise.", "method": "Reformulates stochastic Navier-Stokes equations as random PDE using transform y = u - \u03a6W, then applies different higher-order numerical quadrature rules for diffusion and drift parts.", "result": "Achieves strong convergence rate of 1.5 in probability for both velocity and pressure approximations, with numerical simulations supporting theoretical findings.", "conclusion": "Proposed higher-order scheme successfully improves convergence rates for stochastic Navier-Stokes equations with additive noise, validated by both theory and simulations."}}
{"id": "2602.13931", "pdf": "https://arxiv.org/pdf/2602.13931", "abs": "https://arxiv.org/abs/2602.13931", "authors": ["Ting Peng"], "title": "Geometry Challenges Entropy: Regime-DependentRectification in Nanofluidic Cascades", "categories": ["physics.comp-ph", "cond-mat.soft", "cond-mat.stat-mech"], "comment": null, "summary": "Can geometry alone reshape equilibrium? Cascaded nanofluidic chambers show complex accumulation patterns, traditionally attributed to geometric diode effects. We use 3D molecular dynamics to decouple funnel rectification from boundary reflection. Simulations with argon parameters (r = 0.19 nm) reveal a striking \"reverse\" rectification in a 2-chamber setup: the narrow side accumulates over 5x more particles (N_1/N_0 = 5.37 +/- 0.01, p < 0.0001). In a 10-chamber argon cascade, this effect drives massive downstream accumulation. A symmetric control (w_L = w_R) eliminates the gradient, confirming that funnel asymmetry - not boundary/edge effects - is the primary driver in the ballistic regime. By contrast, the super-atom regime is dominated by boundary reflection. Our results challenge standard entropic transport theory and provide design rules for passive, geometry-driven density gradients - no pump, no drive.", "AI": {"tldr": "Geometry alone can reshape equilibrium through asymmetric funnel nanochambers, creating passive density gradients without external driving forces.", "motivation": "To challenge traditional geometric diode theory and understand how pure geometry (not boundary effects) can create particle accumulation gradients in nanofluidic systems.", "method": "3D molecular dynamics simulations using argon parameters (r = 0.19 nm) with asymmetric funnel nanochambers, comparing 2-chamber and 10-chamber cascades against symmetric controls.", "result": "Striking \"reverse\" rectification: narrow side accumulates over 5x more particles (N_1/N_0 = 5.37 \u00b1 0.01). In 10-chamber cascade, massive downstream accumulation occurs. Symmetric controls eliminate gradient, proving funnel asymmetry (not boundary effects) drives ballistic regime accumulation.", "conclusion": "Pure geometry (funnel asymmetry) can create passive density gradients without pumps or external drives, challenging standard entropic transport theory and providing design rules for geometry-driven nanofluidic systems."}}
{"id": "2602.13408", "pdf": "https://arxiv.org/pdf/2602.13408", "abs": "https://arxiv.org/abs/2602.13408", "authors": ["E. M. Starodubtseva", "I. N. Tsymbalov", "D. A. Gorlova", "K. A. Ivanov", "R. V. Volkov", "A. B. Savel'ev"], "title": "Measurement of the laser pulse phase velocity in plasma channel for DLA optimization", "categories": ["physics.plasm-ph", "physics.acc-ph"], "comment": null, "summary": "We demonstrate a novel, direct method for measuring the phase velocity $v_\u03c6$ of an intense laser pulse within a plasma channel - the crucial parameter that controls the resonance condition in direct laser acceleration (DLA). The technique exploits the second harmonic (SH) radiation generated at the channel sheath - a phenomenon previously observed in laser-wakefield acceleration experiments. The SH emission angle is governed by a phase-matching condition that directly depends on $v_\u03c6$. Experimental measurements performed using a 1 TW, 10 Hz Ti:Sa laser system yield phase velocities in the range $v_\u03c6=(1.010-1.030)c$ for plasma electron densities in the range $n_e=(0.01-0.06)n_{cr}$. The diagnostic is validated through quasi-3D particle-in-cell (PIC) simulations that reproduce the experimental conditions. This work provides a way to optimize DLA schemes by enabling in-situ measurement of the laser pulse phase velocity in plasma channels.", "AI": {"tldr": "Direct measurement of intense laser pulse phase velocity in plasma channels using second harmonic radiation angle, enabling optimization of direct laser acceleration schemes.", "motivation": "Phase velocity is crucial for resonance in direct laser acceleration (DLA), but measuring it directly in plasma channels has been challenging. Current methods lack direct in-situ measurement capability.", "method": "Uses second harmonic radiation generated at plasma channel sheath, where emission angle depends on phase velocity through phase-matching condition. Experimental measurements with 1 TW Ti:Sa laser and validation via quasi-3D particle-in-cell simulations.", "result": "Measured phase velocities v_\u03c6 = (1.010-1.030)c for plasma densities n_e = (0.01-0.06)n_cr. Technique validated by PIC simulations reproducing experimental conditions.", "conclusion": "Provides novel diagnostic for direct measurement of laser phase velocity in plasma channels, enabling optimization of DLA schemes through in-situ velocity monitoring."}}
{"id": "2602.13223", "pdf": "https://arxiv.org/pdf/2602.13223", "abs": "https://arxiv.org/abs/2602.13223", "authors": ["Fernando Abalos", "David Hilditch"], "title": "Strong Hyperbolicity of Second-Order PDEs via Matrix Pencils", "categories": ["math.AP", "gr-qc", "math-ph"], "comment": "1 figure", "summary": "We introduce a definition of strong hyperbolicity for second order partial differential equations using second order pencils. We show that this definition is equivalent to the standard one, derived by reducing the equations to first order form, but with the benefit of simplifying the calculations necessary to check hyperbolicity. In addition, we observe an interesting property, namely that when a system is strongly hyperbolic, its second order pencil can be factorized as a product of two diagonalizable first order pencils. Finally, we present an application to a vector potential for of Maxwell's equations, with a general extension and gauge fixing.", "AI": {"tldr": "The paper introduces a new definition of strong hyperbolicity for second-order PDEs using second-order pencils, shows equivalence to standard definitions, simplifies verification, reveals factorization properties, and applies to Maxwell's equations.", "motivation": "To develop a more efficient method for checking hyperbolicity of second-order PDEs without needing to reduce them to first-order form, which simplifies calculations and provides new mathematical insights.", "method": "Introduces a definition of strong hyperbolicity using second-order pencils directly, proves equivalence to standard first-order reduction approach, demonstrates factorization properties, and applies to Maxwell's equations with vector potential formulation.", "result": "The new second-order pencil definition is equivalent to standard hyperbolicity definitions but simplifies calculations. Strongly hyperbolic systems allow factorization of second-order pencils into diagonalizable first-order pencils. The method successfully applies to Maxwell's equations with general gauge fixing.", "conclusion": "The second-order pencil approach provides a simpler, equivalent alternative to traditional hyperbolicity analysis, reveals interesting factorization properties, and offers practical applications to important physical systems like Maxwell's equations."}}
{"id": "2602.14309", "pdf": "https://arxiv.org/pdf/2602.14309", "abs": "https://arxiv.org/abs/2602.14309", "authors": ["Dibyendu Adak", "David Mora", "Alberth Silgado"], "title": "Nonconforming virtual element methods for fourth-order nonlinear reaction-diffusion systems: a unified framework and analysis", "categories": ["math.NA"], "comment": "38 pages, 4 figures, 4 tables", "summary": "We develop a unified framework for the design and analysis of high-order nonconforming virtual element methods for nonlinear fourth-order reaction--diffusion problems in two dimensions, with emphasis on clamped, Navier, and Cahn--Hilliard-type boundary conditions. Time discretization is performed using the backward Euler scheme, while the spatial approximation relies on nonconforming virtual element spaces of arbitrary order $k \\ge 2$, encompassing both $C^0$-nonconforming and Morley-type methods. A key contribution of this work is the development of a novel and rigorous unified error analysis for these numerical schemes, applicable to domains that are not necessarily convex, differing from the existing literature. By introducing a class of Companion operators, we construct novel Ritz-type projections and derive a new error equation that enables us to obtain optimal error estimates for the scheme under a minimal spatial regularity assumption on the weak solution. Finally, we present numerical experiments on polygonal meshes as applications of the proposed framework, including the extended Fisher--Kolmogorov equation, and a fourth-order model with Cahn--Hilliard-type boundary conditions, which validate the theoretical results and illustrate the performance of the method for the three classes of boundary conditions.", "AI": {"tldr": "High-order nonconforming virtual element methods for nonlinear fourth-order reaction-diffusion problems with various boundary conditions, featuring unified error analysis and novel Ritz projections.", "motivation": "To develop a unified framework for high-order nonconforming virtual element methods for nonlinear fourth-order PDEs, addressing limitations in existing literature regarding non-convex domains and providing rigorous error analysis.", "method": "Backward Euler time discretization with spatial approximation using nonconforming virtual element spaces (order k\u22652), including C\u2070-nonconforming and Morley-type methods. Uses novel Companion operators to construct Ritz-type projections and derive new error equations.", "result": "Optimal error estimates under minimal spatial regularity assumptions, applicable to non-convex domains. Numerical experiments validate theoretical results for extended Fisher-Kolmogorov equation and fourth-order models with Cahn-Hilliard boundary conditions.", "conclusion": "The framework successfully provides unified analysis for high-order nonconforming virtual element methods for nonlinear fourth-order problems with various boundary conditions, overcoming limitations of existing approaches for non-convex domains."}}
{"id": "2602.14923", "pdf": "https://arxiv.org/pdf/2602.14923", "abs": "https://arxiv.org/abs/2602.14923", "authors": ["Moritz Humer", "Martin Schlipf", "Zoran Sukurma", "Sajad Bazrafshan", "Georg Kresse"], "title": "Auxiliary field quantum Monte Carlo at the basis set limit: application to lattice constants", "categories": ["physics.comp-ph", "physics.chem-ph"], "comment": null, "summary": "We present a plane-wave (PW) implementation of the auxiliary-field quantum Monte Carlo (AFQMC) method within the projector augmented-wave (PAW) formalism in the Vienna ab initio Simulation Package (VASP). By employing an exact inversion of the PAW overlap operator, our approach maintains cubic scaling while naturally operating at the complete basis set limit defined by the PW cutoff. We benchmark this framework by calculating the equilibrium lattice constants and bulk moduli of C, BN, BP, and Si. Our analysis demonstrates that AFQMC systematically corrects the lack of long-range screening in MP2 and the missing higher-order exchange in RPA. We identify RPA as the optimal reference method due to the rapid convergence of the remaining short-range correlations with respect to supercell size. The resulting lattice constants exhibit a mean absolute relative error of 0.14 % relative to experiment, establishing the method as a rigorous benchmark tool for structural properties in condensed matter systems.", "AI": {"tldr": "AFQMC implementation in VASP using PAW formalism achieves cubic scaling and complete basis set limit, providing accurate structural properties for solids with 0.14% error relative to experiments.", "motivation": "To develop a rigorous benchmark tool for structural properties in condensed matter systems that systematically corrects limitations of existing methods like MP2 (lack of long-range screening) and RPA (missing higher-order exchange).", "method": "Plane-wave implementation of auxiliary-field quantum Monte Carlo (AFQMC) within projector augmented-wave (PAW) formalism in VASP, using exact inversion of PAW overlap operator to maintain cubic scaling while operating at complete basis set limit.", "result": "AFQMC systematically corrects MP2 and RPA deficiencies, with RPA identified as optimal reference method due to rapid convergence of remaining short-range correlations. Calculated lattice constants show mean absolute relative error of 0.14% relative to experiment for C, BN, BP, and Si.", "conclusion": "The AFQMC implementation establishes a rigorous benchmark tool for structural properties in condensed matter systems, achieving high accuracy and systematic correction of existing method limitations while maintaining computational efficiency."}}
{"id": "2602.14417", "pdf": "https://arxiv.org/pdf/2602.14417", "abs": "https://arxiv.org/abs/2602.14417", "authors": ["Miguel C\u00e1rdenas"], "title": "A More Realistic Z-pinch Snowplow Model", "categories": ["physics.plasm-ph"], "comment": null, "summary": "We introduce an extended snowplow model for Z-pinch experiments that accounts for partial particle entrainment and current loss during contraction. We applied the methods to a specific case.", "AI": {"tldr": "Extended snowplow model for Z-pinch experiments with partial particle entrainment and current loss during contraction.", "motivation": "Existing snowplow models for Z-pinch experiments may not fully account for partial particle entrainment and current loss during the contraction phase, limiting their accuracy in predicting experimental outcomes.", "method": "Developed an extended snowplow model that incorporates partial particle entrainment and current loss mechanisms during Z-pinch contraction, then applied this model to a specific experimental case.", "result": "The extended model provides more accurate predictions by accounting for partial entrainment and current loss, offering improved understanding of Z-pinch dynamics compared to traditional snowplow models.", "conclusion": "The extended snowplow model with partial particle entrainment and current loss provides a more realistic framework for analyzing Z-pinch experiments, enhancing predictive capability for specific experimental cases."}}
{"id": "2602.13225", "pdf": "https://arxiv.org/pdf/2602.13225", "abs": "https://arxiv.org/abs/2602.13225", "authors": ["Christopher S. Goodrich", "Gabriel Nakhl"], "title": "A Unified Topological Analysis of Variable Growth Kirchhoff-Type Equations", "categories": ["math.AP", "math.FA"], "comment": "Prepublication version. A revised version of this paper has been accepted for publication in Proceedings of the Royal Society A", "summary": "We consider a nonlocal differential equation of Kirchhoff type with a convolution coefficient involving variable growth. The novelty of our work lies in allowing a variable exponent in the nonlocal term. By relating the variable growth problem to a corresponding constant growth problem, we establish the existence of at least one positive solution subject to boundary conditions. Our approach relies on topological fixed point theory. The results treat convex, concave, and mixed growth regimes, providing a unified framework for one-dimensional Kirchhoff-type problems.", "AI": {"tldr": "Existence of positive solutions for Kirchhoff-type equations with convolution coefficients involving variable exponents, using fixed point theory to handle convex, concave, and mixed growth regimes.", "motivation": "To extend Kirchhoff-type equations to include variable exponents in nonlocal convolution coefficients, which is a novel generalization of existing constant exponent models.", "method": "Relate variable growth problem to constant growth problem, then apply topological fixed point theory to establish solution existence under boundary conditions.", "result": "Proved existence of at least one positive solution for Kirchhoff-type equations with variable exponent convolution coefficients in one-dimensional settings.", "conclusion": "Provides unified framework for Kirchhoff-type problems with variable exponents, covering convex, concave, and mixed growth regimes through fixed point theory."}}
{"id": "2602.14369", "pdf": "https://arxiv.org/pdf/2602.14369", "abs": "https://arxiv.org/abs/2602.14369", "authors": ["Sigal Gottlieb", "Zachary J. Grant", "Cesar Herrera"], "title": "Mixed precision and mixed accuracy explicit two-derivative Runge--Kutta methods", "categories": ["math.NA"], "comment": null, "summary": "Mixed precision Runge--Kutta methods have been recently developed and used for the time-evolution of partial differential equations. Two-derivative Runge--Kutta schemes may offer enhanced stability and accuracy properties compared to classical one-derivative methods, making them attractive in a wide variety of problems. However, their computational cost can be significant, motivating the use of a mixed-precision paradigm that employs different floating-point precisions for different function evaluations to balance efficiency and accuracy. To ensure that the perturbations introduced by the low precision computations do not destroy the accuracy of the solution, we need to understand how these perturbation errors propagate. We extend the numerical analysis mixed precision framework previously developed for Runge--Kutta methods to characterize the propagation of the perturbation errors arising from mixed precision computations in explicit and implicit two-derivative Runge--Kutta methods. We use this framework for analyzing the order of the perturbation errors, and for designing new methods that are less sensitive to the effect of the low precision computations. Numerical experiments on linear and nonlinear representative PDEs, demonstrate that appropriately designed mixed-precision two-derivative Runge--Kutta methods achieve the predicted accuracy.", "AI": {"tldr": "Mixed precision two-derivative Runge-Kutta methods balance efficiency and accuracy by using different floating-point precisions, with analysis showing how to design methods less sensitive to low-precision errors.", "motivation": "Two-derivative Runge-Kutta methods offer better stability and accuracy than classical methods but are computationally expensive. Mixed precision computing (using different floating-point precisions) can improve efficiency while maintaining accuracy, but requires understanding how low-precision errors propagate through the numerical scheme.", "method": "Extends existing mixed precision analysis framework from standard Runge-Kutta methods to two-derivative Runge-Kutta methods (both explicit and implicit). Uses this framework to analyze perturbation error order and design new methods that are less sensitive to low-precision computations.", "result": "Successfully characterizes perturbation error propagation in mixed precision two-derivative Runge-Kutta methods. Designs new methods with reduced sensitivity to low-precision computations. Numerical experiments on linear and nonlinear PDEs confirm that appropriately designed mixed-precision methods achieve predicted accuracy.", "conclusion": "Mixed precision two-derivative Runge-Kutta methods can effectively balance computational efficiency and accuracy. The developed analysis framework enables understanding of error propagation and design of robust methods that maintain accuracy despite using lower precision computations."}}
{"id": "2602.12254", "pdf": "https://arxiv.org/pdf/2602.12254", "abs": "https://arxiv.org/abs/2602.12254", "authors": ["Annabelle Canestraight", "Anthony J. Dominic", "Andres Montoya-Castillo", "Libor Veis", "Vojtech Vlcek"], "title": "A Stochastic Cluster Expansion for Electronic Correlation in Large Systems", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Accurate many-body treatments of condensed-phase systems are challenging because correlated solvers such as full configuration interaction (FCI) and the density matrix renormalization group (DMRG) scale exponentially with system size. Downfolding and embedding approaches mitigate this cost but typically require prior selection of a correlated subspace, which can be difficult to determine in heterogeneous or extended systems. Here, we introduce a stochastic cluster expansion framework for efficiently recovering the total correlation energy of large systems with near-DMRG accuracy, without the need to select an active space a priori. By combining correlation contributions from randomly sampled environment orbitals with an exactly treated subspace of interest, the method reproduces total energies for non-reacting and reactive systems while drastically reducing computational cost. The approach also provides a quantitative diagnostic for molecule-solvent correlation, guiding principled embedding decisions. This framework enables systematically improvable many-body calculations in extended systems, opening the door to high-accuracy studies of chemical processes in condensed phase environments.", "AI": {"tldr": "Stochastic cluster expansion framework for efficient many-body calculations in condensed-phase systems without requiring prior active space selection, achieving near-DMRG accuracy at reduced computational cost.", "motivation": "Accurate many-body treatments of condensed-phase systems are challenging due to exponential scaling of correlated solvers like FCI and DMRG with system size. Existing downfolding and embedding approaches require difficult prior selection of correlated subspaces, especially problematic for heterogeneous or extended systems.", "method": "Introduces a stochastic cluster expansion framework that combines correlation contributions from randomly sampled environment orbitals with an exactly treated subspace of interest. This avoids the need for a priori active space selection by stochastically sampling environment orbitals and treating them in combination with the core subspace.", "result": "The method reproduces total energies for both non-reacting and reactive systems with near-DMRG accuracy while drastically reducing computational cost. It also provides a quantitative diagnostic for molecule-solvent correlation, enabling principled embedding decisions.", "conclusion": "This framework enables systematically improvable many-body calculations in extended systems, opening the door to high-accuracy studies of chemical processes in condensed phase environments without the traditional limitations of active space selection."}}
{"id": "2602.14836", "pdf": "https://arxiv.org/pdf/2602.14836", "abs": "https://arxiv.org/abs/2602.14836", "authors": ["Zsolt L\u00e9cz", "Szil\u00e1rd Majorosi"], "title": "Asymmetry in laser wakefields driven by intense pulses", "categories": ["physics.plasm-ph"], "comment": null, "summary": "Laser wakefield theories rely on the laser envelope function, which is radially symmetric, and predict zero transverse momentum for the electrons along the propagation axis. Exact description of laser wakefields, beyond the envelope approximation, requires a more general formula for the Lorentz force acting on the electrons. Here we present a fundamental approach to express the transverse momentum of an electron crossing the laser pulse, and we show that an exact analytical formula can be derived for the non-zero transverse momentum of electrons initially lying along the axis of symmetry. The results outlined here shed light on the details of the electron motion inside an intense laser pulse and explain the strong wakefield asymmetry observed in simulations.", "AI": {"tldr": "Exact analytical formula derived for non-zero transverse momentum of electrons along symmetry axis in laser wakefields, explaining observed wakefield asymmetry.", "motivation": "Laser wakefield theories using envelope approximation predict zero transverse momentum for electrons along propagation axis, but this contradicts observations of wakefield asymmetry in simulations.", "method": "Developed fundamental approach beyond envelope approximation to express transverse momentum of electrons crossing laser pulse, deriving exact analytical formula for non-zero transverse momentum of electrons initially along symmetry axis.", "result": "Derived exact analytical formula showing non-zero transverse momentum for electrons along symmetry axis, explaining strong wakefield asymmetry observed in simulations.", "conclusion": "The exact analytical formula provides deeper understanding of electron motion in intense laser pulses and resolves discrepancy between envelope-based theories and observed wakefield asymmetry."}}
{"id": "2602.13228", "pdf": "https://arxiv.org/pdf/2602.13228", "abs": "https://arxiv.org/abs/2602.13228", "authors": ["Ruben Jakob"], "title": "Corrections to: \"The Willmore flow of Hopf-tori in the 3-sphere\"", "categories": ["math.AP"], "comment": null, "summary": "This erratum addresses a logical mistake in the author's article [Jakob, R. The Willmore flow of Hopf-tori in the $3$-sphere. Journal of Evolution Equations 23, No. 72 (2023)] which resulted in two wrong assertions in parts (II) and (III) of Theorem 1 in the author's cited paper and in an inaccuracy in the formulation of the second part of Proposition 6 in that paper. We will not only point out these mistakes and their corrections, but we will additionally give a concrete counterexample to Statement (III) in Theorem 1 of the author's cited article which will automatically imply the optimality of the corrected version of that statement, as it is formulated in this erratum.", "AI": {"tldr": "Erratum correcting logical errors in previous paper about Willmore flow of Hopf-tori in 3-sphere, fixing Theorem 1 and Proposition 6, with counterexample showing optimality of corrected statement.", "motivation": "To address and correct logical mistakes in the author's previous work on Willmore flow of Hopf-tori in the 3-sphere, specifically errors in Theorem 1 and Proposition 6 that affected the mathematical validity of the original results.", "method": "The erratum identifies specific errors in parts (II) and (III) of Theorem 1 and an inaccuracy in Proposition 6 from the original paper. It provides corrections to these statements and offers a concrete counterexample to Statement (III) in Theorem 1 to demonstrate the necessity and optimality of the corrections.", "result": "The erratum successfully corrects the identified errors in the original paper. The counterexample provided demonstrates that the corrected version of Statement (III) in Theorem 1 is optimal, meaning it cannot be strengthened further without becoming false.", "conclusion": "This erratum rectifies mathematical errors in the original paper, ensuring the corrected results are mathematically sound. The counterexample validates that the corrected formulation represents the best possible statement that can be made about the Willmore flow of Hopf-tori in the 3-sphere."}}
{"id": "2602.14392", "pdf": "https://arxiv.org/pdf/2602.14392", "abs": "https://arxiv.org/abs/2602.14392", "authors": ["Thomas Izgin", "Andreas Meister", "Chi-Wang Shu", "Davide Torlo"], "title": "Flux-Balanced Patankar-type Schemes for the Compressible Euler Equations", "categories": ["math.NA"], "comment": null, "summary": "Positivity preservation of key physical quantities in the context of fluid flows, such as density and internal energy, is an essential property of a numerical scheme as otherwise the solution lacks physical relevance and has a not well-defined equation of state. One time integration technique that is capable of preserving the positivity of quantities for every time step size is the Patankar-trick and its variants. However, in the context of the Euler equations of gas dynamics, we wonder whether the Patankar-trick should be applied to the density and total energy equations or only to one of them. In this work, we discuss one drawback of the schemes when blindly applied to every positive conserved variable and additionally point out how to overcome the issue by balancing the involved numerical fluxes correctly. To illustrate our findings, we investigate modified Patankar--Runge--Kutta (MPRK) schemes in the context of the compressible Euler equations with and without stiff source terms. We discover that it is beneficial to only apply the Patankar-trick in the density equation and to balance the remaining numerical fluxes consistently rather than applying the trick also to the energy equation. This leads also to the preservation of contact discontinuities. We perform numerical experiments to demonstrate that the accuracy of the methods is maintained while the performance of our approach is superior to the traditional application of MPRK schemes.", "AI": {"tldr": "MPRK schemes for Euler equations should apply Patankar-trick only to density equation, not energy equation, to preserve positivity while maintaining accuracy and contact discontinuities.", "motivation": "Positivity preservation of physical quantities like density and internal energy is essential for physically relevant fluid flow simulations. While Patankar-trick methods can preserve positivity for any time step, there's uncertainty about whether to apply it to both density and total energy equations in Euler equations.", "method": "Investigate modified Patankar-Runge-Kutta (MPRK) schemes for compressible Euler equations with/without stiff source terms. Compare traditional approach (applying Patankar-trick to all positive conserved variables) vs new approach (applying only to density equation while balancing remaining numerical fluxes consistently).", "result": "Applying Patankar-trick only to density equation while consistently balancing other numerical fluxes is superior. This approach maintains accuracy, preserves contact discontinuities, and avoids drawbacks of blindly applying the trick to all positive conserved variables.", "conclusion": "For Euler equations, selective application of Patankar-trick to density equation with consistent flux balancing yields better performance than traditional MPRK schemes that apply the trick to both density and energy equations."}}
{"id": "2602.12666", "pdf": "https://arxiv.org/pdf/2602.12666", "abs": "https://arxiv.org/abs/2602.12666", "authors": ["Shijun Liao", "Shijie Qin"], "title": "Non-uniqueness of smooth solutions of the Navier-Stokes equations from almost the same initial conditions", "categories": ["math.AP", "math.NA", "nlin.CD", "physics.comp-ph", "physics.flu-dyn"], "comment": "8 pages, 3 figures", "summary": "Using clean numerical simulation (CNS) which can give very accurate spatiotemporal trajectory of Navier-Stokes turbulence in a finite but long enough interval of time, we give some numerical evidences that the Navier-Stokes equations admit distinct global solutions from almost the same initial conditions whose difference is very small, i.e. even at the order $10^{-40}$ of magnitude. Hopefully these examples could provide some enlightenments for the uniqueness and existence of Navier-Stokes equations, which are related to one Millennium Prize Problem of Clay Institute.", "AI": {"tldr": "Numerical evidence suggests Navier-Stokes equations may have distinct global solutions from nearly identical initial conditions, even with differences as small as 10^-40.", "motivation": "To investigate the uniqueness and existence of solutions to Navier-Stokes equations, which is related to one of the Clay Institute's Millennium Prize Problems. The study aims to provide numerical evidence about whether extremely small differences in initial conditions can lead to distinct global solutions.", "method": "Uses Clean Numerical Simulation (CNS) to obtain highly accurate spatiotemporal trajectories of Navier-Stokes turbulence over finite but long time intervals. The method examines solutions starting from almost identical initial conditions with very small differences (order 10^-40).", "result": "Numerical evidence indicates that Navier-Stokes equations may admit distinct global solutions from almost the same initial conditions, even when the initial difference is extremely small (10^-40 magnitude). This suggests potential non-uniqueness of solutions.", "conclusion": "The findings provide numerical evidence that could challenge the uniqueness of Navier-Stokes solutions and offer insights into the Millennium Prize Problem regarding existence and smoothness of solutions to the Navier-Stokes equations."}}
{"id": "2602.14918", "pdf": "https://arxiv.org/pdf/2602.14918", "abs": "https://arxiv.org/abs/2602.14918", "authors": ["S. Zhang", "M. Mallon", "M. Luo", "J. Thiyagalingam", "P. Tzeferacos", "R. Bingham", "G. Gregori"], "title": "Data-driven modeling of shock physics by physics-informed MeshGraphNets", "categories": ["physics.plasm-ph"], "comment": null, "summary": "High-resolution fluid simulations for plasma physics and astrophysics rely on Particle in cell (PIC) and hydrodynamic solvers (e.g., FLASH) to resolve shock dominated, multiscale phenomena, but their high computational cost severely limits scalability. This motivates the development of learning based surrogate models, which offer a promising route to accelerate these simulations while preserving physical fidelity. In this work, we study the Sedov Taylor shock propagation problem using a physics informed graph based surrogate model, Physics Informed MeshGraphNet (PhyMGN), designed for grid-based hydrodynamics. By incorporating weak physics constraints derived from the Euler equations using finite difference method, the model captures the self similar shock evolution and associated flow structures without explicitly solving the full hydrodynamic equations at each timestep. Comparing to the baseline MeshGraphNet model, PhyMGN is able to generalize beyond the training regime with a higher accuracy and preserves differentiability in parameter space while achieving a substantial reduction in computational cost relative to conventional numerical solvers.", "AI": {"tldr": "Physics-informed graph neural network (PhyMGN) accelerates shock simulations by incorporating Euler equation constraints, achieving better generalization and accuracy than baseline MeshGraphNet while reducing computational cost.", "motivation": "High computational cost of traditional PIC and hydrodynamic solvers (like FLASH) limits scalability for high-resolution plasma physics and astrophysics simulations. Learning-based surrogate models offer promising acceleration while preserving physical fidelity.", "method": "Physics Informed MeshGraphNet (PhyMGN) - a graph-based surrogate model incorporating weak physics constraints derived from Euler equations using finite difference method. Designed for grid-based hydrodynamics to capture shock propagation without solving full hydrodynamic equations at each timestep.", "result": "PhyMGN generalizes beyond training regime with higher accuracy than baseline MeshGraphNet, preserves differentiability in parameter space, and achieves substantial computational cost reduction compared to conventional numerical solvers for Sedov-Taylor shock propagation problem.", "conclusion": "Physics-informed graph neural networks provide an effective approach for accelerating complex fluid simulations while maintaining physical accuracy, offering a promising alternative to traditional high-cost numerical methods for shock-dominated multiscale phenomena."}}
{"id": "2602.13276", "pdf": "https://arxiv.org/pdf/2602.13276", "abs": "https://arxiv.org/abs/2602.13276", "authors": ["Monica Caloi", "Mattia Zanella"], "title": "Supercritical Mass and Condensation in Fokker--Planck Equations for Consensus Formation", "categories": ["math.AP", "cs.MA", "nlin.AO"], "comment": null, "summary": "Inspired by recently developed Fokker--Planck models for Bose--Einstein statistics, we study a consensus formation model with condensation effects driven by a polynomial diffusion coefficient vanishing at the domain boundaries. For the underlying kinetic model, given by a nonlinear Fokker--Planck equation with superlinear drift, it was shown that if the initial mass exceeds a critical threshold, the solution may exhibit finite-time concentration in certain parameter regimes. Here, we show that this supercritical mass phenomenon persists for a broader class of diffusion functions and provide estimates of the critical mass required to induce finite-time loss of regularity.", "AI": {"tldr": "The paper studies a consensus formation model with condensation effects, showing that supercritical mass phenomena persist for broader diffusion functions and providing estimates for critical mass thresholds.", "motivation": "Inspired by Fokker-Planck models for Bose-Einstein statistics, the research aims to understand consensus formation with condensation effects, particularly investigating when finite-time concentration occurs in kinetic models.", "method": "The study analyzes a nonlinear Fokker-Planck equation with superlinear drift and polynomial diffusion coefficients vanishing at domain boundaries. It extends previous results to broader classes of diffusion functions.", "result": "The research demonstrates that supercritical mass phenomena persist for a broader class of diffusion functions and provides estimates for the critical mass required to induce finite-time loss of regularity.", "conclusion": "The findings extend understanding of finite-time concentration phenomena in consensus formation models, showing broader applicability of supercritical mass effects beyond previously studied parameter regimes."}}
{"id": "2602.14405", "pdf": "https://arxiv.org/pdf/2602.14405", "abs": "https://arxiv.org/abs/2602.14405", "authors": ["Tiantian Huang", "Buyang Li", "Rong Tang"], "title": "A convergent finite element method with minimal deformation rate for mean curvature flow", "categories": ["math.NA"], "comment": "77 pages", "summary": "We propose and analyze a fully discrete parametric finite element method with minimal deformation rate (MDR) for simulating the mean curvature flow of general closed surfaces in three dimensions. The method is formulated from a coupled system that enforces the mean curvature flow law for the normal velocity while introducing an artificial tangential velocity that minimizes the deformation-rate energy, thereby preserving mesh quality without requiring remeshing or reparametrization. An $L^{2}$-projected averaged normal vector is used in the scheme to facilitate a rigorous convergence analysis. Within the projected--distance framework, we establish the first complete convergence proof for a parametric finite element method that incorporates the MDR tangential motion without relying on evolution equations for the mean curvature or the normal vector, achieving optimal-order error estimates for finite elements of degree $k \\ge 3$. Numerical experiments corroborate the theoretical results and demonstrate that the proposed MDR method maintains mesh quality comparable to the Barrett--Garcke--N\u00fcrnberg method, for which convergence has not yet been established.", "AI": {"tldr": "A fully discrete parametric finite element method with minimal deformation rate (MDR) for simulating mean curvature flow of 3D surfaces, with optimal-order error estimates and mesh quality preservation.", "motivation": "To develop a parametric finite element method for mean curvature flow that maintains mesh quality without requiring remeshing or reparametrization, while providing rigorous convergence analysis that has been lacking for similar methods.", "method": "A coupled system enforcing mean curvature flow law for normal velocity with artificial tangential velocity minimizing deformation-rate energy. Uses L\u00b2-projected averaged normal vector for analysis. Formulated within projected-distance framework with finite elements of degree k \u2265 3.", "result": "First complete convergence proof for parametric finite element method with MDR tangential motion, achieving optimal-order error estimates. Numerical experiments show mesh quality comparable to Barrett-Garcke-N\u00fcrnberg method (which lacks convergence proof).", "conclusion": "The MDR method successfully simulates mean curvature flow while preserving mesh quality and providing rigorous convergence analysis, addressing limitations of existing methods that either lack convergence proofs or require frequent remeshing."}}
{"id": "2602.13337", "pdf": "https://arxiv.org/pdf/2602.13337", "abs": "https://arxiv.org/abs/2602.13337", "authors": ["Dominic M. Robe", "Elnaz Hajizadeh"], "title": "StrAPS: Structural Angular Power Spectrum for Discovering Novel Morphologies in Block Copolymers", "categories": ["cond-mat.soft", "physics.comp-ph"], "comment": null, "summary": "The morphologies of phase separating systems have formal distinctions such as symmetry groups, but the analysis protocol for labeling a particular phase field with a morphology requires manual expertise, arbitrary thresholds, or established signatures. In this work, it is investigated if the angular power spectrum of the 3D structure factor can discriminate between morphologies. The 3D structure factor is computed on configurations of phase separating block copolymers generated by coarse-grained molecular dynamics simulations. The shell of structure factor values containing the primary peaks is isolated. This 2D field on a sphere is decomposed into spherical harmonic modes of even polynomial degree $\\ell\\le 12$, then further reduced to the rotationally invariant angular power spectrum. It is found that these few coefficients for low $\\ell$ discriminate robustly between different morphologies. This analysis serves as an automatic tool for flagging novel structures, without a need to enumerate the plausible morphologies in advance.", "AI": {"tldr": "The angular power spectrum of 3D structure factors can automatically discriminate between different phase separation morphologies without manual expertise or predefined signatures.", "motivation": "Current methods for labeling phase separation morphologies require manual expertise, arbitrary thresholds, or established signatures, which limits automated analysis and discovery of novel structures.", "method": "Compute 3D structure factor from phase separating block copolymer simulations, isolate primary peak shell, decompose into spherical harmonics (even degree \u2113\u226412), and reduce to rotationally invariant angular power spectrum coefficients.", "result": "Few coefficients for low \u2113 robustly discriminate between different morphologies, enabling automatic identification without needing to enumerate all possible structures in advance.", "conclusion": "The angular power spectrum provides an automatic tool for flagging novel phase separation structures, overcoming limitations of manual analysis methods."}}
{"id": "2602.13528", "pdf": "https://arxiv.org/pdf/2602.13528", "abs": "https://arxiv.org/abs/2602.13528", "authors": ["M. Kavtaradze", "G. Mamatsashvili", "G. Chagelishvili", "E. Uchava"], "title": "Leveling of MHD turbulence imbalance in shear flows", "categories": ["physics.space-ph", "astro-ph.SR", "physics.flu-dyn", "physics.plasm-ph"], "comment": "7 pages, 4 figures, submitted to Physical Review Journals", "summary": "We investigate magnetohydrodynamic (MHD) turbulence in plane shear flows with a streamwise background magnetic field in the super-Alfv\u00e9nic regime. We show that the large-scale velocity shear suppresses turbulence imbalance, driving the system toward a balanced state -- the energies of counter-propagating Alfv\u00e9n waves become essentially equal, even at initially perfectly imbalanced Alfv\u00e9nic turbulence. This balancing is due to the shear-induced linear non-modal dynamics of Alfv\u00e9n waves, including their transient growth and over-reflection. This linear route to balancing turbulence is new -- fundamentally different from nonlinear ones operative in shearless MHD turbulence -- and have direct implications for understanding balanced/imbalanced MHD turbulence in the solar wind, which is modeled as a shear flow in a thermodynamically complex plasma.", "AI": {"tldr": "Shear flows suppress turbulence imbalance, driving super-Alfv\u00e9nic MHD turbulence toward balanced state through linear non-modal dynamics.", "motivation": "To understand how large-scale velocity shear affects turbulence imbalance in MHD shear flows with streamwise magnetic fields, particularly relevant for solar wind modeling.", "method": "Investigation of MHD turbulence in plane shear flows with streamwise background magnetic field in super-Alfv\u00e9nic regime, analyzing shear-induced linear non-modal dynamics including transient growth and over-reflection of Alfv\u00e9n waves.", "result": "Large-scale velocity shear suppresses turbulence imbalance, driving system toward balanced state where energies of counter-propagating Alfv\u00e9n waves become essentially equal, even from initially perfectly imbalanced conditions.", "conclusion": "Shear provides a new linear route to balancing turbulence fundamentally different from nonlinear mechanisms in shearless MHD turbulence, with direct implications for understanding balanced/imbalanced turbulence in solar wind shear flows."}}
{"id": "2602.13295", "pdf": "https://arxiv.org/pdf/2602.13295", "abs": "https://arxiv.org/abs/2602.13295", "authors": ["Li Chen", "Li Wang"], "title": "Normalized solutions of quasilinear Schr\u00f6dinger-Poisson system with critical nonlinear term in bounded domain", "categories": ["math.AP"], "comment": "20 pages", "summary": "This work examines a quasilinear Schr\u00f6dinger-Poisson system involving a critical nonlinearity, expressed as \\[ -\u0394u + \u03c6u + \u03bbu = |u|^{q-2} u + |u|^4 u, \\quad x \\in \u03a9_r, \\] \\[ -\u0394\u03c6- \\varepsilon^4 \u0394_4 \u03c6= u^2, \\qquad\\qquad\\qquad\\quad\\ x \\in \u03a9_r, \\] \\[ \\enspace u = \u03c6= 0, \\qquad\\qquad\\qquad\\qquad\\qquad\\enspace\\ \\ \\,x \\in \\partial \u03a9_r \\] subject to the normalized condition \\[ \\int_{\u03a9_r} |u|^2\\, \\mathrm d x = b^2. \\] Here $\\varepsilon > 0$, $q \\in (2, 8/3)$, $\u03a9_r \\subset \\mathbb R^3$ is a bounded domain. By means of a truncation method combined with genus theory, we establish the existence of multiple families of normalized solutions. Due to the presence of a critical exponent in the nonlinear term, the associated energy functional fails to satisfy the usual compactness properties. To address this issue, we invoke the concentration-compactness principle. Furthermore, we derive the asymptotic result that the aforementioned system reduces to the classical Schr\u00f6dinger-Poisson system (with $\\varepsilon = 0$). Our findings extend several recent results concerning problems of this type.", "AI": {"tldr": "The paper studies a quasilinear Schr\u00f6dinger-Poisson system with critical nonlinearity and normalized constraint, proving existence of multiple normalized solutions using truncation methods and genus theory, and showing convergence to classical system as \u03b5\u21920.", "motivation": "To investigate normalized solutions for a quasilinear Schr\u00f6dinger-Poisson system with critical nonlinearity, addressing the challenge of compactness loss due to critical exponent and extending recent results in this area.", "method": "Uses truncation method combined with genus theory to establish existence of multiple families of normalized solutions. Employs concentration-compactness principle to handle compactness issues from critical exponent. Derives asymptotic convergence to classical system.", "result": "Proves existence of multiple families of normalized solutions for the quasilinear system. Shows the system reduces to classical Schr\u00f6dinger-Poisson system as \u03b5\u21920, extending several recent results in this field.", "conclusion": "The paper successfully establishes existence results for normalized solutions in a critical quasilinear Schr\u00f6dinger-Poisson system and demonstrates asymptotic convergence to the classical case, contributing to the understanding of such nonlinear systems."}}
{"id": "2602.14449", "pdf": "https://arxiv.org/pdf/2602.14449", "abs": "https://arxiv.org/abs/2602.14449", "authors": ["Zhuang-Ao He", "Meiyue Shao"], "title": "On Two-Stage Householder Orthogonalization", "categories": ["math.NA"], "comment": null, "summary": "Two-stage orthogonalization is essential in numerical algorithms such as Krylov subspace methods. For this task we need to orthogonalize a matrix $A$ against another matrix $V$ with orthonormal columns. A common approach is to employ the block Gram--Schmidt algorithm. However, its stability largely depends on the condition number of $[V,A]$. While performing a Householder orthogonalization on $[V,A]$ is unconditionally stable, it does not utilize the knowledge that $V$ has orthonormal columns. To address these issues, we propose a two-stage Householder orthogonalization algorithm based on the generalized Householder transformation. Instead of explicitly orthogonalizing the entire $V$, our algorithm only needs to orthogonalizes a square submatrix of $V$. Theoretical analysis and numerical experiments demonstrate that our method is also unconditionally stable.", "AI": {"tldr": "Proposes a two-stage Householder orthogonalization algorithm that only needs to orthogonalize a square submatrix of V, achieving unconditional stability while leveraging V's orthonormal structure.", "motivation": "Two-stage orthogonalization is crucial for numerical algorithms like Krylov subspace methods, but existing approaches have limitations. Block Gram-Schmidt stability depends on condition number, while full Householder orthogonalization on [V,A] is unconditionally stable but doesn't utilize V's orthonormal structure.", "method": "Proposes a two-stage Householder orthogonalization algorithm based on generalized Householder transformation. Instead of orthogonalizing entire V, the algorithm only needs to orthogonalize a square submatrix of V, making it more efficient while maintaining stability.", "result": "Theoretical analysis and numerical experiments demonstrate that the proposed method is unconditionally stable, overcoming the condition number dependency of block Gram-Schmidt while being more efficient than full Householder orthogonalization.", "conclusion": "The proposed two-stage Householder algorithm provides an unconditionally stable solution for orthogonalizing A against V with orthonormal columns, offering both stability and computational efficiency by leveraging V's known structure."}}
{"id": "2602.13438", "pdf": "https://arxiv.org/pdf/2602.13438", "abs": "https://arxiv.org/abs/2602.13438", "authors": ["Sean D. Lam", "Roberto dos Reis"], "title": "Quantum Algorithm Framework for Phase-Contrast Transmission Electron Microscopy Image Simulation", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "comment": "28 pages, 9 figures (including appendices); supplementary code available at https://github.com/QuScope/examples-applications/blob/main/notebooks/Quantum_ctem_paper_full_example.ipynb", "summary": "We present a quantum algorithmic framework for simulating phase-contrast transmission electron microscopy (CTEM) image formation using a fault-tolerant, gate-based quantum circuit model. The electron wavefield on an $N\\times N$ grid is amplitude-encoded into a $2\\log_2 N$-qubit register. Free-space propagation and objective-lens aberrations are implemented via two-dimensional quantum Fourier transforms (QFTs) and diagonal phase operators in reciprocal space, while specimen interaction is modeled under the weak phase object approximation (WPOA) as a position-dependent phase grating. We validate projected potentials, contrast transfer function (CTF) behavior, and image contrast trends against classical multislice simulations for MoS$_2$ over experimentally relevant parameters, and provide resource estimates and key assumptions that determine end-to-end runtime. While extracting complete $N\\times N$ intensity images requires $O(N^2/\u03b5^2)$ measurements that preclude advantage for full-image reconstruction, the framework enables quantum advantage for tasks requiring Fourier-space queries, global image statistics, or phase-coherent observables inaccessible to classical intensity-only detection. This framework provides a physics-grounded mapping from CTEM theory to quantum circuits and establishes a baseline for extending toward full multislice and inelastic scattering models.", "AI": {"tldr": "Quantum circuit framework for simulating phase-contrast TEM image formation, enabling quantum advantage for Fourier-space queries and phase-coherent observables.", "motivation": "To develop a quantum algorithmic framework for simulating transmission electron microscopy (TEM) that can provide quantum advantage for certain imaging tasks, particularly those requiring Fourier-space analysis and phase information that classical intensity-only detection cannot access.", "method": "Encodes electron wavefield on N\u00d7N grid into 2log\u2082N-qubit register, implements free-space propagation and lens aberrations via 2D quantum Fourier transforms and diagonal phase operators, models specimen interaction using weak phase object approximation as position-dependent phase grating.", "result": "Validated against classical multislice simulations for MoS\u2082, showing correct projected potentials, contrast transfer function behavior, and image contrast trends. While full image reconstruction requires O(N\u00b2/\u03b5\u00b2) measurements (no advantage), the framework enables quantum advantage for Fourier-space queries, global statistics, and phase-coherent observables.", "conclusion": "The framework provides a physics-grounded mapping from CTEM theory to quantum circuits and establishes a baseline for extending toward more complex models like full multislice and inelastic scattering simulations."}}
{"id": "2602.13644", "pdf": "https://arxiv.org/pdf/2602.13644", "abs": "https://arxiv.org/abs/2602.13644", "authors": ["Shibotosh Biswas", "Ankush Bhaskar", "SG Abitha", "Omkar Dhamane", "Sanchita Pal", "Dibyendu Chakrabarty", "Vipin K Yadav"], "title": "Unprecedented Multipoint Observation of Spatially Varying ICME Turbulence of Different Ages during October 2024 Extreme Solar Storm at 1 AU", "categories": ["astro-ph.SR", "physics.plasm-ph", "physics.space-ph"], "comment": "Submitted to the Astrophysical Journal Supplement Series", "summary": "Understanding turbulence in interplanetary coronal mass ejections is fundamental to space plasma research and critical for assessing the impact of space weather on geospace. Turbulence governs energy cascade, plasma heating, magnetic reconnection, and solar wind magnetosphere coupling, thereby influencing both ICME evolution and geoeffectiveness. While previous event-based and statistical studies have examined ICME turbulence and its radial evolution in great detail, no significant measurements of ICME magnetic turbulence at a specific vantage point have been made using multiple observatories separated azimuthally. Here, we present the first multipoint analysis of MHD turbulence across ICME plasma regions, using four spacecraft at the Sun-Earth L1 point, separated by 80 RE along the dawn-dusk direction. Previous studies reveal that ICME shocks, sheaths, and magnetic clouds are highly non-uniform, with strong azimuthal variability. Using high-resolution magnetic field observations from ISRO's Aditya-L1, NASA's Wind and ACE, and NOAA's DSCOVR, we analyze turbulence associated with the 10th October 2024 solar storm, which triggered the second-strongest geomagnetic storm of solar cycle 25. Our results reveal significant variability and differing turbulence maturity across small separations, supported by analysis of field-aligned and perpendicular magnetic field cascades, indicating strong anisotropies. Sheath turbulence is substantially modified by shock induced energy injection. Evidence of compressible turbulence and plasma energization at the flux rope interaction region indicates that internal processes, such as magnetic reconnection, strongly influence ICME plasma evolution, highlighting pronounced spatial variability in turbulence and plasma states observed by multiple L1 monitors near Earth and underscoring their potential role in space weather impacts.", "AI": {"tldr": "First multipoint analysis of MHD turbulence across ICME plasma regions using four spacecraft at L1 point separated azimuthally, revealing significant variability in turbulence maturity and strong anisotropies.", "motivation": "Understanding ICME turbulence is fundamental for space plasma research and critical for assessing space weather impacts on geospace, but previous studies lacked multipoint measurements from azimuthally separated observatories.", "method": "Used high-resolution magnetic field data from four spacecraft (Aditya-L1, Wind, ACE, DSCOVR) at Sun-Earth L1 point separated by 80 RE along dawn-dusk direction to analyze turbulence during October 10, 2024 solar storm.", "result": "Found significant variability and differing turbulence maturity across small separations, with strong anisotropies in field-aligned/perpendicular cascades. Sheath turbulence modified by shock energy injection, and evidence of compressible turbulence/plasma energization at flux rope interaction region.", "conclusion": "Internal processes like magnetic reconnection strongly influence ICME plasma evolution, highlighting pronounced spatial variability in turbulence observed by multiple L1 monitors and underscoring their role in space weather impacts."}}
{"id": "2602.13364", "pdf": "https://arxiv.org/pdf/2602.13364", "abs": "https://arxiv.org/abs/2602.13364", "authors": ["Xiangqian Yan", "Yongsheng Li", "Juan Huang", "Jianhua Huang", "Wei Yan"], "title": "The Cauchy problem for the generalized KdV equation in the Sobolev space $H^{s}(\\mathbf{R})$", "categories": ["math.AP"], "comment": "41 Pages", "summary": "In this paper, we are concerned with the Cauchy problem for the generalized KdV equation with random data and rough data. Firstly, when $s\\in\\mathbf{R}$, by using the initial value randomization technique introduced by Shen et al. (arXiv:2111.11935) and the construction of appropriate auxiliary spaces, we establish the almost sure local well-posedness of the generalized KdV equation in $H^{s}(\\mathbf{R})$, which improves Theorem 1.3 of Hwang and Kwak (Proc. Amer. Math. Soc. 146(2018), 267-280.) and Theorem 1.5 of Yan et al.(arXiv:2011.07128.). Secondly, by using the well-posedness results proved in Theorem 1.1, for $f\\in H^{s}(\\mathbf{R}),\\, s\\in\\mathbf{R}$, we obtain \\begin{eqnarray*} &&\\mathbb{P}\\left(\\left\\{\u03c9:\\lim_{t\\rightarrow0}\\|u(t,x)-U(t)f^\u03c9(x)\\|_{L_{x}^{\\infty}}=0\\right\\}\\right)=1, \\end{eqnarray*} which improves Theorem 1.6 of Yan et al.(arXiv:2011.07128.). Thirdly, by using the dyadic decomposition and constructing appropriate function spaces, we establish nonlinear smoothing for the generalized KdV equation with rough data. Furthermore, by using this estimate, when data $f\\in H^{s}(\\mathbf{R})\\cap\\hat{L}^{\\infty}(\\mathbf{R}),\\, s>\\frac{1}{2}-\\frac{2}{k+1},\\, k\\geq4$, we obtain \\begin{eqnarray*} &&\\lim_{|x|\\rightarrow \\infty}u(t,x)=0,\\quad t\\in[0, T]. \\end{eqnarray*} In particular, for $f(x)\\in H^{s}(\\mathbf{R}),\\,s>\\frac{1}{2}-\\frac{2}{k+1},\\,k\\geq4$, we prove \\begin{eqnarray*} &&\\lim_{|x|\\rightarrow \\infty}(u(t,x)-U(t)f(x))=0. \\end{eqnarray*} Finally, by using Theorem 1.1, when $f\\in H^{s}(\\mathbf{R}),\\, s\\in\\mathbf{R}$, we obtain \\begin{eqnarray*} &&\\mathbb{P}\\left(\\left\\{\u03c9: \\forall t\\in I_\u03c9, \\lim_{|x|\\rightarrow \\infty}\\left(u(t,x)-U(t)f^\u03c9(x)\\right)=0\\right\\}\\right)=1. \\end{eqnarray*}", "AI": {"tldr": "This paper establishes improved well-posedness results for the generalized KdV equation with random and rough initial data, proving almost sure local well-posedness in H^s(R) for all s\u2208R, convergence properties, nonlinear smoothing effects, and decay at spatial infinity.", "motivation": "To improve existing results on the Cauchy problem for generalized KdV equation with random and rough data, addressing limitations in previous theorems by Hwang & Kwak and Yan et al., and to establish stronger convergence and decay properties.", "method": "Uses initial value randomization technique, construction of appropriate auxiliary spaces, dyadic decomposition, and specialized function spaces. Combines probabilistic methods with PDE analysis techniques.", "result": "1) Almost sure local well-posedness in H^s(R) for all s\u2208R, improving previous theorems. 2) Almost sure convergence of solution to linear evolution. 3) Nonlinear smoothing effects for rough data. 4) Decay at spatial infinity for solutions with data in H^s\u2229L\u0302^\u221e. 5) Almost sure decay at infinity for random data.", "conclusion": "The paper significantly advances the theory of generalized KdV equation with random and rough data, establishing comprehensive well-posedness, convergence, smoothing, and decay properties that improve upon multiple existing results in the literature."}}
{"id": "2602.14504", "pdf": "https://arxiv.org/pdf/2602.14504", "abs": "https://arxiv.org/abs/2602.14504", "authors": ["Naveed Ahmed", "Abhinav Jha"], "title": "Adaptive Finite Elements with Algebraic Stabilization for Convection-Dominated Transport", "categories": ["math.NA"], "comment": null, "summary": "We present a numerical investigation of residual-based a posteriori error estimation for finite element discretizations of convection--diffusion equations stabilized by algebraic flux correction and related algebraic stabilization techniques. In particular, we consider AFC schemes employing the BJK and Monolithic Convex (MC) limiters and algebraically stabilized methods including MUAS, SMUAS, and the BBK approach. The performance of the estimators and limiters are studied on adaptively refined meshes for several two-dimensional test problems, including boundary layers, interior layers, and a nonlinear convection problem with solution-dependent transport.\n  The experiments assess accuracy, preservation of the discrete maximum principle, adaptive mesh behaviour, and computational efficiency. The results show that the interaction between stabilization and a posteriori error estimation depends strongly on mesh alignment and on the character of the convection field. In particular, for problems with moving or curved layers, the behaviour of the limiters differs significantly: strongly upwind-biased limiters provide the most accurate solutions, while smoother algebraic stabilizations lead to more efficient nonlinear iterations. The study also indicates that residual-based estimators remain reliable for both linear and nonlinear problems but may react to changes in limiter activation during adaptive refinement.\n  Overall, the numerical results clarify the practical behaviour of several widely used stabilization techniques within an adaptive framework and highlight aspects that are not yet fully explained by the current theory, particularly for nonlinear transport problems.", "AI": {"tldr": "Numerical study of residual-based a posteriori error estimation for finite element discretizations of convection-diffusion equations with algebraic stabilization techniques, comparing performance on adaptive meshes for various 2D test problems.", "motivation": "To investigate the interaction between algebraic stabilization techniques (AFC schemes and algebraically stabilized methods) and residual-based a posteriori error estimation in adaptive finite element frameworks for convection-diffusion problems, particularly for problems with challenging features like boundary layers and nonlinear transport.", "method": "Numerical investigation using finite element discretizations with algebraic flux correction (AFC) schemes (BJK and MC limiters) and algebraically stabilized methods (MUAS, SMUAS, BBK). Performance studied on adaptively refined meshes for 2D test problems including boundary layers, interior layers, and nonlinear convection problems with solution-dependent transport.", "result": "The interaction between stabilization and error estimation strongly depends on mesh alignment and convection field characteristics. For moving/curved layers, strongly upwind-biased limiters provide most accurate solutions, while smoother algebraic stabilizations lead to more efficient nonlinear iterations. Residual-based estimators remain reliable for linear and nonlinear problems but may react to limiter activation changes during adaptive refinement.", "conclusion": "The study clarifies practical behavior of stabilization techniques in adaptive frameworks and highlights aspects not fully explained by current theory, particularly for nonlinear transport problems. Results provide insights into trade-offs between accuracy and computational efficiency for different stabilization approaches."}}
{"id": "2602.13805", "pdf": "https://arxiv.org/pdf/2602.13805", "abs": "https://arxiv.org/abs/2602.13805", "authors": ["Yutong Du", "Zicheng Liu", "Yi Huang", "Bazargul Matkerim", "Bo Qi", "Yali Zong", "Peixian Han"], "title": "Fast Physics-Driven Untrained Network for Highly Nonlinear Inverse Scattering Problems", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "Untrained neural networks (UNNs) offer high-fidelity electromagnetic inverse scattering reconstruction but are computationally limited by high-dimensional spatial-domain optimization. We propose a Real-Time Physics-Driven Fourier-Spectral (PDF) solver that achieves sub-second reconstruction through spectral-domain dimensionality reduction. By expanding induced currents using a truncated Fourier basis, the optimization is confined to a compact low-frequency parameter space supported by scattering measurements. The solver integrates a contraction integral equation (CIE) to mitigate high-contrast nonlinearity and a contrast-compensated operator (CCO) to correct spectral-induced attenuation. Furthermore, a bridge-suppressing loss is formulated to enhance boundary sharpness between adjacent scatterers. Numerical and experimental results demonstrate a 100-fold speedup over state-of-the-art UNNs with robust performance under noise and antenna uncertainties, enabling real-time microwave imaging applications.", "AI": {"tldr": "PDF solver enables real-time electromagnetic inverse scattering by reducing optimization to compact spectral domain, achieving 100x speedup over UNNs with robust noise performance.", "motivation": "Untrained neural networks provide high-fidelity electromagnetic inverse scattering but suffer from computational bottlenecks due to high-dimensional spatial-domain optimization, limiting real-time applications.", "method": "Proposes Real-Time Physics-Driven Fourier-Spectral (PDF) solver using truncated Fourier basis expansion to confine optimization to low-frequency spectral domain. Integrates contraction integral equation (CIE) for high-contrast nonlinearity mitigation, contrast-compensated operator (CCO) for spectral-induced attenuation correction, and bridge-suppressing loss for boundary sharpness enhancement.", "result": "Achieves sub-second reconstruction with 100-fold speedup over state-of-the-art UNNs while maintaining robust performance under noise and antenna uncertainties, enabling real-time microwave imaging.", "conclusion": "The PDF solver successfully addresses computational limitations of UNNs through spectral-domain dimensionality reduction, making real-time electromagnetic inverse scattering practical for microwave imaging applications."}}
{"id": "2602.13425", "pdf": "https://arxiv.org/pdf/2602.13425", "abs": "https://arxiv.org/abs/2602.13425", "authors": ["Juan Pablo Cabeza", "Gabrielle Nornberg", "Disson dos Prazeres"], "title": "Strong maximum principle for fully nonlinear nonlocal problems", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study solvability and qualitative properties of nonnegative solutions for a sublinear nonlocal problem with fully nonlinear structure in the form $$\n  \\mathcal{M}^{\\pm}[u]+a(x)u^{q}(x)=0 \\; \\text{ in }\u03a9,\\qquad u\\geq 0 \\; \\text{ in }\u03a9. $$ Here $\u03a9\\subset \\mathbb{R}^n$ is a bounded $C^{1,1}$ convex domain, $\\mathcal{M}^{ \\pm}$ stands for nonlocal Pucci extremal operators defined in a class $\\mathcal{L}_*$ of homogeneous kernels, $q\\in(0,1)$, and $a$ is a possibly sign-changing weight.\n  We introduce a new nonlocal hypothesis on the negative part of the solution outside the domain, which together with the negative part of the potential, influences the formation of dead cores and cannot be removed. Our approach relies on uniform bounds from below of the maximum of nontrivial solutions through Liouville theorems, and on a Hopf lemma for viscosity solutions driven by fully nonlinear operators, which we also prove.", "AI": {"tldr": "Study of solvability and qualitative properties of nonnegative solutions for sublinear nonlocal problems with fully nonlinear structure, focusing on dead core formation influenced by nonlocal hypothesis and sign-changing weight.", "motivation": "To understand how nonlocal effects and sign-changing weights affect the existence and properties of nonnegative solutions to fully nonlinear sublocal problems, particularly the formation of dead cores where solutions vanish.", "method": "Introduce new nonlocal hypothesis on negative part of solution outside domain; use uniform bounds from below of maximum of nontrivial solutions through Liouville theorems; prove Hopf lemma for viscosity solutions driven by fully nonlinear operators.", "result": "Established solvability conditions and qualitative properties for nonnegative solutions; showed that nonlocal hypothesis together with negative part of potential influences dead core formation and cannot be removed.", "conclusion": "The nonlocal hypothesis on negative part of solution outside domain plays crucial role in dead core formation for sublinear nonlocal problems with fully nonlinear structure and sign-changing weights."}}
{"id": "2602.14588", "pdf": "https://arxiv.org/pdf/2602.14588", "abs": "https://arxiv.org/abs/2602.14588", "authors": ["Alexander Freiszlinger", "Dirk Pauly", "Dirk Praetorius", "Michael Schomburg"], "title": "New a posteriori error estimates for full-space transmission problems", "categories": ["math.NA"], "comment": null, "summary": "In the present work, we derive functional upper bounds for the potential error arising from finite-element boundary-element coupling formulations for a nonlinear Poisson-type transmission problem. The proposed a posteriori error estimates are independent of the precise discretization scheme and provide guaranteed upper bounds for the potential error. The computation of these upper bounds is based on the solutions of local auxiliary finite element problems on patches in the interior domain and in a strip domain along the coupling boundary. Numerical experiments illustrate the performance of the proposed error estimation strategy for a related adaptive mesh-refinement strategy.", "AI": {"tldr": "Derives guaranteed functional upper bounds for potential error in FEM-BEM coupling for nonlinear Poisson transmission problems using local auxiliary problems.", "motivation": "To provide reliable error estimation for finite-element boundary-element coupling formulations in nonlinear Poisson-type transmission problems, ensuring guaranteed upper bounds independent of specific discretization schemes.", "method": "Develops a posteriori error estimates using local auxiliary finite element problems solved on patches in the interior domain and along the coupling boundary strip.", "result": "Proposed error estimates provide guaranteed upper bounds for potential error, with numerical experiments demonstrating performance for adaptive mesh-refinement strategies.", "conclusion": "The method offers reliable error estimation for FEM-BEM coupling in nonlinear transmission problems, supporting adaptive refinement strategies with guaranteed error bounds."}}
{"id": "2602.13811", "pdf": "https://arxiv.org/pdf/2602.13811", "abs": "https://arxiv.org/abs/2602.13811", "authors": ["Suhas Suresh Bharadwaj", "Reuben Thomas Thovelil"], "title": "A Unified Physics-Informed Neural Network for Modeling Coupled Electro- and Elastodynamic Wave Propagation Using Three-Stage Loss Optimization", "categories": ["cs.NE", "cs.LG", "physics.comp-ph"], "comment": "6 pages, 2 figures", "summary": "Physics-Informed Neural Networks present a novel approach in SciML that integrates physical laws in the form of partial differential equations directly into the NN through soft constraints in the loss function. This work studies the application of PINNs to solve a one dimensional coupled electro-elastodynamic system modeling linear piezoelectricity in stress-charge form, governed by elastodynamic and electrodynamic equations. Our simulation employs a feedforward architecture, mapping space-time coordinates to mechanical displacement and electric potential. Our PINN model achieved global relative L2 errors of 2.34 and 4.87 percent for displacement and electric potential respectively. The results validate PINNs as effective mesh free solvers for coupled time-dependent PDE systems, though challenges remain regarding error accumulation and stiffness in coupled eigenvalue systems.", "AI": {"tldr": "PINNs applied to solve 1D coupled electro-elastodynamic system for linear piezoelectricity, achieving ~2-5% relative L2 errors for displacement and electric potential.", "motivation": "To explore Physics-Informed Neural Networks as mesh-free solvers for coupled time-dependent PDE systems, specifically for linear piezoelectricity problems governed by elastodynamic and electrodynamic equations.", "method": "Used feedforward PINN architecture mapping space-time coordinates to mechanical displacement and electric potential, incorporating physical laws as soft constraints in the loss function to solve the coupled electro-elastodynamic system.", "result": "Achieved global relative L2 errors of 2.34% for displacement and 4.87% for electric potential, validating PINNs as effective mesh-free solvers for coupled time-dependent PDE systems.", "conclusion": "PINNs are effective for solving coupled electro-elastodynamic systems, though challenges remain regarding error accumulation and stiffness in coupled eigenvalue systems."}}
{"id": "2602.13501", "pdf": "https://arxiv.org/pdf/2602.13501", "abs": "https://arxiv.org/abs/2602.13501", "authors": ["Jo\u00e3o Marcos do \u00d3", "Guozhen Lu", "Raon\u00ed Ponciano"], "title": "Radial Sobolev embeddings on spherically symmetric Riemannian manifolds", "categories": ["math.AP"], "comment": null, "summary": "We study Sobolev spaces of radial functions on spherically symmetric Riemannian manifolds. Using geodesic polar coordinates, we give a sharp one-dimensional reduction: a radial function belongs to the Sobolev space on the manifold if and only if its radial representation lies in an associated weighted Sobolev space on an interval, with weights determined explicitly by the metric. This characterization allows us to prove optimal Sobolev-type embeddings for radial functions into weighted Lebesgue spaces on both bounded and unbounded spherically symmetric manifolds. As further consequences, we establish new radial lemmas and decay estimates that capture the precise behaviour of radial Sobolev functions near the origin and at infinity. Our results unify and extend the classical radial embeddings in Euclidean and hyperbolic spaces.", "AI": {"tldr": "Sharp one-dimensional reduction of Sobolev spaces for radial functions on spherically symmetric Riemannian manifolds via geodesic polar coordinates, leading to optimal embeddings and decay estimates.", "motivation": "To characterize Sobolev spaces of radial functions on spherically symmetric Riemannian manifolds and establish optimal Sobolev-type embeddings that unify and extend classical results in Euclidean and hyperbolic spaces.", "method": "Using geodesic polar coordinates to reduce the problem to one dimension: a radial function belongs to the Sobolev space on the manifold if and only if its radial representation lies in an associated weighted Sobolev space on an interval, with weights determined explicitly by the metric.", "result": "Proved optimal Sobolev-type embeddings for radial functions into weighted Lebesgue spaces on both bounded and unbounded spherically symmetric manifolds. Established new radial lemmas and decay estimates capturing precise behavior near origin and infinity.", "conclusion": "The results provide a unified framework for radial Sobolev spaces on spherically symmetric manifolds, extending classical embeddings from Euclidean and hyperbolic spaces to more general geometric settings."}}
{"id": "2602.14609", "pdf": "https://arxiv.org/pdf/2602.14609", "abs": "https://arxiv.org/abs/2602.14609", "authors": ["Paola Boito", "Dario Fasino", "Beatrice Meini"], "title": "Advances on the recovery of (perturbed) Cauchy matrices", "categories": ["math.NA"], "comment": null, "summary": "Given a (possibly approximate) Cauchy matrix, how can we efficiently compute its generators? Expanding on previous work by Liesen and Luce [Linear Algebra Appl. 493 (2016) 261--280], we present a general family of algorithms for Cauchy parameter recovery, together with new error estimates. We also introduce a displacement-based approximation, which leads to a new algorithm for Cauchy parameter recovery. Numerical experiments show that the algorithm based on the displacement approximation is generally more accurate than the other algorithms.", "AI": {"tldr": "New algorithms for recovering generators of Cauchy matrices with improved accuracy using displacement approximations", "motivation": "Need efficient methods to compute generators of (possibly approximate) Cauchy matrices, building on previous work by Liesen and Luce", "method": "Presents general family of algorithms for Cauchy parameter recovery with new error estimates, introduces displacement-based approximation leading to new algorithm", "result": "Numerical experiments show displacement-based algorithm is generally more accurate than other algorithms", "conclusion": "Displacement approximation provides superior accuracy for Cauchy parameter recovery compared to existing methods"}}
{"id": "2602.13525", "pdf": "https://arxiv.org/pdf/2602.13525", "abs": "https://arxiv.org/abs/2602.13525", "authors": ["K. Ammari", "F. Hassine", "L. Tebou"], "title": "Regularity and stability of two coupled Euler-Bernoulli equations with a localized singular structural damping", "categories": ["math.AP"], "comment": null, "summary": "This paper is concerned with the study of regularity and stability properties of two Euler-Bernoulli beam equations with localized singular damping. Under suitable regularity assumptions on the damping coefficient, we establish Gevrey regularity for the semigroup generated by the associated operator. Furthermore, for a broader class of damping mechanisms, including less regular damping, we derive uniform stability result. These findings provide a detailed description of the long-term behavior of the corresponding dynamical systems.", "AI": {"tldr": "The paper studies regularity and stability properties of Euler-Bernoulli beam equations with localized singular damping, establishing Gevrey regularity for the semigroup and uniform stability results for various damping mechanisms.", "motivation": "To understand the long-term behavior of Euler-Bernoulli beam equations with localized singular damping, which is important for analyzing structural stability and control of beam systems with irregular damping mechanisms.", "method": "The authors study two Euler-Bernoulli beam equations with localized singular damping. They establish Gevrey regularity for the semigroup generated by the associated operator under suitable regularity assumptions on the damping coefficient, and derive uniform stability results for a broader class of damping mechanisms including less regular damping.", "result": "The paper establishes Gevrey regularity for the semigroup generated by the operator associated with the beam equations under appropriate damping coefficient regularity. Additionally, uniform stability results are obtained for a wider class of damping mechanisms, including those with less regularity.", "conclusion": "The findings provide a detailed description of the long-term behavior of the corresponding dynamical systems, showing that even with localized singular damping, the beam equations exhibit good regularity properties and stability characteristics under appropriate conditions."}}
{"id": "2602.14757", "pdf": "https://arxiv.org/pdf/2602.14757", "abs": "https://arxiv.org/abs/2602.14757", "authors": ["Erik Burman", "Mats G. Larson", "Karl Larsson", "Jonatan Vallin"], "title": "Solving Inverse Parametrized Problems via Finite Elements and Extreme Learning Networks", "categories": ["math.NA", "cs.LG"], "comment": null, "summary": "We develop an interpolation-based reduced-order modeling framework for parameter-dependent partial differential equations arising in control, inverse problems, and uncertainty quantification. The solution is discretized in the physical domain using finite element methods, while the dependence on a finite-dimensional parameter is approximated separately. We establish existence, uniqueness, and regularity of the parametric solution and derive rigorous error estimates that explicitly quantify the interplay between spatial discretization and parameter approximation.\n  In low-dimensional parameter spaces, classical interpolation schemes yield algebraic convergence rates based on Sobolev regularity in the parameter variable. In higher-dimensional parameter spaces, we replace classical interpolation by extreme learning machine (ELM) surrogates and obtain error bounds under explicit approximation and stability assumptions. The proposed framework is applied to inverse problems in quantitative photoacoustic tomography, where we derive potential and parameter reconstruction error estimates and demonstrate substantial computational savings compared to standard approaches, without sacrificing accuracy.", "AI": {"tldr": "ROM framework for parameter-dependent PDEs using interpolation and ELM surrogates with rigorous error analysis, applied to photoacoustic tomography inverse problems.", "motivation": "Need efficient reduced-order modeling for parameter-dependent PDEs in control, inverse problems, and uncertainty quantification where computational costs are high.", "method": "Finite element discretization in physical domain + separate parameter approximation. Classical interpolation for low-dimensional parameters, extreme learning machine (ELM) surrogates for high-dimensional parameters.", "result": "Established existence, uniqueness, regularity of parametric solutions. Derived rigorous error estimates quantifying spatial vs parameter approximation trade-offs. Applied to photoacoustic tomography with computational savings and maintained accuracy.", "conclusion": "Framework provides efficient ROM for parameter-dependent PDEs with theoretical guarantees, enabling substantial computational savings in inverse problems without sacrificing accuracy."}}
{"id": "2602.13893", "pdf": "https://arxiv.org/pdf/2602.13893", "abs": "https://arxiv.org/abs/2602.13893", "authors": ["Roy Maman", "David Ohana", "Jacob Engelberg", "Uriel Levy"], "title": "Prompt-to-prescription: towards generative design of diffraction-limited refractive optics", "categories": ["physics.optics", "physics.app-ph", "physics.comp-ph"], "comment": "17 pages, 5 figures", "summary": "The design of high-performance optical systems remains a specialized domain gated by the limited availability of expert engineers, creating a bottleneck that stalls innovation despite the growing demand for imaging hardware. While deep learning has improved parameter optimization, it has yet to address the fundamental challenge of conceptualizing valid optical architectures from functional requirements. Here, we present an end-to-end generative framework that couples the semantic reasoning of Large Language Models (LLMs) with a differentiable ray-tracing engine to democratize the synthesis of diffraction-limited optical prescriptions. By treating optical design as a semantic-to-physical translation task, the system autonomously interprets prompts ranging from high-level end-user requests to rigorous technical specifications. We demonstrate the framework's versatility across three distinct regimes: (1) finite-conjugate industrial metrology systems, where the model autonomously enforces application-specific constraints such as telecentricity to achieve diffraction-limited performance; (2) a suite of infrared objectives (NIR, SWIR, and LWIR), demonstrating the framework's ability to synthesize valid topologies and optical prescriptions for non-visible spectral bands, and (3) complex aspheric mobile lenses, where the system successfully navigates the high-dimensional optimization landscape to produce high-resolution designs suitable for modern sensors. Validated against industry-standard simulation tools, these results establish a new paradigm for automated optical engineering, bridging the gap between semantic intent and physical realization.", "AI": {"tldr": "An end-to-end generative framework that uses LLMs and differentiable ray-tracing to automatically design diffraction-limited optical systems from semantic prompts, democratizing optical engineering.", "motivation": "Optical system design is bottlenecked by limited expert availability, stalling innovation despite growing demand for imaging hardware. Current deep learning approaches only optimize parameters but don't conceptualize valid architectures from requirements.", "method": "Couples semantic reasoning of Large Language Models with differentiable ray-tracing engine to treat optical design as semantic-to-physical translation. System autonomously interprets prompts ranging from high-level user requests to technical specifications.", "result": "Demonstrated across three regimes: 1) finite-conjugate industrial metrology systems with application-specific constraints like telecentricity, 2) infrared objectives (NIR, SWIR, LWIR) for non-visible spectral bands, 3) complex aspheric mobile lenses for modern sensors. Validated against industry-standard simulation tools.", "conclusion": "Establishes a new paradigm for automated optical engineering that bridges semantic intent with physical realization, democratizing optical design and overcoming the expert bottleneck."}}
{"id": "2602.13589", "pdf": "https://arxiv.org/pdf/2602.13589", "abs": "https://arxiv.org/abs/2602.13589", "authors": ["Engui Fan", "Gaozhan Li", "Yiling Yang", "Lun Zhang"], "title": "Painlev\u00e9 XXXIV asymptotics for the defocusing nonlinear Schr\u00f6dinger equation with a finite-genus algebro-geometric background", "categories": ["math.AP", "math-ph", "nlin.SI"], "comment": null, "summary": "In this paper, we consider the Cauchy problem for the defocusing nonlinear Schr$\\ddot{\\text{o}}$dinger equation with a finite genus algebro-geometric background. Long-time asymptotics of the solution are derived in four space-time regions. It comes out that the leading-order term in the expansion is, up to a constant, given by the background solution with a shift of the parameter. The subleading term, however, decays at different rates for different regions. We particularly highlight that in the two transition regions, they are of order $\\mathcal{O}(t^{-1/3})$ and the coefficients involve an integral of the Painlev\u00e9 XXXIV transcendent. We establish our results by applying a nonlinear steepest descent analysis to the associated Riemann-Hilbert problems.", "AI": {"tldr": "Long-time asymptotics for defocusing nonlinear Schr\u00f6dinger equation with finite genus algebro-geometric background in four space-time regions, showing different decay rates in transition regions.", "motivation": "To analyze the long-time behavior of solutions to the defocusing nonlinear Schr\u00f6dinger equation with finite genus algebro-geometric background, particularly understanding how solutions evolve asymptotically in different space-time regions.", "method": "Apply nonlinear steepest descent analysis to the associated Riemann-Hilbert problems to derive long-time asymptotics.", "result": "Leading-order term is the background solution with parameter shift; subleading terms decay at different rates: order O(t^{-1/3}) in two transition regions with coefficients involving Painlev\u00e9 XXXIV transcendent integrals.", "conclusion": "The paper successfully establishes detailed long-time asymptotics for the defocusing nonlinear Schr\u00f6dinger equation with algebro-geometric background, revealing different decay behaviors in various space-time regions and connections to Painlev\u00e9 transcendents."}}
{"id": "2602.14786", "pdf": "https://arxiv.org/pdf/2602.14786", "abs": "https://arxiv.org/abs/2602.14786", "authors": ["Achraf Badahmane", "Xian-Ming GU"], "title": "New Randomized Global Generalized Minimum Residual (RGl-GMRES) method", "categories": ["math.NA"], "comment": null, "summary": "In this paper, we develop a new Randomized Global Generalized Minimum Residual (RGlGMRES) algorithm for efficiently computing solutions to large scale linear systems with multiple right hand sides.The proposed method builds on a recently developed randomized global Gram Schmidt process, in which sketched Frobenius inner products are employed to approximate the exact Frobenius inner products of high-dimensional matrices. We give some new convergence results of the randomized global GMRES method for multiple linear systems. In the case where the coefficient matrix A is diagonalizable, we derive new upper bounds for the randomized Frobenius norm of the residual. In this paper, we study how to introduce matrix sketching in this algorithm. It allows us to reduce the dimension of the problem in one of the main steps of the algorithm. To validate the effectiveness and practicality of this approach, we conduct several numerical experiments, which demonstrate that our RGl-GMRES method is competitive with the GlGMRES method for solving large scale problems with multiple right-hand sides.", "AI": {"tldr": "RGlGMRES algorithm uses randomized sketching to efficiently solve large-scale linear systems with multiple right-hand sides, reducing computational costs while maintaining competitive performance with traditional methods.", "motivation": "Need efficient methods for solving large-scale linear systems with multiple right-hand sides, as traditional approaches become computationally expensive for high-dimensional problems.", "method": "Develops Randomized Global GMRES (RGlGMRES) using randomized global Gram-Schmidt process with sketched Frobenius inner products to approximate exact inner products, reducing problem dimension through matrix sketching.", "result": "Provides new convergence results and upper bounds for residual norms when coefficient matrix is diagonalizable; numerical experiments show RGlGMRES is competitive with traditional GlGMRES for large-scale problems.", "conclusion": "RGlGMRES is an effective and practical randomized approach that reduces computational costs while maintaining solution quality for large-scale linear systems with multiple right-hand sides."}}
{"id": "2602.13969", "pdf": "https://arxiv.org/pdf/2602.13969", "abs": "https://arxiv.org/abs/2602.13969", "authors": ["Gang Cui", "Lei Zhang", "Pingwen Zhang", "An-Chang Shi", "Kai Jiang"], "title": "Phason-Driven Diversity of Nucleation Pathways in Icosahedral Quasicrystals", "categories": ["cond-mat.soft", "physics.comp-ph"], "comment": null, "summary": "The nucleation of quasicrystals remains a fundamental puzzle, primarily due to the absence of a periodic translational template. Here, we demonstrate that phasons - hidden degrees of freedom unique to quasiperiodic order - drive diverse nucleation pathways in icosahedral quasicrystals (IQCs). Combining a Landau free-energy model with the spring pair method, we compute distinct critical nuclei and their corresponding minimum energy paths. At low temperatures, a direct, symmetry-preserving pathway dominates. In contrast, higher temperatures promote a \"symmetry detour\" that reduces the nucleation barrier via a lower-symmetry critical nucleus. Remarkably, while the resulting bulk IQCs exhibit distinct real-space symmetries, they remain thermodynamically degenerate with identical diffraction patterns. We resolve this paradox within the high-dimensional projection framework, showing that phason shifts modulate real-space symmetry without altering bulk thermodynamics. Our findings establish phasons as the structural origin of pathway diversity, offering a new physical picture for the emergence of quasiperiodic order.", "AI": {"tldr": "Phasons drive diverse nucleation pathways in icosahedral quasicrystals, with temperature-dependent symmetry changes that don't affect bulk thermodynamics.", "motivation": "To understand the fundamental puzzle of quasicrystal nucleation, which lacks periodic translational templates, by investigating the role of phasons - unique degrees of freedom in quasiperiodic systems.", "method": "Combined Landau free-energy model with spring pair method to compute distinct critical nuclei and their minimum energy paths for icosahedral quasicrystals.", "result": "Low temperatures favor direct symmetry-preserving nucleation, while higher temperatures promote \"symmetry detour\" pathways with lower-symmetry critical nuclei that reduce nucleation barriers. Resulting bulk quasicrystals show distinct real-space symmetries but remain thermodynamically degenerate with identical diffraction patterns.", "conclusion": "Phasons are the structural origin of pathway diversity in quasicrystal nucleation, modulating real-space symmetry without altering bulk thermodynamics, providing a new physical picture for emergence of quasiperiodic order."}}
{"id": "2602.13612", "pdf": "https://arxiv.org/pdf/2602.13612", "abs": "https://arxiv.org/abs/2602.13612", "authors": ["Yang Yang"], "title": "A Formula for Time-to-Frequency Wave Boundary Data Conversion by the Boundary Control Method", "categories": ["math.AP"], "comment": "23 pages, 5 figures/tables", "summary": "Given the wave equation on a compact Riemannian manifold with boundary, we derive an explicit reconstruction procedure to represent the frequency-domain Neumann-to-Dirichlet map in terms of the time-domain Neumann-to-Dirichlet map at any non-eigenfrequency. If the wave equation is exactly controllable, we derive an explicit formula to compute the former from the latter. The derivation is based on the boundary control method and requires only knowledge on the boundary of the manifold. The formula is stable when the level of regularization is fixed. The numerical feasibility is validated using one-dimensional examples in both Euclidean and non-Euclidean geometries.", "AI": {"tldr": "Explicit formula to compute frequency-domain Neumann-to-Dirichlet map from time-domain data using boundary control method, validated with 1D examples.", "motivation": "To develop a stable reconstruction procedure for frequency-domain boundary data from time-domain measurements in wave propagation problems on manifolds with boundaries.", "method": "Based on boundary control method, deriving explicit formulas connecting time-domain and frequency-domain Neumann-to-Dirichlet maps, requiring only boundary knowledge.", "result": "Successfully derived explicit reconstruction procedure, stable with fixed regularization, validated numerically in 1D Euclidean and non-Euclidean geometries.", "conclusion": "The method provides a practical, boundary-only approach for frequency-domain reconstruction from time-domain data with demonstrated numerical feasibility."}}
{"id": "2602.14854", "pdf": "https://arxiv.org/pdf/2602.14854", "abs": "https://arxiv.org/abs/2602.14854", "authors": ["Stefan Brunner", "Lukas Einkemmer", "Terry Haut"], "title": "Domain decomposition dynamical low-rank for multi-dimensional radiative transfer equations", "categories": ["math.NA", "physics.comp-ph"], "comment": null, "summary": "In this paper, we propose a domain decomposition dynamical low-rank method to solve high-dimensional radiative transfer problems and similar kinetic equations. The algorithm uses a separate low-rank approximation on each spatial subdomain, which means that, for a given accuracy, we can often use a smaller overall rank compared to classic dynamical low-rank methods. In particular, we can solve problems with point sources efficiently, that for classic algorithms require almost full rank. Our algorithm only transfers boundary data between subdomains and is thus very attractive for distributed memory parallelization, where classic dynamical low-rank algorithms suffer from global data dependency. We demonstrate the efficiency of our algorithm by a number of challenging test examples that have both very optical thin and thick regions.", "AI": {"tldr": "Domain decomposition dynamical low-rank method for high-dimensional radiative transfer problems that uses separate low-rank approximations on spatial subdomains, enabling smaller overall rank and efficient parallelization.", "motivation": "Classic dynamical low-rank methods for high-dimensional radiative transfer problems suffer from global data dependency (making parallelization difficult) and require high rank for problems with point sources, which is computationally expensive.", "method": "Proposes a domain decomposition approach where each spatial subdomain uses a separate low-rank approximation. The algorithm only transfers boundary data between subdomains, avoiding global data dependency and enabling distributed memory parallelization.", "result": "The method can solve problems with point sources efficiently (which require almost full rank for classic algorithms) and can handle challenging test cases with both very optical thin and thick regions. The domain decomposition allows using smaller overall rank for given accuracy.", "conclusion": "The proposed domain decomposition dynamical low-rank method is efficient for high-dimensional radiative transfer problems, offering better parallelization capabilities and reduced computational requirements compared to classic dynamical low-rank approaches."}}
{"id": "2602.14261", "pdf": "https://arxiv.org/pdf/2602.14261", "abs": "https://arxiv.org/abs/2602.14261", "authors": ["Yongbo Deng", "Jan G. Korvink"], "title": "Topology optimization of type-II superconductors with superconductor-dielectric/vacuum interfaces based on Ginzburg-Landau theory under Weyl gauge", "categories": ["cond-mat.supr-con", "math-ph", "math.OC", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "Geometry design is a crucial and challenging strategy for improving the performance of type-II superconductors. Topology optimization is one of the most powerful approaches used to determine structural geometries. Therefore, a topology optimization approach is presented to inversely design structural geometries of both low- and high-temperature type-II superconductors with superconductor-dielectric/vacuum interfaces. In the presented approach, the magnetic response of type-II superconductors is modeled using the Ginzburg-Landau theory, where the temporal evolution of the order parameter and vector potential is described by the time-dependent Ginzburg-Landau equations under the Weyl gauge.", "AI": {"tldr": "Topology optimization approach for designing structural geometries of type-II superconductors using Ginzburg-Landau theory to improve performance.", "motivation": "Geometry design is crucial for improving performance of type-II superconductors, but challenging. Topology optimization is a powerful approach for determining optimal structural geometries.", "method": "Presents a topology optimization approach using Ginzburg-Landau theory to model magnetic response. Uses time-dependent Ginzburg-Landau equations under Weyl gauge to describe temporal evolution of order parameter and vector potential.", "result": "The approach enables inverse design of structural geometries for both low- and high-temperature type-II superconductors with superconductor-dielectric/vacuum interfaces.", "conclusion": "Topology optimization combined with Ginzburg-Landau theory provides an effective framework for designing optimized geometries of type-II superconductors to enhance their performance."}}
{"id": "2602.13696", "pdf": "https://arxiv.org/pdf/2602.13696", "abs": "https://arxiv.org/abs/2602.13696", "authors": ["Ruxuan Chen", "Qi Zhang", "Zhikang Zhang", "Xiongbo Zheng"], "title": "Shinbrot Type Criteria for Energy Conservation of the Compressible Navier-Stokes Equations", "categories": ["math.AP"], "comment": null, "summary": "We prove that weak solutions to the compressible Navier-Stokes equations satisfy the energy equality under a Shinbrot-type regularity criterion. Our method applies to the fluids with both constant and degenerate viscosity and relies on a novel weak-type commutator estimate. These criterion are strictly weaker than those required in prior works [Arch. Ration. Mech. Anal., 225 (2017)] and [SIAM J. Math. Anal. 52 (2020)].", "AI": {"tldr": "Weak solutions to compressible Navier-Stokes equations satisfy energy equality under Shinbrot-type regularity criterion, using novel weak-type commutator estimate for fluids with constant/degenerate viscosity.", "motivation": "To establish conditions under which weak solutions to compressible Navier-Stokes equations satisfy the energy equality, improving upon previous regularity criteria from prior works.", "method": "Uses a novel weak-type commutator estimate to prove energy equality under Shinbrot-type regularity criterion, applicable to fluids with both constant and degenerate viscosity.", "result": "Proves that weak solutions satisfy energy equality under regularity criteria that are strictly weaker than those required in prior works from 2017 and 2020.", "conclusion": "The paper establishes improved regularity conditions for energy conservation in compressible Navier-Stokes equations through innovative commutator estimates, advancing beyond previous results."}}
{"id": "2602.14912", "pdf": "https://arxiv.org/pdf/2602.14912", "abs": "https://arxiv.org/abs/2602.14912", "authors": ["A. K. Dond", "D. Gallistl", "S. Nayak", "M. Schedensack"], "title": "A posteriori error estimates for a modified Morley FEM", "categories": ["math.NA"], "comment": null, "summary": "Residual-based a~posteriori error estimators are derived for the modified Morley FEM, proposed by Wang, Xu, Hu [J. Comput. Math, 24(2), 2006], for the singularly perturbed biharmonic equation and the nonlinear von K\u00e1rm\u00e1n equations. The error estimators are proven to be reliable and efficient. Moreover, an adaptive algorithm driven by these error estimators is investigated in numerical experiments.", "AI": {"tldr": "Residual-based a posteriori error estimators for modified Morley FEM on singularly perturbed biharmonic and nonlinear von K\u00e1rm\u00e1n equations, proven reliable/efficient, with adaptive algorithm tested numerically.", "motivation": "To develop reliable and efficient error estimators for the modified Morley finite element method when applied to challenging problems like singularly perturbed biharmonic equations and nonlinear von K\u00e1rm\u00e1n equations, enabling adaptive refinement strategies.", "method": "Derived residual-based a posteriori error estimators for the modified Morley FEM (proposed by Wang, Xu, Hu in 2006) applied to singularly perturbed biharmonic equations and nonlinear von K\u00e1rm\u00e1n equations.", "result": "The error estimators are mathematically proven to be both reliable (upper bound on error) and efficient (lower bound on error). An adaptive algorithm driven by these estimators was implemented and tested in numerical experiments.", "conclusion": "The paper successfully develops theoretically sound and practically effective error estimators for the modified Morley FEM on challenging PDE problems, enabling adaptive mesh refinement strategies with proven reliability and efficiency guarantees."}}
{"id": "2602.14384", "pdf": "https://arxiv.org/pdf/2602.14384", "abs": "https://arxiv.org/abs/2602.14384", "authors": ["Vsevolod Biryukov", "Kamal Choudhary", "Timur Bazhirov"], "title": "M-CODE: Materials Categorization via Ontology, Dimensionality and Evolution", "categories": ["cond-mat.mtrl-sci", "cs.DL", "physics.comp-ph"], "comment": "13 pages, 2 figures, 5 tables", "summary": "The rapid advancement of artificial intelligence in materials science requires data standards and data management practices that can capture the complexity of real-world structures, including surfaces, interfaces, defects, and dimensionality reduction. We present M-CODE - Materials Categorization via Ontology, Dimensionality and Evolution - a compact categorization system that links materials-science-specific terminology to a set of reusable concepts as building blocks and provenance-aware transformations. M-CODE classifies structures by dimensionality, structural complexity (from pristine to compound pristine, defective, and processed), and variants that capture common structure creation and evolution approaches. A practical implementation of the categorization is provided in an open-source codebase that includes JSON schemas, examples, and Python and TypeScript types/interfaces, designed to support reproducible dataset generation, validation, and community contributions.", "AI": {"tldr": "M-CODE is a categorization system for materials science data that standardizes terminology for complex structures (surfaces, interfaces, defects) using reusable concepts and provenance-aware transformations.", "motivation": "The rapid advancement of AI in materials science requires data standards and management practices that can capture the complexity of real-world structures including surfaces, interfaces, defects, and dimensionality reduction.", "method": "M-CODE uses a compact categorization system that links materials-science-specific terminology to reusable concepts as building blocks and provenance-aware transformations. It classifies structures by dimensionality, structural complexity (from pristine to compound pristine, defective, and processed), and variants capturing common structure creation and evolution approaches.", "result": "A practical implementation is provided in an open-source codebase including JSON schemas, examples, and Python/TypeScript types/interfaces, designed to support reproducible dataset generation, validation, and community contributions.", "conclusion": "M-CODE provides a standardized categorization framework for materials science data that addresses the complexity of real-world structures and supports AI applications through reproducible data management practices."}}
{"id": "2602.13703", "pdf": "https://arxiv.org/pdf/2602.13703", "abs": "https://arxiv.org/abs/2602.13703", "authors": ["Thierry Daud\u00e9", "Niky Kamran", "Fran\u00e7ois Nicoleau"], "title": "Stability in the anisotropic Calder\u00f3n problem for Painlev\u00e9-Liouville Riemannian manifolds", "categories": ["math.AP", "math-ph", "math.SP"], "comment": null, "summary": "We study the question of stability of the global and partial anisotropic Calder\u00f3n inverse problems for the class of Painlev\u00e9-Liouville Riemannian manifolds, that is compact $n$-dimensional manifolds with boundary $(M,g)$, where $M=[0,1]\\times K\\,$, $K$ is any smooth closed connected orientable manifold of dimension $n-1$ endowed with a Riemannian metric $g_K$, and $g=\u03b1^4 g_{0}$ is any conformal deformation of the product metric $g_{0}=dx^2+g_{K}$ on $M$ which is compatible with the Painlev\u00e9 block-separability of the Laplace-Beltrami operator $\u0394_{g_0}$. Given a pair of Painlev\u00e9-Liouville Riemannian manifolds $(M,g)$ and $(M,\\tilde{g})$ satisfying some technical hypothesis, denoting the corresponding Dirichlet-to-Neumann maps by $\u039b_{g}$ and $\u039b_{\\tilde{g}}$, and assuming that $\\lVert \u039b_{g}-\u039b_{\\tilde{g}}\\rVert_{\\mathcal{B}(H^{1/2}(\\partial M), H^{-1/2}(\\partial M))}\\ = \u03b5$, we show a logarithmic stability result for the global anisotropic Calder\u00f3n problem which says that there exists constants $C$ and $0<\u03b8<1$ such that $\\| \u03b1- \\tilde\u03b1 \\|_{C^{0,r}(M)} \\leq C \\left( \\ln \\frac{1}\u03b5 \\right)^{-\u03b8}$ for some $0<r<1$. Similar results are obtained for the partial anisotropic Calder\u00f3n problem, corresponding to the case where the data are measured on only one connected component of the boundary.", "AI": {"tldr": "The paper proves logarithmic stability for anisotropic Calder\u00f3n inverse problems on Painlev\u00e9-Liouville Riemannian manifolds, showing that small differences in Dirichlet-to-Neumann maps imply small differences in conformal factors with logarithmic rate.", "motivation": "The anisotropic Calder\u00f3n problem concerns determining the interior conductivity (or Riemannian metric) from boundary measurements. While uniqueness results exist, stability estimates are crucial for practical applications and numerical reconstruction. This paper addresses stability for a specific class of Riemannian manifolds where the geometry has product structure.", "method": "The authors study Painlev\u00e9-Liouville Riemannian manifolds - compact manifolds with boundary of the form M=[0,1]\u00d7K, where K is a closed manifold. They consider conformal deformations g=\u03b1\u2074g\u2080 of the product metric g\u2080=dx\u00b2+g_K that preserve Painlev\u00e9 block-separability of the Laplace-Beltrami operator. Using Dirichlet-to-Neumann maps as boundary measurements, they establish stability estimates through analytical techniques.", "result": "Main result: If two Painlev\u00e9-Liouville Riemannian manifolds satisfy technical hypotheses and their Dirichlet-to-Neumann maps differ by \u03b5 in operator norm, then the conformal factors satisfy \u2016\u03b1-\u03b1\u0303\u2016_{C\u2070\u02b3(M)} \u2264 C(ln(1/\u03b5))^{-\u03b8} for some 0<\u03b8<1 and 0<r<1. Similar logarithmic stability is shown for the partial data case where measurements are taken on only one boundary component.", "conclusion": "The paper establishes logarithmic stability for both global and partial anisotropic Calder\u00f3n inverse problems on Painlev\u00e9-Liouville Riemannian manifolds. This provides quantitative stability estimates for reconstructing conformal factors from boundary measurements, with the logarithmic rate being typical for such ill-posed inverse problems."}}
{"id": "2602.14921", "pdf": "https://arxiv.org/pdf/2602.14921", "abs": "https://arxiv.org/abs/2602.14921", "authors": ["Pedro Morin", "Cornelia Schneider", "Nick Schneider"], "title": "Approximation classes for the anisotropic space-time finite element method. An almost characterization", "categories": ["math.NA"], "comment": null, "summary": "We study the approximation of $L_p$-functions, $p\\in (0,\\infty]$, on cylindrical space-time domains $\u03a9_T:=[0,T]\\times \u03a9$, $0<T<\\infty$, $\u03a9\\subset \\R^d$ Lipschitz, $d\\in \\mathbb{N}$, with respect to continuous anisotropic space-time finite elements on prismatic meshes. In particular, we propose a suitable refinement technique which creates (locally refined) prismatic meshes with sufficient smoothness and the desired anisotropy, and prove complexity estimates. Furthermore, we define a (quasi-)interpolation operator on this type of meshes and use it to characterize the corresponding approximation classes by showing direct and inverse estimates in terms of anisotropic Besov norms.", "AI": {"tldr": "The paper develops anisotropic space-time finite element approximation theory for L_p functions on cylindrical domains using prismatic meshes, including mesh refinement techniques and characterization of approximation classes via anisotropic Besov norms.", "motivation": "To develop efficient numerical methods for time-dependent PDEs on cylindrical space-time domains by creating appropriate anisotropic finite element approximations that can handle different scales in space and time directions.", "method": "Proposes a refinement technique for creating locally refined prismatic meshes with sufficient smoothness and desired anisotropy. Defines a (quasi-)interpolation operator on these meshes and uses it to characterize approximation classes through direct and inverse estimates in anisotropic Besov norms.", "result": "Develops a complete approximation theory including complexity estimates for the mesh refinement technique and establishes characterization of approximation classes via anisotropic Besov norms through direct and inverse estimates.", "conclusion": "The paper provides a comprehensive framework for anisotropic space-time finite element approximation on cylindrical domains with prismatic meshes, including practical mesh generation techniques and theoretical characterization of approximation properties."}}
{"id": "2602.14650", "pdf": "https://arxiv.org/pdf/2602.14650", "abs": "https://arxiv.org/abs/2602.14650", "authors": ["Kati Asikainen", "Matti Alatalo", "Marko Huttula", "Assa Aravindh Sasikala Devi"], "title": "Data-Efficient Machine learning for Predicting Dopant Formation Energies in TiO$_2$ Monolayer", "categories": ["cond-mat.mtrl-sci", "physics.comp-ph"], "comment": null, "summary": "Machine learning models are increasingly applied in materials science, yet their predictive power is often constrained by data scarcity. Here, we show that accurate predictions can be achieved, even with a limited number of training examples, provided the dataset is compact and and grounded in physically relevant quantities. By combining density functional theory calculations with a machine-learning framework, we construct accurate descriptor-based models to predict the formation energies of doped lepidocrocite TiO$_2$ monolayers. The predictive accuracy of machine-learning models was first evaluated for single-dopant Pt configurations, demonstrating that the selected structural and chemical descriptors reliably capture the key factors governing dopant stability. Chemical transferability is then examined by extending the dataset to include Ag-doped configurations. Predictive accuracy improved systematically as additional Ag-doped data points were included in the training, while the performance of Pt remains robust. These results highlight the potential of small and well-curated datasets combined with physically informed descriptors to enable not only accurate but also chemically transferable machine-learning-driven screening in doped TiO$_2$ monolayer.", "AI": {"tldr": "Machine learning models can accurately predict formation energies of doped TiO2 monolayers using small, well-curated datasets with physically relevant descriptors, showing chemical transferability between Pt and Ag dopants.", "motivation": "Machine learning models in materials science face data scarcity limitations, but accurate predictions may be possible with compact, physically-grounded datasets.", "method": "Combined density functional theory calculations with machine learning framework to construct descriptor-based models for predicting formation energies of doped lepidocrocite TiO2 monolayers, using structural and chemical descriptors.", "result": "Models achieved accurate predictions for single-dopant Pt configurations, and showed systematic improvement in predictive accuracy for Ag-doped configurations as more data was added, while maintaining robust performance for Pt.", "conclusion": "Small, well-curated datasets combined with physically informed descriptors enable accurate and chemically transferable machine-learning-driven screening in doped TiO2 monolayers."}}
{"id": "2602.13727", "pdf": "https://arxiv.org/pdf/2602.13727", "abs": "https://arxiv.org/abs/2602.13727", "authors": ["Haesung Lee"], "title": "Resolvent approaches to elliptic regularity in stationary Fokker-Planck equations", "categories": ["math.AP"], "comment": "19 pages", "summary": "This paper investigates the local regularity of solutions to stationary Fokker-Planck equations on an open set $U \\subset \\mathbb{R}^d$ with $d \\geq 2$. A central objective is to relax the classical assumptions on the coefficients by focusing on the case where the drift vector field $\\mathbf{G}$ is only assumed to be locally square-integrable, i.e. $\\mathbf{G} \\in L^2_{loc}(U, \\mathbb{R}^d)$, the diffusion matrix $A = (a_{ij})_{1 \\leq i,j \\leq d}$ is assumed to be locally uniformly strictly elliptic and bounded, with coefficients satisfying $\\frac{a_{ij}+a_{ji}}{2} \\in VMO_{loc}(U)$ for all $1 \\leq i,j \\leq d$ and ${\\rm div}A \\in L^2_{loc}(U, \\mathbb{R}^d)$. Our main result shows that any locally bounded function $h \\in L^\\infty_{loc}(U)$ satisfying the stationary Fokker-Planck equation $L^*(h\\, dx) = 0$ must in fact belong to the local Sobolev space $H^{1,2}_{loc}(U)$. The proof is based on the construction of a sub-Markovian resolvent associated with the principal elliptic operator $L^A := \\operatorname{trace}(A \\nabla^2)$, combined with delicate energy-type inequalities. In particular, we show that the density $h$ can be realized as the weak $H^{1,2}$-limit of images of resolvent operators.", "AI": {"tldr": "The paper proves that solutions to stationary Fokker-Planck equations with minimal regularity assumptions on coefficients have local Sobolev regularity (H^{1,2}_{loc}).", "motivation": "To relax classical assumptions on coefficients for stationary Fokker-Planck equations, allowing drift to be only locally square-integrable and diffusion matrix with VMO coefficients, while still establishing regularity properties.", "method": "Constructs a sub-Markovian resolvent associated with the principal elliptic operator L^A, combined with delicate energy-type inequalities. Shows density h can be realized as weak H^{1,2}-limit of images of resolvent operators.", "result": "Any locally bounded function satisfying the stationary Fokker-Planck equation with the given coefficient assumptions must belong to the local Sobolev space H^{1,2}_{loc}(U).", "conclusion": "The paper establishes Sobolev regularity for solutions under significantly relaxed coefficient conditions, providing a robust regularity theory for stationary Fokker-Planck equations with minimal assumptions."}}
{"id": "2602.14967", "pdf": "https://arxiv.org/pdf/2602.14967", "abs": "https://arxiv.org/abs/2602.14967", "authors": ["Guosheng Fu", "Brendan Keith", "Dohyun Kim", "Rami Masri", "Will Pazner"], "title": "The proximal Galerkin method for non-symmetric variational inequalities", "categories": ["math.NA"], "comment": null, "summary": "We introduce the proximal Galerkin (PG) method for non-symmetric variational inequalities. The proposed approach is asymptotically mesh-independent and yields constraint-preserving approximations. We present both a conforming PG formulation and a hybrid mixed first-order system variant (FOSPG). We establish optimal a priori error estimates for each variant, which are verified numerically. We conclude by applying the method to American option pricing, free boundary problems in porous media, advection-diffusion with a semipermeable boundary, and the enforcement of discrete maximum principles.", "AI": {"tldr": "Proximal Galerkin method for non-symmetric variational inequalities with mesh-independent, constraint-preserving approximations, applied to American options, porous media, advection-diffusion, and maximum principles.", "motivation": "To develop a robust numerical method for non-symmetric variational inequalities that maintains mesh independence and preserves constraints across various applications.", "method": "Proximal Galerkin method with two variants: conforming PG formulation and hybrid mixed first-order system variant (FOSPG). The method is asymptotically mesh-independent and yields constraint-preserving approximations.", "result": "Established optimal a priori error estimates for both variants, verified numerically. Successfully applied to American option pricing, free boundary problems in porous media, advection-diffusion with semipermeable boundary, and enforcement of discrete maximum principles.", "conclusion": "The Proximal Galerkin method provides an effective, mesh-independent approach for solving non-symmetric variational inequalities with constraint preservation, demonstrating broad applicability across multiple domains."}}
{"id": "2602.14654", "pdf": "https://arxiv.org/pdf/2602.14654", "abs": "https://arxiv.org/abs/2602.14654", "authors": ["Marco Patriarca"], "title": "Boundary conditions for the Schr\u00f6dinger equation in the numerical simulation of quantum systems", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.comp-ph"], "comment": "7 pages, 4 figures", "summary": "We study the problem of the boundary conditions in the numerical simulation of closed and open quantum systems, described by a Schr\u00f6dinger equation. On one hand, we show that a closed quantum system is defined by local boundary conditions. On the other hand, we argue that, because of the uncertainty principle, no local boundary condition can be defined for open quantum systems. For this reason plane waves or wave packet trains cannot be simulated on a finite numerical lattice with the usual procedures. We suggest a method that avoids these difficulties by using only a small numerical lattice and maintains the correspondence with the physical picture, in which the incident and scattered waves may be infinitely extended.", "AI": {"tldr": "The paper addresses boundary condition problems in quantum system simulations, showing closed systems need local boundary conditions while open systems cannot have them due to uncertainty principle, and proposes a method using small lattices to handle extended waves.", "motivation": "To solve the fundamental problem of boundary conditions in numerical simulations of quantum systems, particularly the inability to simulate plane waves or wave packet trains on finite lattices with standard methods due to the uncertainty principle constraints in open systems.", "method": "Proposes a novel simulation method that uses only a small numerical lattice while maintaining correspondence with physical reality where incident and scattered waves can be infinitely extended, avoiding the limitations of local boundary conditions for open systems.", "result": "Establishes that closed quantum systems require local boundary conditions, but open quantum systems cannot have local boundary conditions due to the uncertainty principle, making conventional simulation approaches inadequate for extended wave phenomena.", "conclusion": "A new simulation approach is needed for open quantum systems that circumvents the impossibility of local boundary conditions, enabling accurate simulation of extended wave phenomena on finite computational domains."}}
{"id": "2602.13753", "pdf": "https://arxiv.org/pdf/2602.13753", "abs": "https://arxiv.org/abs/2602.13753", "authors": ["Pierpaolo Esposito", "Pablo Salgado", "Angela Pistoia", "Giusi Vaira"], "title": "Entire solutions to a strongly competitive nonlinear Schr\u00f6dinger system", "categories": ["math.AP"], "comment": null, "summary": "We build infinitely-many non-radial positive solutions to the Schr\u00f6dinger system \\begin{equation*} \\left\\{\\begin{aligned} &-\u0394u_1+u_1=u_1^{{\\mathfrak p} }-\u039bu_1^{a_1} u_2^{a_2}\\ \\hbox{in}\\ \\mathbb R^N\\\\ &-\u0394u_2+u_2=u_2^{{\\mathfrak p} }-\u039bu_1^{b_1}u_2^{b_2} \\ \\hbox{in}\\ \\mathbb R^N\\\\ \\end{aligned}\\right. \\end{equation*} with sub-critical $\\mathfrak p$-growth as $\u039b\\to +\\infty$. The profile of each component is the sum of several copies of the positive solution to $-\u0394U+U=U^{{\\mathfrak p} }$ in $\\mathbb R^N$, centered at suitable {\\em peaks} whose mutual distances diverge as $\u039b$ increases. More precisely, given two concentric regular polygons with $k$ sides and very large radii, the peaks of the first component are arranged along the edges of the {\\em outer} polygon, alternated with those of the second component, and along the $k$ rays joining the vertices of the two polygons. To the best of our knowledge, this provides the first example of non-radial positive solutions for strongly competitive Schr\u00f6dinger systems in the whole space.", "AI": {"tldr": "The paper constructs infinitely many non-radial positive solutions for a strongly competitive Schr\u00f6dinger system with sub-critical growth as \u039b\u2192\u221e, using multi-peak configurations arranged on concentric polygons.", "motivation": "To provide the first example of non-radial positive solutions for strongly competitive Schr\u00f6dinger systems in the whole space \u211d^N, addressing a gap in existing literature where such solutions were not known.", "method": "Construct solutions by arranging peaks of each component on concentric regular polygons: peaks of the first component on the outer polygon edges, alternated with second component peaks, and additional peaks along rays joining vertices of both polygons. The profile uses multiple copies of the positive solution to the single equation -\u0394U+U=U^\ud835\udd2d.", "result": "Successfully builds infinitely many non-radial positive solutions as \u039b\u2192\u221e, with peak distances diverging as \u039b increases. The solutions have sub-critical \ud835\udd2d-growth and exhibit strongly competitive behavior.", "conclusion": "This work provides the first construction of non-radial positive solutions for strongly competitive Schr\u00f6dinger systems in \u211d^N, demonstrating that such systems admit rich geometric configurations beyond radial solutions."}}
{"id": "2602.14667", "pdf": "https://arxiv.org/pdf/2602.14667", "abs": "https://arxiv.org/abs/2602.14667", "authors": ["Alessandro De Rosis"], "title": "Recursive regularised lattice Boltzmann method for magnetohydrodynamics", "categories": ["physics.flu-dyn", "physics.comp-ph"], "comment": null, "summary": "We present and test a recursive regularised lattice Boltzmann method for incompressible magnetohydrodynamic (MHD) flows. The approach is based on a double-distribution formulation, in which the magnetic field is evolved using a standard BGK lattice Boltzmann scheme, while the fluid solver is enhanced through a Hermite-based recursive regularisation of the non-equilibrium moments. The method exploits a fourth-order Hermite expansion of the equilibrium distribution on the D2Q9 lattice, allowing higher-order isotropy to be retained while selectively filtering spurious non-hydrodynamic contributions. The regularisation procedure reconstructs the non-equilibrium distribution from physically consistent Hermite coefficients, avoiding explicit evaluation of velocity gradients. The resulting scheme preserves the correct incompressible MHD limit, improves numerical stability at low viscosities, and reduces lattice-dependent artefacts. The proposed formulation provides a robust and versatile framework for MHD simulations and offers a systematic route for extending regularised lattice Boltzmann methods to coupled multiphysics systems.", "AI": {"tldr": "A recursive regularised lattice Boltzmann method for incompressible MHD flows using double-distribution formulation with Hermite-based regularisation for improved stability and accuracy.", "motivation": "To develop a more robust and stable lattice Boltzmann method for incompressible magnetohydrodynamic flows that can handle low viscosities while reducing numerical artefacts.", "method": "Double-distribution formulation: magnetic field evolved via standard BGK lattice Boltzmann, fluid solver enhanced through Hermite-based recursive regularisation of non-equilibrium moments using fourth-order Hermite expansion on D2Q9 lattice.", "result": "The method preserves correct incompressible MHD limit, improves numerical stability at low viscosities, reduces lattice-dependent artefacts, and provides a robust framework for MHD simulations.", "conclusion": "The recursive regularised lattice Boltzmann method offers a versatile framework for MHD simulations and provides a systematic approach for extending regularised methods to coupled multiphysics systems."}}
{"id": "2602.13788", "pdf": "https://arxiv.org/pdf/2602.13788", "abs": "https://arxiv.org/abs/2602.13788", "authors": ["Namhyun Eun", "Moon-Jin Kang", "Jeongho Kim"], "title": "Contraction of viscous-dispersive shocks: Zero viscosity-capillarity limits", "categories": ["math.AP"], "comment": null, "summary": "We prove the contraction property of any large solution perturbed from a viscous-dispersive shock wave of the Navier--Stokes--Korteweg (NSK) system. The contraction holds up to a dynamical shift, since the contraction is measured by the relative entropy that is locally $L^2$. We use the contraction property to show the global existence of large solution perturbed from a viscous-dispersive shock wave. To prove the contraction property, we first employ the effective velocity to transform the NSK system into the system of two degenerate parabolic equations, then apply the method of $a$-contraction with shifts. The contraction property does not depend on the strengths of viscosity and capillarity. Based on this uniformity, we show the existence of zero viscosity-capillarity limits of solutions to the NSK system, on which Riemann shocks are unique and stable up to shifts.", "AI": {"tldr": "The paper proves contraction properties for large perturbations of viscous-dispersive shock waves in the Navier-Stokes-Korteweg system, leading to global existence and zero viscosity-capillarity limits.", "motivation": "To establish contraction properties for large solutions perturbed from viscous-dispersive shock waves in the NSK system, which enables proving global existence and studying zero viscosity-capillarity limits.", "method": "1. Use effective velocity to transform NSK system into two degenerate parabolic equations. 2. Apply the method of $a$-contraction with shifts to prove contraction property measured by relative entropy. 3. The contraction holds up to a dynamical shift and is locally $L^2$.", "result": "1. Contraction property holds for large perturbations of viscous-dispersive shock waves. 2. Global existence of large solutions perturbed from viscous-dispersive shock waves. 3. Zero viscosity-capillarity limits exist, showing Riemann shocks are unique and stable up to shifts. 4. Results are independent of viscosity and capillarity strengths.", "conclusion": "The paper successfully establishes contraction properties for the NSK system, leading to global existence results and demonstrating the existence of zero viscosity-capillarity limits where Riemann shocks remain unique and stable."}}
{"id": "2602.13413", "pdf": "https://arxiv.org/pdf/2602.13413", "abs": "https://arxiv.org/abs/2602.13413", "authors": ["Yuchen Fang", "James Demmel", "Javad Lavaei"], "title": "Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise", "categories": ["cs.LG", "math.NA", "math.OC", "stat.ML"], "comment": null, "summary": "We develop a worst-case complexity theory for stochastically preconditioned stochastic gradient descent (SPSGD) and its accelerated variants under heavy-tailed noise, a setting that encompasses widely used adaptive methods such as Adam, RMSProp, and Shampoo. We assume the stochastic gradient noise has a finite $p$-th moment for some $p \\in (1,2]$, and measure convergence after $T$ iterations. While clipping and normalization are parallel tools for stabilizing training of SGD under heavy-tailed noise, there is a fundamental separation in their worst-case properties in stochastically preconditioned settings. We demonstrate that normalization guarantees convergence to a first-order stationary point at rate $\\mathcal{O}(T^{-\\frac{p-1}{3p-2}})$ when problem parameters are known, and $\\mathcal{O}(T^{-\\frac{p-1}{2p}})$ when problem parameters are unknown, matching the optimal rates for normalized SGD, respectively. In contrast, we prove that clipping may fail to converge in the worst case due to the statistical dependence between the stochastic preconditioner and the gradient estimates. To enable the analysis, we develop a novel vector-valued Burkholder-type inequality that may be of independent interest. These results provide a theoretical explanation for the empirical preference for normalization over clipping in large-scale model training.", "AI": {"tldr": "The paper analyzes worst-case complexity of stochastically preconditioned SGD (SPSGD) under heavy-tailed noise, showing normalization guarantees convergence while clipping may fail due to statistical dependence between preconditioner and gradients.", "motivation": "To develop a theoretical understanding of why normalization outperforms clipping in large-scale model training with adaptive methods (Adam, RMSProp, Shampoo) under heavy-tailed noise conditions.", "method": "Develops worst-case complexity theory for stochastically preconditioned SGD and its accelerated variants. Assumes stochastic gradient noise has finite p-th moment (p\u2208(1,2]). Uses novel vector-valued Burkholder-type inequality for analysis. Compares normalization vs clipping approaches.", "result": "Normalization guarantees convergence to first-order stationary point at rate O(T^{-(p-1)/(3p-2)}) with known parameters and O(T^{-(p-1)/(2p)}) with unknown parameters (matching optimal rates for normalized SGD). Clipping may fail to converge in worst case due to statistical dependence between stochastic preconditioner and gradient estimates.", "conclusion": "Provides theoretical explanation for empirical preference of normalization over clipping in large-scale training. Shows fundamental separation between normalization and clipping in stochastically preconditioned settings under heavy-tailed noise."}}
{"id": "2602.14787", "pdf": "https://arxiv.org/pdf/2602.14787", "abs": "https://arxiv.org/abs/2602.14787", "authors": ["Lasse Ermoneit", "Abel Thayil", "Thomas Koprucki", "Markus Kantner"], "title": "Exact Multi-Valley Envelope Function Theory of Valley Splitting in Si/SiGe Nanostructures", "categories": ["cond-mat.mes-hall", "math-ph", "physics.app-ph", "physics.comp-ph", "quant-ph"], "comment": null, "summary": "Valley splitting in strained Si/SiGe quantum wells is a central parameter for silicon spin qubits and is commonly described with envelope-function and effective-mass theories. These models provide a computationally efficient continuum description and have been shown to agree well with atomistic approaches when the confinement potential is slowly varying on the lattice scale. In modern Si/SiGe heterostructures with atomically sharp interfaces and engineered Ge concentration profiles, however, the slowly varying potential approximation underlying conventional (local) envelope-function theory is challenged. We formulate an exact multi-valley envelope-function model by combining Burt-Foreman-type envelope-function theory, which does not rely on the assumption of a slowly varying potential, with a valley-sector decomposition of the Brillouin zone. This construction enforces band-limited envelopes, which satisfy a set of coupled integro-differential equations with a non-local potential energy operator. Using degenerate perturbation theory, we derive the intervalley coupling matrix element within this non-local model and prove that it is strictly invariant under global shifts of the confinement potential (choice of reference energy). We then show that the conventional local envelope model generically violates this invariance due to spectral leakage between valley sectors, leading to an unphysical energy-reference dependence of the intervalley coupling. The resulting ambiguity is quantified by numerical simulations of various engineered Si/SiGe heterostructures. Finally, we propose a simple spectrally filtered local approximation that restores the energy-reference invariance exactly and provides a good approximation to the exact non-local theory.", "AI": {"tldr": "The paper develops an exact multi-valley envelope-function model for valley splitting in Si/SiGe quantum wells that addresses limitations of conventional local models, particularly for modern heterostructures with sharp interfaces.", "motivation": "Conventional envelope-function models assume slowly varying potentials, which is challenged by modern Si/SiGe heterostructures with atomically sharp interfaces and engineered Ge concentration profiles. These local models violate physical invariance principles.", "method": "Combines Burt-Foreman-type envelope-function theory (which doesn't require slowly varying potentials) with valley-sector decomposition of the Brillouin zone. This creates a non-local model with band-limited envelopes satisfying coupled integro-differential equations. Uses degenerate perturbation theory to derive intervalley coupling matrix elements.", "result": "The exact non-local model maintains strict invariance under global energy shifts, while conventional local models violate this invariance due to spectral leakage between valley sectors. Numerical simulations quantify this ambiguity in engineered heterostructures. A spectrally filtered local approximation is proposed that restores invariance and approximates the exact theory.", "conclusion": "The work provides a rigorous envelope-function framework for valley splitting in modern Si/SiGe quantum wells that respects fundamental physical invariance principles, addressing limitations of conventional local models for heterostructures with sharp interfaces."}}
{"id": "2602.13822", "pdf": "https://arxiv.org/pdf/2602.13822", "abs": "https://arxiv.org/abs/2602.13822", "authors": ["T. Kim", "T. Lee"], "title": "Liouville-type theorems for Lane--Emden inequalities involving nonlocal operators", "categories": ["math.AP"], "comment": "10 pages", "summary": "We establish a Liouville-type theorem for nonnegative weak supersolutions to $\\mathcal{L}_K u = u^q$ in $\\mathbb{R}^n$, where $\\mathcal{L}_K$ is a translation-invariant integro-differential operator of order $2s$ with $s \\in (0,1)$. The kernel $K$ is assumed to be even and satisfy uniform ellipticity bounds. We prove that the only nonnegative supersolution is the trivial one $u \\equiv 0$ in the range $1 < q \\le \\frac{n}{n-2s}$ for $n > 2s$ (and for all $q > 1$ when $n \\le 2s$). Our proof is elementary and relies on a test function method combined with a dyadic decomposition of the nonlocal tail. Notably, our argument does not rely on the maximum principle or the fundamental solution.", "AI": {"tldr": "Liouville-type theorem for nonnegative supersolutions to integro-differential equations: only trivial solution u\u22610 exists for certain exponent ranges.", "motivation": "To establish nonexistence results (Liouville-type theorems) for nonnegative weak supersolutions of integro-differential equations with fractional Laplacian-type operators, extending classical results for local elliptic equations to the nonlocal setting.", "method": "Elementary proof using test function method combined with dyadic decomposition of the nonlocal tail. Notably avoids reliance on maximum principle or fundamental solution.", "result": "Proves that the only nonnegative supersolution is u\u22610 for 1<q\u2264n/(n-2s) when n>2s, and for all q>1 when n\u22642s.", "conclusion": "Establishes sharp Liouville-type theorem for nonlocal integro-differential operators, providing complete classification of nonexistence ranges for supersolutions."}}
{"id": "2602.13472", "pdf": "https://arxiv.org/pdf/2602.13472", "abs": "https://arxiv.org/abs/2602.13472", "authors": ["Junaid Aftab", "Yuehaw Khoo", "Haizhao Yang"], "title": "Non-Uniform Quantum Fourier Transform", "categories": ["quant-ph", "math.NA"], "comment": "32 pages, 5 figures, comments are most welcome", "summary": "The Discrete Fourier Transform (DFT) is central to the analysis of uniformly sampled signals, yet many practical applications involve non-uniform sampling, requiring the Non-Uniform Discrete Fourier Transform (NUDFT). While quantum algorithms for the standard DFT are well established, a corresponding framework for the non-uniform case remains underdeveloped. This work introduces a quantum algorithm for the Non-Uniform Quantum Fourier Transform (NUQFT) based on a low-rank factorization of the NUDFT matrix. The factorization is translated into an explicit quantum construction using block encodings, Quantum Signal Processing, and the Linear Combination of Unitaries framework, yielding an $\u03b5$-accurate block encoding of the NUDFT matrix with controlled approximation error from both classical truncation and quantum implementation. Under standard oracle access assumptions for non-uniform sampling points, we derive explicit, non-asymptotic gate-level resource estimates. The resulting complexity scales polylogarithmically with target precision, quadratically with the number of qubits through the quantum Fourier transform, and logarithmically with a geometry-dependent conditioning parameter induced by the non-uniform grid. This establishes a concrete and resource-efficient quantum analogue of the NUDFT and provides a foundation for quantum algorithms on irregularly sampled data.", "AI": {"tldr": "Quantum algorithm for Non-Uniform Quantum Fourier Transform (NUQFT) using low-rank factorization, block encodings, and quantum signal processing with polylogarithmic precision scaling.", "motivation": "Many practical applications involve non-uniform sampling, but while quantum algorithms for standard DFT exist, a framework for non-uniform case remains underdeveloped.", "method": "Low-rank factorization of NUDFT matrix translated into quantum construction using block encodings, Quantum Signal Processing, and Linear Combination of Unitaries framework.", "result": "\u03b5-accurate block encoding of NUDFT matrix with controlled approximation error, explicit gate-level resource estimates with polylogarithmic precision scaling, quadratic qubit dependence, and logarithmic geometry-dependent conditioning.", "conclusion": "Establishes concrete, resource-efficient quantum analogue of NUDFT and provides foundation for quantum algorithms on irregularly sampled data."}}
{"id": "2602.14853", "pdf": "https://arxiv.org/pdf/2602.14853", "abs": "https://arxiv.org/abs/2602.14853", "authors": ["Jonathan Gorard", "Ammar Hakim", "James Juno"], "title": "BEACONS: Bounded-Error, Algebraically-Composable Neural Solvers for Partial Differential Equations", "categories": ["cs.LG", "math.NA", "physics.comp-ph"], "comment": "31 pages, 8 figures, 9 tables", "summary": "The traditional limitations of neural networks in reliably generalizing beyond the convex hulls of their training data present a significant problem for computational physics, in which one often wishes to solve PDEs in regimes far beyond anything which can be experimentally or analytically validated. In this paper, we show how it is possible to circumvent these limitations by constructing formally-verified neural network solvers for PDEs, with rigorous convergence, stability, and conservation properties, whose correctness can therefore be guaranteed even in extrapolatory regimes. By using the method of characteristics to predict the analytical properties of PDE solutions a priori (even in regions arbitrarily far from the training domain), we show how it is possible to construct rigorous extrapolatory bounds on the worst-case L^inf errors of shallow neural network approximations. Then, by decomposing PDE solutions into compositions of simpler functions, we show how it is possible to compose these shallow neural networks together to form deep architectures, based on ideas from compositional deep learning, in which the large L^inf errors in the approximations have been suppressed. The resulting framework, called BEACONS (Bounded-Error, Algebraically-COmposable Neural Solvers), comprises both an automatic code-generator for the neural solvers themselves, as well as a bespoke automated theorem-proving system for producing machine-checkable certificates of correctness. We apply the framework to a variety of linear and non-linear PDEs, including the linear advection and inviscid Burgers' equations, as well as the full compressible Euler equations, in both 1D and 2D, and illustrate how BEACONS architectures are able to extrapolate solutions far beyond the training data in a reliable and bounded way. Various advantages of the approach over the classical PINN approach are discussed.", "AI": {"tldr": "BEACONS framework creates formally-verified neural PDE solvers with guaranteed correctness even far beyond training data, using compositional deep learning and automated theorem proving.", "motivation": "Neural networks struggle to generalize beyond convex hulls of training data, which is problematic for computational physics where PDEs often need solving in regimes far beyond experimentally or analytically validated domains.", "method": "Uses method of characteristics to predict analytical properties of PDE solutions a priori, constructs rigorous extrapolatory bounds on worst-case L^inf errors of shallow neural approximations, then composes them into deep architectures using compositional deep learning to suppress large errors. Includes automatic code-generator and bespoke automated theorem-proving system.", "result": "Applied to linear advection, inviscid Burgers', and full compressible Euler equations in 1D/2D, BEACONS architectures reliably extrapolate solutions far beyond training data with bounded errors, showing advantages over classical PINN approach.", "conclusion": "BEACONS framework successfully circumvents neural network generalization limitations by providing formally-verified neural PDE solvers with rigorous convergence, stability, and conservation properties that guarantee correctness even in extrapolatory regimes."}}
{"id": "2602.13929", "pdf": "https://arxiv.org/pdf/2602.13929", "abs": "https://arxiv.org/abs/2602.13929", "authors": ["Patrick Heslin", "Stephen C. Preston"], "title": "Exact non-stationary solutions of the Euler equations in two and three dimensions", "categories": ["math.AP", "math.DG"], "comment": "Draft version prior to submission for publication", "summary": "We develop, via Arnold's geometric framework, a mechanism for constructing explicit, smooth, global-in-time, and typically non-stationary solutions of the incompressible Euler equations. The approach introduces a notion of generalized Coriolis force, whose spectrum underlies the construction of these solutions. In the setting of ideal hydrodynamics, the construction recovers classical exact solutions such as Kelvin and Rossby-Haurwitz waves, while also producing new explicit examples on curved surfaces and three-dimensional manifolds including the round three-sphere. We further obtain a complete classification in two dimensions and a partial classification in three dimensions of the Riemannian manifolds that admit such solutions. The method is also formulated in the general Euler-Arnold setting and yields a simple criterion for non-stationarity.", "AI": {"tldr": "The paper develops a geometric framework using Arnold's approach to construct explicit, smooth, global-in-time, non-stationary solutions to incompressible Euler equations via generalized Coriolis forces.", "motivation": "To develop a systematic geometric framework for constructing explicit, smooth, global-in-time solutions to the incompressible Euler equations, going beyond classical stationary solutions and enabling new discoveries on curved manifolds.", "method": "Uses Arnold's geometric framework to introduce a notion of generalized Coriolis force, whose spectrum underlies the construction of solutions. The method is formulated in the general Euler-Arnold setting and provides a criterion for non-stationarity.", "result": "Recovers classical exact solutions (Kelvin and Rossby-Haurwitz waves), produces new explicit examples on curved surfaces and 3D manifolds including the round three-sphere, and obtains complete classification in 2D and partial classification in 3D of Riemannian manifolds admitting such solutions.", "conclusion": "The geometric framework provides a powerful mechanism for constructing explicit non-stationary solutions to Euler equations, extending classical results to curved manifolds and offering classification insights across dimensions."}}
{"id": "2602.13513", "pdf": "https://arxiv.org/pdf/2602.13513", "abs": "https://arxiv.org/abs/2602.13513", "authors": ["Grant Norman", "Conor Rowan", "Kurt Maute", "Alireza Doostan"], "title": "Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization", "categories": ["math.OC", "cs.CE", "cs.LG", "math.DS", "math.NA"], "comment": "44 pages, 13 figures. To be submitted to CMAME", "summary": "In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient.", "AI": {"tldr": "The paper introduces Learned Gradient Flow (LGF) optimizer, which uses data-driven equation discovery to learn continuous-time dynamics from optimization trajectory data, creating surrogate models that accelerate convergence by avoiding expensive objective function and gradient evaluations.", "motivation": "Traditional optimization methods require expensive evaluations of objective functions and their gradients. The authors aim to develop a more efficient approach by learning continuous-time dynamics from optimization trajectory data to create surrogate models that can accelerate convergence.", "method": "The authors leverage trajectory data on optimization variables to learn continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization using data-driven equation discovery. They introduce the Learned Gradient Flow (LGF) optimizer, which builds surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals during optimization.", "result": "The approach was demonstrated on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Results show that learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations.", "conclusion": "The Learned Gradient Flow optimizer provides an effective data-driven approach to accelerate optimization by learning continuous-time dynamics from trajectory data, creating surrogate models that avoid expensive objective function and gradient evaluations while maintaining convergence properties."}}
{"id": "2602.13963", "pdf": "https://arxiv.org/pdf/2602.13963", "abs": "https://arxiv.org/abs/2602.13963", "authors": ["Evan Miller"], "title": "Global regularity for axisymmetric, swirl-free solutions of the Euler equation in four dimensions", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we prove global regularity for all smooth, axisymmetric, swirl-free solutions of the Euler equation in four dimensions. Previous works establishing global regularity for certain axisymmetric, swirl-free solutions of the Euler equation in four dimensions required the additional assumption that $\\frac{\u03c9^0}{r^2}\\in L^\\infty$, which can fail even for Schwartz class solutions. The key advance is a new bound on the vortex stretching term that only requires $\\frac{\u03c9^0}{r^2}\\in L^{2,1}(\\mathbb{R}^4)$, which is generically true for any axisymmetric, swirl-free initial data $u^0\\in H^s\\left(\\mathbb{R}^4\\right), s>4$, with reasonable decay at infinity.", "AI": {"tldr": "Global regularity proven for all smooth axisymmetric swirl-free Euler solutions in 4D without requiring \u03c9\u2070/r\u00b2 \u2208 L\u221e, only needing \u03c9\u2070/r\u00b2 \u2208 L\u00b2,\u00b9.", "motivation": "Previous global regularity results for 4D axisymmetric swirl-free Euler solutions required \u03c9\u2070/r\u00b2 \u2208 L\u221e, which can fail even for Schwartz class solutions. This limitation needed to be overcome.", "method": "Developed a new bound on the vortex stretching term that only requires \u03c9\u2070/r\u00b2 \u2208 L\u00b2,\u00b9(\u211d\u2074) instead of the stronger L\u221e condition.", "result": "Proved global regularity for all smooth axisymmetric swirl-free Euler solutions in 4D with initial data u\u2070 \u2208 H\u02e2(\u211d\u2074), s>4, having reasonable decay at infinity.", "conclusion": "The weaker condition \u03c9\u2070/r\u00b2 \u2208 L\u00b2,\u00b9 is generically satisfied for axisymmetric swirl-free initial data, making global regularity results more broadly applicable than previous work."}}
{"id": "2602.13565", "pdf": "https://arxiv.org/pdf/2602.13565", "abs": "https://arxiv.org/abs/2602.13565", "authors": ["Paromita Banerjee", "Anirban Mondal"], "title": "An Improved Milstein Method for the Numerical Solution of Multidimensional Stochastic Differential Equations", "categories": ["math.ST", "math.NA", "math.PR", "stat.OT"], "comment": null, "summary": "Stochastic differential equations (SDEs) offer powerful and accessible mathematical models for capturing both deterministic and probabilistic aspects of dynamic behavior across a wide range of physical, financial, and social systems. However, analytical solutions for many SDEs are often unavailable, necessitating the use of numerical approximation methods. The rate of convergence of such numerical methods is of great importance, as it directly influences both computational efficiency and accuracy. This paper presents a proposed theorem, along with its proof, that facilitates the numerical evaluation of the strong (and weak) order of convergence of a numerical scheme for an SDE when the analytical solution is unavailable. Additionally, we address the challenge of numerically computing the multiple stochastic integrals required by the Milstein method to achieve improved convergence rates for multidimensional SDEs. In this context, two newly proposed numerical techniques for computing these multiple stochastic integrals are introduced and compared with existing approaches in terms of efficiency and effectiveness. The methodologies are further illustrated through simulation studies and applications to widely used financial models.", "AI": {"tldr": "The paper proposes a theorem for numerically evaluating convergence orders of SDE numerical schemes when analytical solutions are unavailable, and introduces new methods for computing multiple stochastic integrals in Milstein schemes.", "motivation": "SDEs are important for modeling dynamic systems but often lack analytical solutions, requiring numerical methods. Determining convergence rates of these methods is crucial for computational efficiency and accuracy, especially when analytical solutions are unavailable.", "method": "1) Proposes and proves a theorem for numerically evaluating strong/weak convergence orders without analytical solutions. 2) Introduces two new numerical techniques for computing multiple stochastic integrals required by Milstein method for multidimensional SDEs.", "result": "The proposed theorem enables numerical evaluation of convergence orders. The new multiple stochastic integral computation methods are compared with existing approaches and shown to be efficient and effective through simulation studies.", "conclusion": "The paper provides practical tools for assessing numerical scheme convergence in SDEs without analytical solutions, and improves computational methods for Milstein schemes in multidimensional SDE applications, particularly in finance."}}
{"id": "2602.14962", "pdf": "https://arxiv.org/pdf/2602.14962", "abs": "https://arxiv.org/abs/2602.14962", "authors": ["Benjamin X. Shi", "Timothy Berkelbach"], "title": "Practical and improved density functionals for computational catalysis on metal surfaces", "categories": ["cond-mat.mtrl-sci", "physics.chem-ph", "physics.comp-ph"], "comment": null, "summary": "Density functional theory (DFT) has been critical towards our current atomistic understanding of catalysis on transition-metal surfaces. It has opened new paradigms in rational catalyst design, predicting fundamental properties, like the adsorption energy and reaction barriers, linked to catalytic performance. However, such applications depend sensitively on the predictive accuracy of DFT and achieving experimental-level reliability, so-called transition-metal chemical accuracy (13 kJ/mol), remains challenging for present density functional approximations (DFAs) or even methods beyond DFT. We introduce a new framework for designing DFAs tailored towards studying molecules adsorbed on transition-metal surfaces, building upon recent developments in non-self-consistent DFAs. We propose two functionals within this framework, demonstrating that transition-metal chemical accuracy can be achieved across a diverse set of 39 adsorption reactions while delivering consistent performance for 17 barrier heights. Moreover, we show that these non-self-consistent DFAs address qualitative failures that challenge current self-consistent DFAs, such as CO adsorption on Pt(111) and graphene on Ni(111). The resulting functionals are computationally practical and compatible with existing DFT codes, with scripts and workflows provided to use them. Looking ahead, this framework establishes a path toward developing more accurate and sophisticated DFAs for computational heterogeneous catalysis and beyond.", "AI": {"tldr": "New framework for designing density functional approximations (DFAs) tailored for molecules adsorbed on transition-metal surfaces achieves transition-metal chemical accuracy (13 kJ/mol) for adsorption energies and reaction barriers.", "motivation": "Current DFT methods struggle to achieve experimental-level reliability (transition-metal chemical accuracy of 13 kJ/mol) for catalysis on transition-metal surfaces, which limits rational catalyst design and predictive accuracy for adsorption energies and reaction barriers.", "method": "Developed a new framework for designing DFAs specifically for molecules adsorbed on transition-metal surfaces, building on recent non-self-consistent DFA developments. Proposed two functionals within this framework that use non-self-consistent approaches.", "result": "Achieved transition-metal chemical accuracy (13 kJ/mol) across 39 diverse adsorption reactions and consistent performance for 17 barrier heights. Successfully addressed qualitative failures of current self-consistent DFAs, such as CO adsorption on Pt(111) and graphene on Ni(111). Functionals are computationally practical and compatible with existing DFT codes.", "conclusion": "The framework establishes a path toward developing more accurate and sophisticated DFAs for computational heterogeneous catalysis, offering improved predictive accuracy for transition-metal surface chemistry while maintaining computational practicality."}}
{"id": "2602.13978", "pdf": "https://arxiv.org/pdf/2602.13978", "abs": "https://arxiv.org/abs/2602.13978", "authors": ["Weiqi Guan"], "title": "Constrained variational problems on perturbed lattice graphs", "categories": ["math.AP"], "comment": "17 pages", "summary": "In this paper, we solve some constrained variational problems on perturbed lattice graphs $G$. The first problem addresses the existence of ground state normalized solutions to Schr\u00f6dinger equations\n  \\begin{equation*} \\left\\{\n  \\begin{aligned}\n  &-\u0394_{G} u+\u03bbu=\\vert u\\vert^{p-2}u,x\\in G\n  &\\Vert u\\Vert_{l^2(G)}^2=a.\n  \\end{aligned}\n  \\right. \\end{equation*} We prove that if the graph is obtained by deleting finite edges in lattice graphs while maintaining connectivity, then there exists a threshold $\u03b1_G\\in[0,\\infty)$ such that there do not exist ground state normalized solution if $0<a<\u03b1_G$, and there exists a ground state normalized solution if $a>\u03b1_G.$ If the graph is obtained by adding finite edges $E^{'}$ to lattice graphs, we prove that there exist $E^{'}$ and $a_1$ such that for all $a>a_1,$ there do not exist ground state normalized solutions.\n  The second problem concerns the existence of an extremal function for the Sobolev inequality. If the graph $G$ is obtained by deleting finite edges in lattice graphs while maintaining connectivity, for the Sobolev super-critical regime, we prove that there exists an extremal function. for the Sobolev critical regime, we prove that there exists $G$ such that extremal can be attained. If the graph is obtained by adding finite edges $E^{'}$ to lattice graphs, we prove that there exists $E^{'}$ such that there does not exist an extremal function.", "AI": {"tldr": "Existence of ground state normalized solutions to Schr\u00f6dinger equations and extremal functions for Sobolev inequalities on perturbed lattice graphs, with different behaviors depending on whether edges are deleted or added.", "motivation": "To study constrained variational problems on perturbed lattice graphs, specifically examining how edge modifications (deletion or addition) affect the existence of ground state normalized solutions to Schr\u00f6dinger equations and extremal functions for Sobolev inequalities.", "method": "Analyze two types of perturbed lattice graphs: (1) graphs obtained by deleting finite edges while maintaining connectivity, and (2) graphs obtained by adding finite edges. For each type, study the existence of ground state normalized solutions to Schr\u00f6dinger equations with L\u00b2 constraint and extremal functions for Sobolev inequalities in super-critical and critical regimes.", "result": "For edge-deleted graphs: there exists threshold \u03b1_G such that no ground state normalized solutions exist for 0 < a < \u03b1_G, but solutions exist for a > \u03b1_G. For Sobolev inequalities, extremal functions exist in super-critical regime, and some graphs admit extremals in critical regime. For edge-added graphs: certain edge additions E' and threshold a\u2081 exist such that no ground state normalized solutions exist for all a > a\u2081, and some E' prevent existence of extremal functions for Sobolev inequalities.", "conclusion": "Edge modifications significantly affect existence properties of constrained variational problems on lattice graphs. Edge deletion generally preserves or enables solution existence under certain conditions, while edge addition can prevent existence of both ground state normalized solutions and Sobolev extremal functions."}}
{"id": "2602.13620", "pdf": "https://arxiv.org/pdf/2602.13620", "abs": "https://arxiv.org/abs/2602.13620", "authors": ["Xiaozhe Hu", "Sara Pollock", "Zhongqin Xue", "Yunrong Zhu"], "title": "An adaptive framework for first-order gradient methods", "categories": ["math.OC", "math.NA"], "comment": null, "summary": "Gradient methods are widely used in optimization problems. In practice, while the smoothness parameter can be estimated utilizing techniques such as backtracking, estimating the strong convexity parameter remains a challenge; moreover, even with the optimal parameter choice, convergence can be slow. In this work, we propose a framework for dynamically adapting the step size and momentum parameters in first-order gradient methods for the optimization problem, without prior knowledge of the strong convexity parameter. The main idea is to use the geometric average of the ratios of successive residual norms as an empirical estimate of the upper bound on the convergence rate, which in turn allows us to adaptively update the algorithm parameters. The resulting algorithms are simple to implement, yet efficient in practice, requiring only a few additional computations on existing information. The proposed adaptive gradient methods are shown to converge at least as fast as gradient descent for quadratic optimization problems. Numerical experiments on both quadratic and nonlinear problems validate the effectiveness of the proposed adaptive algorithms. The results show that the adaptive algorithms are comparable to their counterparts using optimal parameters, and in some cases, they capture local information and exhibit improved performance.", "AI": {"tldr": "Proposes adaptive gradient methods that dynamically adjust step size and momentum without needing strong convexity parameter, using geometric average of residual ratios to estimate convergence rate.", "motivation": "Gradient methods require smoothness and strong convexity parameters for optimal performance. While smoothness can be estimated via backtracking, strong convexity estimation is challenging, and even with optimal parameters, convergence can be slow.", "method": "Framework using geometric average of successive residual norm ratios as empirical estimate of convergence rate upper bound. This estimate enables adaptive updates of step size and momentum parameters without prior knowledge of strong convexity parameter.", "result": "Algorithms converge at least as fast as gradient descent for quadratic problems. Numerical experiments on quadratic and nonlinear problems show adaptive methods perform comparably to optimal-parameter counterparts, sometimes capturing local information for improved performance.", "conclusion": "Proposed adaptive gradient methods are simple to implement, efficient, and effective alternatives that don't require strong convexity parameter knowledge while maintaining or improving convergence performance."}}
{"id": "2602.13986", "pdf": "https://arxiv.org/pdf/2602.13986", "abs": "https://arxiv.org/abs/2602.13986", "authors": ["Cong-Bang Trang", "Hoang-Hung Vo"], "title": "Spectral Theory of Fractional Cooperative Systems and Threshold Dynamics in Epidemic Models", "categories": ["math.AP"], "comment": null, "summary": "Spectral analysis has long been recognized as a fundamental tool for studying the existence, uniqueness, and qualitative behavior of solutions to semilinear elliptic and parabolic equations, as well as their long-time dynamics. In modern mathematics, fractional Laplacians are widely used to model nonlocal or long-range diffusion processes arising in biology, including anomalous movement, long-distance dispersal, and Levy-flight migration of organisms, cells, and epidemics.\n  In this paper, we employ the spectral fractional Laplacian introduced by Caffarelli and Stinga (2016) to develop the eigentheory for a cooperative system describing an infectious epidemic process and to analyze its long-term behavior. Using Fredholm theory and related analytical techniques, building in part on ideas of Lam and Lou (2016), we establish a sharp criterion ensuring the existence and simplicity of the principal eigenvalue, together with variational characterizations and consequences for the validity of maximum principles. We further derive the asymptotic behavior of the principal eigenvalue with respect to diffusion coefficients, fractional orders, and domain scaling, complementing recent developments by Zhao and Ruan (2023) and Feng, Li, Ruan, and Xin (2024).\n  As an application of this spectral framework, we prove the existence, uniqueness, and threshold-type long-time dynamics of solutions to an endemic reaction-diffusion system with fractional diffusion, providing a perspective that differs from earlier approaches such as Hsu and Yang (2013). Our results contribute to the growing interaction between spectral theory and nonlocal analysis, in line with recent advances in the area.", "AI": {"tldr": "The paper develops spectral theory for cooperative epidemic systems with fractional diffusion, establishing eigenvalue criteria and applying it to prove threshold dynamics in endemic models.", "motivation": "Fractional Laplacians model nonlocal diffusion in biological processes like epidemic spread, but spectral theory for such systems needs development. The paper aims to bridge spectral theory with nonlocal analysis for epidemic models.", "method": "Uses spectral fractional Laplacian (Caffarelli & Stinga, 2016) with Fredholm theory and analytical techniques (building on Lam & Lou, 2016). Develops eigentheory for cooperative epidemic systems, establishing principal eigenvalue existence/simplicity, variational characterizations, and maximum principles.", "result": "Establishes sharp criterion for principal eigenvalue existence/simplicity, derives asymptotic behavior with respect to diffusion coefficients, fractional orders, and domain scaling. Proves existence, uniqueness, and threshold-type long-time dynamics for endemic reaction-diffusion systems with fractional diffusion.", "conclusion": "The spectral framework bridges spectral theory and nonlocal analysis, providing new tools for studying epidemic dynamics with fractional diffusion, differing from earlier approaches and contributing to advances in the field."}}
{"id": "2602.13759", "pdf": "https://arxiv.org/pdf/2602.13759", "abs": "https://arxiv.org/abs/2602.13759", "authors": ["ZhiMing Li", "JiaHe Feng"], "title": "Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition", "categories": ["cs.LG", "math.NA", "math.OC"], "comment": "75 pages, 9 figures", "summary": "We study matrix-free eigendecomposition under a matrix-vector product (MVP) oracle, where each step observes a covariance operator $C_k = C_{sig} + \u03c3_k^2 I + E_k$. Standard stochastic approximation methods either use fixed steps that couple stability to $\\|C_k\\|_2$, or adapt steps in ways that slow down due to vanishing updates. We introduce a discrete double-bracket flow whose generator is invariant to isotropic shifts, yielding pathwise invariance to $\u03c3_k^2 I$ at the discrete-time level. The resulting trajectory and a maximal stable step size $\u03b7_{max} \\propto 1/\\|C_e\\|_2^2$ depend only on the trace-free covariance $C_e$. We establish global convergence via strict-saddle geometry for the diagonalization objective and an input-to-state stability analysis, with sample complexity scaling as $O(\\|C_e\\|_2^2 / (\u0394^2 \u03b5))$ under trace-free perturbations. An explicit characterization of degenerate blocks yields an accelerated $O(\\log(1/\u03b6))$ saddle-escape rate and a high-probability finite-time convergence guarantee.", "AI": {"tldr": "Novel discrete double-bracket flow algorithm for matrix-free eigendecomposition that achieves pathwise invariance to isotropic noise, with convergence guarantees and improved sample complexity.", "motivation": "Standard stochastic approximation methods for eigendecomposition under matrix-vector product oracles either use fixed step sizes that couple stability to noise covariance, or adaptive steps that slow down due to vanishing updates. The authors aim to develop a method that is invariant to isotropic noise shifts while maintaining efficient convergence.", "method": "Introduces a discrete double-bracket flow whose generator is invariant to isotropic shifts, making the trajectory pathwise invariant to isotropic noise components. The algorithm uses a maximal stable step size \u03b7_max \u221d 1/\u2016C_e\u2016\u2082\u00b2 that depends only on the trace-free covariance C_e. The method includes explicit characterization of degenerate blocks for accelerated saddle-escape.", "result": "Establishes global convergence via strict-saddle geometry and input-to-state stability analysis. Achieves sample complexity scaling as O(\u2016C_e\u2016\u2082\u00b2/(\u0394\u00b2\u03b5)) under trace-free perturbations. Provides accelerated O(log(1/\u03b6)) saddle-escape rate and high-probability finite-time convergence guarantee.", "conclusion": "The proposed discrete double-bracket flow algorithm successfully decouples stability from isotropic noise, enabling efficient matrix-free eigendecomposition with provable convergence guarantees and improved sample complexity compared to existing stochastic approximation methods."}}
{"id": "2602.13995", "pdf": "https://arxiv.org/pdf/2602.13995", "abs": "https://arxiv.org/abs/2602.13995", "authors": ["Nicola De Nitti", "Jie Guo", "Quansen Jiu"], "title": "Stability and instability of a one-dimensional MHD model", "categories": ["math.AP"], "comment": null, "summary": "We consider a one-dimensional magnetohydrodynamics model introduced by Dai \\textit{et al.}~(2023), in a parameter regime where, in the absence of a magnetic field, the system reduces to the De Gregorio model for the Euler equations. We analyze stability and instability near the first excited state on the torus, thus generalizing the recent results obtained by Guo and Jiu~(2025) for the De Gregorio model. Specifically, we establish global well-posedness of the linearized system, local well-posedness for the nonlinear system, and demonstrate both linear and nonlinear instability for a broad class of initial data in the weighted Sobolev space introduced by Lai \\textit{et al.}~(2020). We identify the principal linearized operator, which is structurally equivalent to that of the De Gregorio model, as the primary mechanism of instability. Moreover, we prove global well-posedness and stability of both linear and nonlinear systems for initial data in a particular subspace of the aforementioned weighted Sobolev space.", "AI": {"tldr": "Analysis of stability/instability near first excited state in 1D MHD model (Dai et al. 2023), generalizing Guo & Jiu's De Gregorio results. Shows global linear well-posedness, local nonlinear well-posedness, and instability for broad class of initial data in weighted Sobolev space.", "motivation": "Extend stability analysis from De Gregorio model (Euler equations without magnetic field) to magnetohydrodynamics setting. Understand how magnetic field affects stability properties near excited states in 1D MHD systems.", "method": "Analyze linearized system around first excited state on torus. Use weighted Sobolev spaces (Lai et al. 2020). Identify principal linearized operator structurally equivalent to De Gregorio model. Study both linear and nonlinear systems in specific subspaces.", "result": "1) Global well-posedness of linearized system. 2) Local well-posedness for nonlinear system. 3) Linear and nonlinear instability for broad class of initial data. 4) Global well-posedness and stability in particular subspace of weighted Sobolev space.", "conclusion": "MHD model inherits instability mechanism from De Gregorio model through structurally equivalent principal linearized operator. Magnetic field doesn't stabilize system for general initial data, but stability can be achieved in specific subspaces."}}
{"id": "2602.14053", "pdf": "https://arxiv.org/pdf/2602.14053", "abs": "https://arxiv.org/abs/2602.14053", "authors": ["Sourabh Bhattacharya"], "title": "Mean-Square Convergence of a New Parameterized Leapfrog Scheme for Hamiltonian Systems Driven by Gaussian Process Potentials", "categories": ["math.ST", "math.NA"], "comment": "Feedback welcome", "summary": "This paper establishes the mean-square convergence of a new stochastic, parameterized leapfrog scheme introduced in our companion paper Mazumder et al. (2026) for Hamiltonian systems with Gaussian process potentials. We consider a one-step numerical integrator and provide a complete, rigorous analysis under minimal regularity assumptions on the Gaussian potential. The key technical contribution is identifying and exploiting the symplectic structure ingrained in our stochastic, parameterized leapfrog method. Combined with local truncation error analysis, this leads to a global error bound of O(\u03b4t) in mean-square sense. Our results establish that although the spatio-temporal model of Mazumder et al. (2026) arises as the anticipated new stochastic leapfrog solution of a system of modified (parameterized) stochastic Hamiltonian equations, the new stochastic leapfrog actually solves the traditional stochastic Hamiltonian equations, driven by Gaussian process potential.", "AI": {"tldr": "The paper proves mean-square convergence of a new stochastic parameterized leapfrog scheme for Hamiltonian systems with Gaussian process potentials, achieving O(\u03b4t) global error bound.", "motivation": "To establish rigorous convergence analysis for a novel stochastic leapfrog scheme introduced in a companion paper, specifically for Hamiltonian systems with Gaussian process potentials, under minimal regularity assumptions.", "method": "Uses a one-step numerical integrator with symplectic structure analysis and local truncation error analysis to prove convergence. The key insight is identifying and exploiting the symplectic structure inherent in the stochastic parameterized leapfrog method.", "result": "Proves mean-square convergence with O(\u03b4t) global error bound, establishing that the new stochastic leapfrog scheme actually solves traditional stochastic Hamiltonian equations driven by Gaussian process potentials, despite arising from modified parameterized equations.", "conclusion": "The new stochastic parameterized leapfrog scheme converges in mean-square sense with first-order accuracy, providing rigorous theoretical foundation for numerical integration of Hamiltonian systems with Gaussian process potentials while preserving symplectic structure."}}
{"id": "2602.14019", "pdf": "https://arxiv.org/pdf/2602.14019", "abs": "https://arxiv.org/abs/2602.14019", "authors": ["Fei Hou", "Huicheng Yin", "Meng Yuan"], "title": "Long time smooth solutions of 2-D quadratic quasilinear wave equations in exterior domains with Neumann boundary conditions", "categories": ["math.AP"], "comment": null, "summary": "For the 3-D quadratic quasilinear wave equations in exterior domains with Dirichlet or Neumann boundary conditions, the global existence or the maximal existence time of small data smooth solutions have been established in the past. However, so far it is still open for the corresponding 2-D Neumann boundary value problem. In this paper, we investigate the long time existence of small data solutions to 2-D quadratic quasilinear wave equations with homogeneous Neumann boundary values. Our main ingredients include: establishing some new pointwise spacetime decay estimates for the 2-D initial boundary value problem of the divergence form wave equations, and introducing a series of good unknowns to derive the required energy estimates. The obtained results can be directly applied to the initial boundary value problem of 2-D isentropic and irrotational compressible Euler equations for both the polytropic gases and the Chaplygin gases in exterior domains with impermeable conditions, the 2-D relativistic membrane equations and 2-D membrane equations with homogeneous Neumann boundary values.", "AI": {"tldr": "This paper establishes long-time existence of small data solutions for 2-D quadratic quasilinear wave equations with Neumann boundary conditions, solving an open problem in the field.", "motivation": "While global existence or maximal existence time for 3-D quadratic quasilinear wave equations with Dirichlet/Neumann boundary conditions has been established, the corresponding 2-D Neumann boundary value problem remained open. This paper aims to address this gap.", "method": "The authors develop new pointwise spacetime decay estimates for 2-D initial boundary value problems of divergence form wave equations, and introduce a series of \"good unknowns\" to derive required energy estimates.", "result": "The paper establishes long-time existence of small data solutions to 2-D quadratic quasilinear wave equations with homogeneous Neumann boundary values.", "conclusion": "The results have direct applications to several important physical systems including 2-D isentropic/irrotational compressible Euler equations for polytropic and Chaplygin gases, relativistic membrane equations, and membrane equations with Neumann boundary conditions in exterior domains."}}
{"id": "2602.14061", "pdf": "https://arxiv.org/pdf/2602.14061", "abs": "https://arxiv.org/abs/2602.14061", "authors": ["Sourabh Bhattacharya"], "title": "MPL-HMC: A Tunable Parameterized Leapfrog Framework for Robust Hamiltonian Monte Carlo", "categories": ["stat.CO", "math.NA"], "comment": "Feedback welcome", "summary": "This article introduces the Modified Parameterized Leapfrog Hamiltonian Monte Carlo (MPL-HMC) method, a novel extension of HMC addressing key limitations through tunable integration parameters $\u03b1(\u03b4t)$ and $\u03b2(\u03b4t)$, enabling controlled perturbations to Hamiltonian dynamics. Theoretical analysis demonstrates MPL-HMC maintains approximate detailed balance. Extensive empirical evaluation reveals systematic performance improvements. The damping variant ($\u03b1_2=-0.1$, $\u03b2_2=-0.05$) achieves a 14-fold increase in effective sample size for Neal's funnel and 27\\% better efficiency for pharmacokinetic models. The anti-damping variant ($\u03b1_2=0.1$, $\u03b2_2=0.05$) achieves $\\hat{R}=1.026$ for Bayesian neural networks versus $\\hat{R}=1.981$ for standard HMC. We introduce aggressive MPL-HMC for multimodal distributions, employing extreme parameters ($\u03b1_2=8.0$--$15.0$, $\u03b2_2=5.0$--$8.0$) with enhanced sampling to achieve full mode exploration where standard methods fail. All variants maintain computational efficiency identical to standard HMC while providing systematic control over damping, exploration, stability, and accuracy. The article provides rigorous mathematical foundations, implementation specifications, parameter tuning strategies, and comprehensive performance comparisons, extending HMC's applicability to previously challenging domains.", "AI": {"tldr": "MPL-HMC introduces tunable parameters \u03b1(\u03b4t) and \u03b2(\u03b4t) to modify Hamiltonian dynamics, achieving significant performance improvements over standard HMC while maintaining computational efficiency.", "motivation": "Standard Hamiltonian Monte Carlo (HMC) has limitations in sampling efficiency, particularly for challenging distributions like multimodal targets, Bayesian neural networks, and complex hierarchical models. The authors aim to extend HMC's applicability by introducing controlled perturbations to Hamiltonian dynamics.", "method": "Modified Parameterized Leapfrog Hamiltonian Monte Carlo (MPL-HMC) introduces tunable integration parameters \u03b1(\u03b4t) and \u03b2(\u03b4t) that control perturbations to Hamiltonian dynamics. Three variants are developed: damping variant (\u03b1\u2082=-0.1, \u03b2\u2082=-0.05), anti-damping variant (\u03b1\u2082=0.1, \u03b2\u2082=0.05), and aggressive variant (\u03b1\u2082=8.0-15.0, \u03b2\u2082=5.0-8.0) for multimodal distributions. The method maintains approximate detailed balance and identical computational cost to standard HMC.", "result": "Damping variant achieves 14-fold increase in effective sample size for Neal's funnel and 27% better efficiency for pharmacokinetic models. Anti-damping variant achieves R\u0302=1.026 for Bayesian neural networks versus R\u0302=1.981 for standard HMC. Aggressive variant enables full mode exploration in multimodal distributions where standard methods fail. All variants maintain computational efficiency identical to standard HMC.", "conclusion": "MPL-HMC provides systematic control over damping, exploration, stability, and accuracy while maintaining computational efficiency. The method extends HMC's applicability to previously challenging domains including Bayesian neural networks, multimodal distributions, and complex hierarchical models, with rigorous mathematical foundations and practical implementation guidelines."}}
{"id": "2602.14064", "pdf": "https://arxiv.org/pdf/2602.14064", "abs": "https://arxiv.org/abs/2602.14064", "authors": ["Heming Jiao", "Zhenan Sui"], "title": "Interior Hessian estimates for Hessian quotient equations in dimension three", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we establish the interior Hessian estimates for $2$-convex solutions to $\\frac{\u03c3_2}{\u03c3_1} (D^2 u) = \u03c8(x,u)$ in dimension three. In higher dimensions ($n \\geq 4$), we prove the interior Hessian estimates for semi-convex solutions. We provide a new method to prove the doubling inequality for smooth solutions in dimensions three and four. In higher dimensions ($n\\geq 5$) the doubling inequality is proved under an additional dynamic semi-convexity condition which is the same to that in \\cite{SY2025}. The method also applies to the equation $\u03c3_2 (D^2 u) = \u03c8(x, u, \\nabla u)$.", "AI": {"tldr": "The paper establishes interior Hessian estimates for 2-convex solutions to \u03c3\u2082/\u03c3\u2081(D\u00b2u) = \u03c8(x,u) in dimension 3, and for semi-convex solutions in higher dimensions (n\u22654). It also provides new methods for proving doubling inequalities in dimensions 3-4, and under additional conditions for n\u22655.", "motivation": "The motivation is to develop interior regularity theory for solutions to fully nonlinear elliptic equations involving elementary symmetric functions of the Hessian matrix. Specifically, the paper aims to establish Hessian estimates and doubling inequalities for solutions to equations involving \u03c3\u2082/\u03c3\u2081 and \u03c3\u2082, which are important in geometric analysis and PDE theory.", "method": "The authors develop a new method to prove doubling inequalities for smooth solutions in dimensions three and four. For higher dimensions (n\u22655), they prove doubling inequalities under an additional dynamic semi-convexity condition. The method also extends to equations of the form \u03c3\u2082(D\u00b2u) = \u03c8(x, u, \u2207u).", "result": "Main results: 1) Interior Hessian estimates for 2-convex solutions to \u03c3\u2082/\u03c3\u2081(D\u00b2u) = \u03c8(x,u) in dimension 3; 2) Interior Hessian estimates for semi-convex solutions in higher dimensions (n\u22654); 3) New doubling inequality proofs for smooth solutions in dimensions 3-4; 4) Doubling inequalities under dynamic semi-convexity condition for n\u22655.", "conclusion": "The paper provides significant advances in the regularity theory for fully nonlinear elliptic equations involving elementary symmetric functions. The new methods for proving doubling inequalities and Hessian estimates extend previous results and apply to broader classes of equations, contributing to the understanding of interior regularity for these important PDEs."}}
{"id": "2602.14289", "pdf": "https://arxiv.org/pdf/2602.14289", "abs": "https://arxiv.org/abs/2602.14289", "authors": ["Xiaoye Sherry Li", "Yang Liu"], "title": "Parallel Sparse and Data-Sparse Factorization-based Linear Solvers", "categories": ["cs.MS", "cs.DC", "math.NA"], "comment": null, "summary": "Efficient solutions of large-scale, ill-conditioned and indefinite algebraic equations are ubiquitously needed in numerous computational fields, including multiphysics simulations, machine learning, and data science. Because of their robustness and accuracy, direct solvers are crucial components in building a scalable solver toolchain. In this article, we will review recent advances of sparse direct solvers along two axes: 1) reducing communication and latency costs in both task- and data-parallel settings, and 2) reducing computational complexity via low-rank and other compression techniques such as hierarchical matrix algebra. In addition to algorithmic principles, we also illustrate the key parallelization challenges and best practices to deliver high speed and reliability on modern heterogeneous parallel machines.", "AI": {"tldr": "Recent advances in sparse direct solvers focusing on communication reduction and computational complexity reduction via compression techniques for large-scale ill-conditioned systems.", "motivation": "Large-scale, ill-conditioned, and indefinite algebraic equations are ubiquitous in multiphysics simulations, machine learning, and data science. Direct solvers are crucial for scalable solver toolchains due to their robustness and accuracy.", "method": "Review of recent advances along two axes: 1) reducing communication and latency costs in task- and data-parallel settings, and 2) reducing computational complexity via low-rank and hierarchical matrix compression techniques.", "result": "The paper reviews algorithmic principles and illustrates key parallelization challenges and best practices for delivering high speed and reliability on modern heterogeneous parallel machines.", "conclusion": "Sparse direct solvers continue to advance through communication optimization and compression techniques, enabling efficient solutions for large-scale ill-conditioned systems on modern parallel architectures."}}
{"id": "2602.14070", "pdf": "https://arxiv.org/pdf/2602.14070", "abs": "https://arxiv.org/abs/2602.14070", "authors": ["Saumyajit Das", "Ram Gopal Jaiswal"], "title": "Existence for the Discrete Nonlinear Fragmentation Equation with Degenerate Diffusion", "categories": ["math.AP"], "comment": "38 pages", "summary": "A mathematical model for the discrete nonlinear fragmentation (collision-induced breakage) equation with diffusion is studied. The existence of global weak solutions is established in arbitrary spatial dimensions without assuming a strictly positive lower bound on the diffusion coefficients, extending previous results that were restricted to one-dimensional domains and relied on uniformly positive diffusion. The analysis is carried out under boundedness assumptions on the collision and breakage kernels. The proof is based on the construction of a suitable regularized system, combined with weak $L^2$ a priori estimates and compactness arguments in $L^1$, which allow the passage to the limit in the nonlinear fragmentation operator.", "AI": {"tldr": "Global weak solutions exist for discrete nonlinear fragmentation equations with diffusion in arbitrary dimensions, even with non-positive diffusion coefficients.", "motivation": "Previous results on fragmentation equations with diffusion were limited to one-dimensional domains and required strictly positive diffusion coefficients. The authors aim to extend these results to arbitrary spatial dimensions without the strict positivity requirement on diffusion.", "method": "The proof constructs a regularized system and uses weak L\u00b2 a priori estimates combined with compactness arguments in L\u00b9. This approach allows handling the nonlinear fragmentation operator when passing to the limit.", "result": "Existence of global weak solutions is established for the discrete nonlinear fragmentation equation with diffusion in arbitrary spatial dimensions, without requiring strictly positive lower bounds on diffusion coefficients.", "conclusion": "The paper successfully extends previous one-dimensional results to arbitrary dimensions and relaxes the diffusion positivity requirement, providing a more general existence theory for fragmentation equations with diffusion."}}
{"id": "2602.14315", "pdf": "https://arxiv.org/pdf/2602.14315", "abs": "https://arxiv.org/abs/2602.14315", "authors": ["Siiri Rautio", "Alexander Meaney", "Salla-Maaria Latva-\u00c4ij\u00f6", "Harshit Agrawal", "Mikael Brix", "Dinidu Jayakody", "Samuli Siltanen"], "title": "Complex Wavelet-Based Sinogram Segmentation for Metal Artifact Reduction in Cone-Beam CT", "categories": ["physics.med-ph", "math.NA"], "comment": null, "summary": "Metal objects pose a significant challenge in cone-beam computed tomography, as their strong and energy-dependent X-ray attenuation leads to inconsistent projections and severe streaking and shading artifacts in reconstructed images. These artifacts degrade image quality and limit the reliability of subsequent medical analysis. We propose a projection-domain metal artifact reduction method based on analytical metal segmentation in the three-dimensional sinogram using the three-dimensional Dual-Tree Complex Wavelet Transform, where directional wavelet coefficients are exploited to extract the wavefront set and singular support of metal structures. The resulting segmentation enables projection-domain inpainting and artifact-reduced reconstruction by combining metal-free and metal-only reconstructions. The proposed approach is evaluated on both simulated and clinical cone-beam computed tomography data and consistently reduces metal artifacts compared to conventional image-domain hard-thresholding methods. The results demonstrate improved visual quality and robustness in clinically realistic scenarios, highlighting the potential of analytically grounded, non-learned projection-domain segmentation for metal artifact reduction.", "AI": {"tldr": "A projection-domain metal artifact reduction method for cone-beam CT using 3D Dual-Tree Complex Wavelet Transform for analytical metal segmentation, enabling improved reconstruction quality compared to conventional image-domain methods.", "motivation": "Metal objects in cone-beam CT cause severe streaking and shading artifacts due to strong, energy-dependent X-ray attenuation, degrading image quality and limiting reliability of medical analysis.", "method": "Uses 3D Dual-Tree Complex Wavelet Transform to perform analytical metal segmentation in the 3D sinogram, exploiting directional wavelet coefficients to extract wavefront set and singular support of metal structures. Enables projection-domain inpainting and combines metal-free and metal-only reconstructions.", "result": "Consistently reduces metal artifacts compared to conventional image-domain hard-thresholding methods on both simulated and clinical cone-beam CT data, demonstrating improved visual quality and robustness in clinically realistic scenarios.", "conclusion": "The approach highlights the potential of analytically grounded, non-learned projection-domain segmentation for effective metal artifact reduction in cone-beam CT."}}
{"id": "2602.14072", "pdf": "https://arxiv.org/pdf/2602.14072", "abs": "https://arxiv.org/abs/2602.14072", "authors": ["Meiqing Xu", "Hui Yang"], "title": "Liouville theorems for conformal $Q$-curvature equations", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we study the non-existence of positive solutions for the following conformal $Q$-curvature equation \\begin{equation*} (-\u0394)^\u03c3u = K(x) u^{\\frac{n+2\u03c3}{n-2\u03c3}} \\quad \\text{in } \\mathbb{R}^n, \\end{equation*} where $ \u03c3\\in (0, n/2)$ is a real number. When $\u03c3=1$, this equation reduces to the well-known scalar curvature equation arising from the prescribed scalar curvature problem. For general $\u03c3\\in (0, n/2)$, it appears in the study of prescribing $Q$-curvature. We establish Liouville theorems under various assumptions on the $Q$-curvature $K(x)$ by developing a unified approach applicable to all $\u03c3\\in (0, n/2)$. Our method successfully addresses the challenges posed by the absence of ODE tools in the fractional regime and the lack of a classification of Delaunay-type singular solutions for the general fractional Yamabe equation.", "AI": {"tldr": "The paper establishes Liouville theorems (non-existence of positive solutions) for the conformal Q-curvature equation with fractional Laplacian, developing a unified approach that works for all fractional orders \u03c3 \u2208 (0, n/2).", "motivation": "The conformal Q-curvature equation generalizes the scalar curvature equation (when \u03c3=1) to fractional orders, appearing in prescribing Q-curvature problems. There are challenges in the fractional regime: lack of ODE tools and absence of classification for Delaunay-type singular solutions.", "method": "Develops a unified approach applicable to all \u03c3 \u2208 (0, n/2) that overcomes the challenges of the fractional regime. The method addresses the absence of ODE tools and lack of classification for Delaunay-type singular solutions in the general fractional Yamabe equation.", "result": "Establishes Liouville theorems (non-existence of positive solutions) under various assumptions on the Q-curvature function K(x). The results apply to the entire range of fractional orders \u03c3 \u2208 (0, n/2).", "conclusion": "The paper successfully develops a unified method to prove non-existence results for the fractional conformal Q-curvature equation, overcoming significant technical challenges in the fractional analysis setting."}}
{"id": "2602.14450", "pdf": "https://arxiv.org/pdf/2602.14450", "abs": "https://arxiv.org/abs/2602.14450", "authors": ["Issaku Kanamori", "Hideo Matsufuru", "Tatsumi Aoyama", "Kazuyuki Kanaya", "Yusuke Namekawa", "Hidekatsu Nemura", "Keigo Nitadori"], "title": "Mixed precision solvers with half-precision floating point numbers for Lattice QCD on A64FX processor", "categories": ["hep-lat", "math.NA"], "comment": "11 pages, 9 figures, contribution to the International Workshop on Arm-based HPC: Practice and Experience 2026 (IWAHPCE2026) at HPC-Asia 2026", "summary": "We investigate the use of half-precision floating-point numbers (FP16) in mixed-precision linear solvers for lattice QCD simulations. Since the emergence of GPUs for general-purpose, mixed-precision algorithms that combine single-precision (FP32) with double-precision (FP64) arithmetics have become widely used in this field and others. While FP32-based methods are now well established, we examine the practicality of using FP16. In this work, we introduce rescaling steps in both the outer iterative refinement step and the inner BiCGStab solver to avoid numerical instability. In our experiments with a simple Wilson kernel, the solver shows improved stability, and the additional iteration count compared to the FP64 version remains within 20\\%, indicating that the FP16 version is practical for use. We believe that the proposed rescaling methods can also benefit other mixed precision preconditioners in avoiding underflows.", "AI": {"tldr": "FP16 mixed-precision linear solvers for lattice QCD with rescaling techniques show practical performance within 20% iteration overhead compared to FP64.", "motivation": "To explore the practicality of using half-precision floating-point numbers (FP16) in mixed-precision linear solvers for lattice QCD simulations, building on existing FP32-FP64 mixed-precision approaches that have become standard with GPU computing.", "method": "Introduce rescaling steps in both the outer iterative refinement step and the inner BiCGStab solver to prevent numerical instability when using FP16 precision. Test with a simple Wilson kernel.", "result": "The solver demonstrates improved stability with FP16, and the additional iteration count compared to the FP64 version remains within 20%, indicating practical feasibility for lattice QCD applications.", "conclusion": "FP16 mixed-precision linear solvers are practical for lattice QCD when using appropriate rescaling techniques, and the proposed rescaling methods can benefit other mixed-precision preconditioners by preventing underflows."}}
{"id": "2602.14144", "pdf": "https://arxiv.org/pdf/2602.14144", "abs": "https://arxiv.org/abs/2602.14144", "authors": ["Geng Lai"], "title": "Oblique wave interactions in 2D steady supersonic flows of Bethe-Zel'dovich-Thompson fluids", "categories": ["math.AP"], "comment": null, "summary": "This paper studies steady supersonic flow in a 2D semi-infinite divergent duct. We assume that the flow satisfies the slip boundary condition on the walls of the duct, and the state of the flow is given at the inlet of the divergent duct. When the fluid is a polytropic ideal gas, the problem can be reduced to some interactions of rarefaction simple waves, and the existence of a global classical solution inside the divergent duct can be established using the method of characteristics. In this paper we assume that the fluid is a nonconvex Bethe-Zel'dovich-Thompson (BZT) fluid. This type of fluid may significantly differ from polytropic ideal gases. For instance, physically admissible rarefaction shocks can occur. Depending on the oncoming flow state and the flare angles of the divergent duct, thirteen distinct types of oblique wave interactions may occur, including oblique composite waves consisting of shocks and centered simple waves. This paper systematically studies these oblique wave interactions and constructs global, piecewise smooth, supersonic solutions within the divergent duct using characteristic decomposition and hodograph transformation methods. We also obtain the detailed structures of these solutions in addition to their existence. The results and methods of this paper are also applicable to some 2D Riemann problems for gases with nonconvex equations of state.", "AI": {"tldr": "This paper studies supersonic flow in a 2D divergent duct for nonconvex BZT fluids, analyzing 13 types of oblique wave interactions and constructing global piecewise smooth solutions using characteristic decomposition and hodograph transformation methods.", "motivation": "The motivation is to extend the analysis of supersonic flow in divergent ducts from polytropic ideal gases to nonconvex Bethe-Zel'dovich-Thompson (BZT) fluids, which exhibit fundamentally different behaviors like physically admissible rarefaction shocks and more complex wave interactions.", "method": "The paper uses characteristic decomposition and hodograph transformation methods to systematically study 13 distinct types of oblique wave interactions, including oblique composite waves consisting of shocks and centered simple waves.", "result": "The authors construct global, piecewise smooth, supersonic solutions within the divergent duct and obtain detailed structures of these solutions in addition to proving their existence.", "conclusion": "The results and methods developed for BZT fluids in divergent ducts are also applicable to some 2D Riemann problems for gases with nonconvex equations of state, extending the analytical framework beyond polytropic ideal gases."}}
{"id": "2602.14479", "pdf": "https://arxiv.org/pdf/2602.14479", "abs": "https://arxiv.org/abs/2602.14479", "authors": ["Samaneh Sojudi", "Mahdieh Tahmasebi"], "title": "Conditional Expectation expression in mean-field SDEs and its applications", "categories": ["math.PR", "math.NA"], "comment": null, "summary": "This study developed a novel formulation of conditional expectations within the framework of a jump-diffusion mean-field stochastic differential equation. We introduce an integrated approach that combines unconditioned expectations with rigorously defined weighting factors, employing Malliavin calculus on Poisson space and directional derivatives to enhance estimation accuracy. \\noindent The proposed method is applied to the numerical pricing of American put options in a jump-diffusion mean-field setting, addressing the challenges proposed by early-exercise features. Comprehensive numerical experiments demonstrate substantial improvements in pricing accuracy compared with conventional techniques.", "AI": {"tldr": "Novel conditional expectation formulation for jump-diffusion mean-field SDEs using Malliavin calculus and weighting factors, applied to American put option pricing with improved accuracy.", "motivation": "To address the challenges of pricing American options in jump-diffusion mean-field settings, particularly dealing with early-exercise features and improving estimation accuracy for conditional expectations.", "method": "Developed a novel formulation combining unconditioned expectations with rigorously defined weighting factors, employing Malliavin calculus on Poisson space and directional derivatives.", "result": "Comprehensive numerical experiments demonstrate substantial improvements in pricing accuracy compared with conventional techniques for American put options.", "conclusion": "The proposed integrated approach successfully enhances estimation accuracy for conditional expectations in jump-diffusion mean-field SDEs and provides superior pricing performance for American options."}}
{"id": "2602.14202", "pdf": "https://arxiv.org/pdf/2602.14202", "abs": "https://arxiv.org/abs/2602.14202", "authors": ["Anh Xuan Do", "Debdip Ganguly", "Nguyen Lam", "Guozhen Lu"], "title": "Logarithmic Sobolev, Poincar\u00e9 and Beckner Inequalities on Hyperbolic Spaces and Riemannian Manifolds", "categories": ["math.AP", "math.DG", "math.PR"], "comment": null, "summary": "We investigate several functional and geometric inequalities on the hyperbolic space $\\mathbb{H}^N$, with a primary emphasis on logarithmic Sobolev inequalities, Poincar\u00e9 inequalities, and Beckner-type inequalities, all studied within the framework of the AB program. The main analytical tool employed throughout this paper is symmetrization. More precisely, our approach relies on an improved version of the P\u00f3lya-Szeg\u00f6 inequality on the hyperbolic space, obtained through a careful comparison of the gradient norms of rearranged functions in the hyperbolic and Euclidean settings. For Beckner-type inequalities, we adopt a semigroup approach based on sharp estimates for the heat semigroup, leading to refined interpolation inequalities between Poincar\u00e9 and logarithmic Sobolev inequalities. Finally, we extend our results beyond hyperbolic space to a class of Riemannian model manifolds $\\mathbb{M}^N$ satisfying the centered isoperimetric inequality. This shows that the inequalities and methods developed in this work are robust and rely mainly on geometric and isoperimetric properties, rather than on the specific structure of hyperbolic space itself.", "AI": {"tldr": "The paper investigates functional inequalities on hyperbolic space using symmetrization techniques, extending results to Riemannian model manifolds.", "motivation": "To establish and understand functional inequalities (logarithmic Sobolev, Poincar\u00e9, Beckner-type) on hyperbolic space and generalize them to broader geometric settings beyond specific hyperbolic structure.", "method": "Uses symmetrization techniques with improved P\u00f3lya-Szeg\u00f6 inequality on hyperbolic space, comparing gradient norms between hyperbolic and Euclidean settings. For Beckner-type inequalities, employs semigroup approach with sharp heat semigroup estimates.", "result": "Develops refined interpolation inequalities between Poincar\u00e9 and logarithmic Sobolev inequalities on hyperbolic space, and extends results to Riemannian model manifolds satisfying centered isoperimetric inequality.", "conclusion": "The inequalities and methods are robust, relying mainly on geometric and isoperimetric properties rather than specific hyperbolic structure, making them applicable to broader classes of Riemannian manifolds."}}
{"id": "2602.14607", "pdf": "https://arxiv.org/pdf/2602.14607", "abs": "https://arxiv.org/abs/2602.14607", "authors": ["Nathan Kirk"], "title": "A Bayesian Approach to Low-Discrepancy Subset Selection", "categories": ["stat.ME", "cs.LG", "math.NA", "stat.CO"], "comment": "13 pages, 3 figures, mODa14", "summary": "Low-discrepancy designs play a central role in quasi-Monte Carlo methods and are increasingly influential in other domains such as machine learning, robotics and computer graphics, to name a few. In recent years, one such low-discrepancy construction method called subset selection has received a lot of attention. Given a large population, one optimally selects a small low-discrepancy subset with respect to a discrepancy-based objective. Versions of this problem are known to be NP-hard. In this text, we establish, for the first time, that the subset selection problem with respect to kernel discrepancies is also NP-hard. Motivated by this intractability, we propose a Bayesian Optimization procedure for the subset selection problem utilizing the recent notion of deep embedding kernels. We demonstrate the performance of the BO algorithm to minimize discrepancy measures and note that the framework is broadly applicable any design criteria.", "AI": {"tldr": "NP-hardness of subset selection for kernel discrepancies established, with Bayesian Optimization proposed as solution using deep embedding kernels.", "motivation": "Subset selection for low-discrepancy designs is important in quasi-Monte Carlo methods, machine learning, robotics, and computer graphics, but known to be NP-hard for some versions. The paper aims to establish NP-hardness for kernel discrepancies specifically and provide practical solutions.", "method": "1) Prove NP-hardness of subset selection for kernel discrepancies. 2) Propose Bayesian Optimization procedure using deep embedding kernels to solve the subset selection problem. 3) Framework designed to be broadly applicable to any design criteria.", "result": "First establishment that subset selection with respect to kernel discrepancies is NP-hard. Bayesian Optimization with deep embedding kernels demonstrates performance in minimizing discrepancy measures.", "conclusion": "Subset selection for kernel discrepancies is computationally intractable (NP-hard), but Bayesian Optimization with deep embedding kernels provides an effective practical approach that can be applied to various design criteria beyond discrepancy minimization."}}
{"id": "2602.14227", "pdf": "https://arxiv.org/pdf/2602.14227", "abs": "https://arxiv.org/abs/2602.14227", "authors": ["Rafael D\u00edaz Fuentes", "Mar\u00eda Victoria Redondo Neble", "Giuseppe Viglialoro"], "title": "Nonlocal logistics and nonlinear productions in an attraction-repulsion chemotaxis model: analysis of the global well-posedness", "categories": ["math.AP"], "comment": null, "summary": "This paper investigates a {three-component} chemotaxis system involving both attraction and repulsion effects, as well as a nonlocal logistic-type source term. Mathematically, if $u=u(x,t)$, $v = v(x,t)$ and $w = w(x,t)$ denote the cell distribution, and the attractive and the repulsive chemical signals, the model is then described by\n  \\begin{equation*}\n  \\begin{cases}\n  u_t = \u0394u - \u03c7\\nabla \\cdot (u \\nabla v) + \u03be\\nabla \\cdot (u \\nabla w) + a u^\u03b1- b u^\u03b1\\int_\u03a9u^\u03b2, & x \\in \u03a9, \\ t > 0,\n  \u03c4v_t = \u0394v - v + f(u), & x \\in \u03a9, \\ t > 0,\n  \u03c4w_t = \u0394w - w + g(u), & x \\in \u03a9, \\ t > 0.\n  \\end{cases}\n  \\end{equation*}\n  Here, $\u03a9\\subset \\mathbb{R}^n$ ($n \\geq 1$) is a bounded smooth domain, $\u03c4\\in\\{0,1\\}$, $a,b,\u03b1,\u03b2,\u03c7,\u03be>0$, the production functions $f(u)$ and $g(u)$ are assumed to satisfy algebraic growth conditions of order $\\ell$ and $\u03c1$, generalizing prototypes of the form $u^\\ell$ and $u^\u03c1$, $\\ell,\u03c1>0$. The work is devoted to proving the global existence and boundedness of classical solutions under a suitable balance between the signal production exponents $\\ell, \u03c1$ and the nonlocal damping exponents $\u03b1, \u03b2$, for regular enough initial data and zero-flux boundary restrictions. In this regard, two main theorems are established for the cases where the chemical signals satisfy either elliptic ($\u03c4=0$) or parabolic ($\u03c4=1$) partial differential equations, highlighting how sufficiently strong nonlocal damping prevents the formation of singularities in time.\n  We extend the results obtained in [Chiyo et al., Appl. Math. Optim. 89:9 (2024)], where the fully parabolic ($\u03c4=1$) and only attraction version is studied. In our context, we establish well-posedness of the system and the long-time behavior of solutions.", "AI": {"tldr": "This paper studies a three-component chemotaxis system with both attractive and repulsive chemical signals and a nonlocal logistic source term, establishing global existence and boundedness of classical solutions under certain parameter conditions.", "motivation": "The motivation is to extend previous work on chemotaxis systems by incorporating both attraction and repulsion effects along with nonlocal logistic damping, addressing the mathematical challenge of preventing singularity formation in such complex biological models.", "method": "The authors analyze a PDE system with three components (cell density, attractive chemical, repulsive chemical) using analytical methods to establish global existence and boundedness of classical solutions. They consider both elliptic (\u03c4=0) and parabolic (\u03c4=1) cases for the chemical equations.", "result": "Two main theorems are established showing global existence and boundedness of classical solutions under suitable balance conditions between signal production exponents (\u2113, \u03c1) and nonlocal damping exponents (\u03b1, \u03b2), demonstrating that sufficiently strong nonlocal damping prevents singularity formation.", "conclusion": "The paper successfully extends previous results by showing that incorporating both attraction and repulsion with nonlocal logistic damping allows for global well-posedness and bounded solutions, with the nonlocal term playing a crucial role in preventing blow-up phenomena."}}
{"id": "2602.14663", "pdf": "https://arxiv.org/pdf/2602.14663", "abs": "https://arxiv.org/abs/2602.14663", "authors": ["Andrew Gracyk"], "title": "Pseudo-differential-enhanced physics-informed neural networks", "categories": ["cs.LG", "math.NA"], "comment": "First version", "summary": "We present pseudo-differential enhanced physics-informed neural networks (PINNs), an extension of gradient enhancement but in Fourier space. Gradient enhancement of PINNs dictates that the PDE residual is taken to a higher differential order than prescribed by the PDE, added to the objective as an augmented term in order to improve training and overall learning fidelity. We propose the same procedure after application via Fourier transforms, since differentiating in Fourier space is multiplication with the Fourier wavenumber under suitable decay. Our methods are fast and efficient. Our methods oftentimes achieve superior PINN versus numerical error in fewer training iterations, potentially pair well with few samples in collocation, and can on occasion break plateaus in low collocation settings. Moreover, our methods are suitable for fractional derivatives. We establish that our methods improve spectral eigenvalue decay of the neural tangent kernel (NTK), and so our methods contribute towards the learning of high frequencies in early training, mitigating the effects of frequency bias up to the polynomial order and possibly greater with smooth activations. Our methods accommodate advanced techniques in PINNs, such as Fourier feature embeddings. A pitfall of discrete Fourier transforms via the Fast Fourier Transform (FFT) is mesh subjugation, and so we demonstrate compatibility of our methods for greater mesh flexibility and invariance on alternative Euclidean and non-Euclidean domains via Monte Carlo methods and otherwise.", "AI": {"tldr": "Pseudo-differential enhanced PINNs use Fourier transforms to improve training by applying gradient enhancement in Fourier space, achieving better error rates, breaking training plateaus, and working with fractional derivatives.", "motivation": "To overcome limitations of gradient-enhanced PINNs by applying the enhancement in Fourier space, which allows for more efficient training, better handling of high frequencies, and compatibility with fractional derivatives and various domain types.", "method": "Extend gradient enhancement to Fourier space by applying Fourier transforms to the PDE residual, then multiplying by Fourier wavenumbers (equivalent to differentiation in Fourier space). Use Monte Carlo methods for mesh flexibility on Euclidean and non-Euclidean domains.", "result": "Methods achieve superior PINN vs numerical error in fewer iterations, break training plateaus in low collocation settings, improve spectral eigenvalue decay of NTK, enhance learning of high frequencies early in training, and work with fractional derivatives.", "conclusion": "Pseudo-differential enhancement in Fourier space provides an effective extension to gradient-enhanced PINNs that improves training efficiency, handles high frequencies better, and offers greater flexibility across various domains and derivative types."}}
{"id": "2602.14305", "pdf": "https://arxiv.org/pdf/2602.14305", "abs": "https://arxiv.org/abs/2602.14305", "authors": ["Aram Hakobyan", "Michael Poghosyan", "Henrik Shahgholian"], "title": "Partial regularity of the gradient for subsolutions", "categories": ["math.AP"], "comment": "11 pages", "summary": "We prove that the gradient of any bounded subharmonic function is upper semi-continuous, provided that its super-level sets can be touched from the exterior by uniform $C^{1,\\text{Dini}}$ domains at every point. This idea extends to a class of general operators, as well as to the boundary behaviour of the gradient of solutions of the Dirichlet problem in a domain whose boundary satisfy this geometric condition.", "AI": {"tldr": "Gradient of bounded subharmonic functions is upper semi-continuous under certain geometric conditions on super-level sets.", "motivation": "To establish regularity properties of gradients for subharmonic functions and solutions to Dirichlet problems under specific geometric conditions on domain boundaries.", "method": "Proves gradient upper semi-continuity using geometric analysis approach where super-level sets can be touched from exterior by uniform C^{1,Dini} domains at every point.", "result": "Gradient of any bounded subharmonic function is upper semi-continuous under the specified geometric condition; result extends to general operators and Dirichlet problem solutions.", "conclusion": "Geometric condition of exterior touchability by uniform C^{1,Dini} domains ensures gradient upper semi-continuity, providing regularity results for subharmonic functions and PDE solutions."}}
{"id": "2602.14683", "pdf": "https://arxiv.org/pdf/2602.14683", "abs": "https://arxiv.org/abs/2602.14683", "authors": ["Valentin Leplat"], "title": "Joint Majorization-Minimization for Nonnegative CP and Tucker Decompositions under $\u03b2$-Divergences: Unfolding-Free Updates", "categories": ["math.OC", "math.NA"], "comment": null, "summary": "We study majorization-minimization methods for nonnegative tensor decompositions under the $\u03b2$-divergence family, focusing on nonnegative CP and Tucker models. Our aim is to avoid explicit mode unfoldings and large auxiliary matrices by deriving separable surrogates whose multiplicative updates can be implemented using only tensor contractions (einsum-style operations). We present both classical block-MM updates in contraction-only form and a joint majorization strategy, inspired by joint MM for matrix $\u03b2$-NMF, that reuses cached reference quantities across inexpensive inner updates. We prove tightness of the proposed majorizers, establish monotonic decrease of the objective, and show convergence of the sequence of objective values; we also discuss how BSUM theory applies to the block-MM scheme for analyzing limit points. Finally, experiments on synthetic tensors and the Uber spatiotemporal count tensor demonstrate substantial speedups over unfolding-based baselines and a recent einsum-factorization framework.", "AI": {"tldr": "Proposes efficient majorization-minimization methods for nonnegative tensor decompositions using \u03b2-divergence, avoiding explicit unfoldings through tensor contractions and joint majorization strategies.", "motivation": "To develop more efficient algorithms for nonnegative tensor decompositions that avoid computational bottlenecks of explicit mode unfoldings and large auxiliary matrices, enabling faster processing of large-scale tensor data.", "method": "Derives separable surrogates with multiplicative updates using only tensor contractions (einsum-style operations). Presents both classical block-MM updates in contraction-only form and a joint majorization strategy that reuses cached reference quantities across inner updates.", "result": "Proves tightness of majorizers, establishes monotonic decrease of objective, shows convergence of objective values. Experiments demonstrate substantial speedups over unfolding-based baselines and recent einsum-factorization framework on synthetic tensors and Uber spatiotemporal count tensor.", "conclusion": "The proposed contraction-only MM methods provide efficient, theoretically sound algorithms for nonnegative tensor decompositions under \u03b2-divergence, offering significant computational advantages over traditional unfolding-based approaches."}}
{"id": "2602.14316", "pdf": "https://arxiv.org/pdf/2602.14316", "abs": "https://arxiv.org/abs/2602.14316", "authors": ["Xin Fu", "Yulin Gong", "Yunlei Wang"], "title": "Observability and Semiclassical Control for Schr\u00f6dinger Equations on Non-compact Hyperbolic Surfaces", "categories": ["math.AP", "math-ph", "math.SP"], "comment": "51 pages, 1 figure", "summary": "We study the observability of the Schr\u00f6dinger equation on $X$, a non-compact covering space of a compact hyperbolic surface $M$. Using a generalized Bloch theory, functions on $X$ are identified as sections of flat Hilbert bundles over $M$. We develop a semiclassical analysis framework for such bundles and generalize the result of semiclassical control estimates in [Dyatlov and Jin, Acta Math., 220 (2018), pp. 297-339] to all flat Hilbert bundles over $M$, with uniform constants with respect to the choice of bundle. Furthermore, when the Riemannian cover $X \\to M$ is a normal cover with a virtually Abelian deck transformation group $\u0393$, we combine the uniform semiclassical control estimates on flat Hilbert bundles with the generalized Bloch theory to derive observability from any $\u0393$-periodic open subsets of $X$. We also discuss applications of the uniform semiclassical control estimates in spectral geometry.", "AI": {"tldr": "Generalizes semiclassical control estimates to all flat Hilbert bundles over compact hyperbolic surfaces with uniform constants, enabling observability results for Schr\u00f6dinger equations on non-compact covering spaces.", "motivation": "To study observability of Schr\u00f6dinger equations on non-compact covering spaces of compact hyperbolic surfaces, extending existing semiclassical control theory to more general geometric settings.", "method": "Uses generalized Bloch theory to identify functions on covering spaces as sections of flat Hilbert bundles, develops semiclassical analysis framework for such bundles, and generalizes Dyatlov-Jin control estimates with uniform constants across all bundles.", "result": "Achieves uniform semiclassical control estimates for all flat Hilbert bundles over compact hyperbolic surfaces, and obtains observability from \u0393-periodic open subsets when the deck transformation group is virtually Abelian.", "conclusion": "The uniform semiclassical control estimates provide powerful tools for studying observability problems on covering spaces and have applications in spectral geometry."}}
{"id": "2602.14346", "pdf": "https://arxiv.org/pdf/2602.14346", "abs": "https://arxiv.org/abs/2602.14346", "authors": ["Huyuan Chen", "Jialei Jiang", "Jun Wang"], "title": "Existence and nonexistence of solutions for fractional elliptic equations arising from closed MEMS model", "categories": ["math.AP"], "comment": null, "summary": "The objective of our paper is to investigate fractional elliptic equations of the form $(-\u0394)^s u=\\frac{\u03bb}{(a-u)^2}$ within a bounded domain $\u03a9$, subject to zero Dirichlet boundary conditions. Here, $s\\in(0,1)$, $\u03bb>0$, and the function $a$ vanishes at the boundary while satisfying additional conditions. This problem originates from Micro-Electromechanical Systems (MEMS) devices, particularly when the elastic membrane makes contact with the ground plate at the boundary. We establish both existence and nonexistence results, illustrating how the boundary decay of the membrane influences the solutions and pull-in voltage.", "AI": {"tldr": "Study of fractional elliptic MEMS equations with singular nonlinearity, establishing existence/nonexistence results based on boundary decay.", "motivation": "The problem arises from Micro-Electromechanical Systems (MEMS) devices where an elastic membrane contacts the ground plate at the boundary, requiring analysis of fractional Laplacian equations with singular nonlinearities.", "method": "Analysis of fractional elliptic equations $(-\u0394)^s u=\\frac{\u03bb}{(a-u)^2}$ in bounded domain \u03a9 with zero Dirichlet boundary conditions, where s\u2208(0,1), \u03bb>0, and a vanishes at boundary with additional conditions.", "result": "Established both existence and nonexistence results, showing how boundary decay of the membrane influences solutions and pull-in voltage in MEMS devices.", "conclusion": "The boundary behavior of the membrane plays crucial role in determining solution existence and pull-in voltage characteristics for fractional MEMS equations with singular nonlinearity."}}
{"id": "2602.14412", "pdf": "https://arxiv.org/pdf/2602.14412", "abs": "https://arxiv.org/abs/2602.14412", "authors": ["Zhendong Fang", "Kunlun Qi", "Huanyao Wen"], "title": "The small Deborah number limit for the compressible fluid-particle flows", "categories": ["math.AP"], "comment": null, "summary": "In this paper, we consider the hydrodynamic limit for the fluid-particle flows governed by the Vlasov-Fokker-Planck equation coupled with the compressible Navier-Stokes equation as the Deborah number tends to zero. The limit is valid globally in time provided that the initial perturbation is small in a neighborhood of a steady state. The proof is based on a formal derivation via the Hilbert expansion around the limiting system, the rigorous justification of which is completed by the refined energy estimates involving the macro-micro decomposition. Compared with the existing results obtained by the relative entropy argument([A. Mellet and A. F. Vasseur, Comm. Math. Phys., 281 (2008), pp. 573--596]), the present work provides a stronger pointwise convergence of the hydrodynamic limits with an explicit rate for the fluid-particle coupled model.", "AI": {"tldr": "Hydrodynamic limit for fluid-particle flows as Deborah number \u2192 0, with global-in-time convergence for small perturbations near steady state.", "motivation": "To establish stronger convergence results (pointwise with explicit rate) for the hydrodynamic limit of fluid-particle flows governed by Vlasov-Fokker-Planck equation coupled with compressible Navier-Stokes equation, improving upon existing relative entropy methods.", "method": "Uses Hilbert expansion around the limiting system with rigorous justification via refined energy estimates involving macro-micro decomposition.", "result": "Proves global-in-time convergence valid for small initial perturbations near steady state, providing stronger pointwise convergence with explicit rate compared to previous relative entropy results.", "conclusion": "The work successfully establishes enhanced convergence properties for hydrodynamic limits in fluid-particle coupled systems, offering improved theoretical understanding beyond existing relative entropy approaches."}}
{"id": "2602.14522", "pdf": "https://arxiv.org/pdf/2602.14522", "abs": "https://arxiv.org/abs/2602.14522", "authors": ["Veronica Felli", "Prasun Roychowdhury", "Giovanni Siclari"], "title": "Magnetic Neumann problems with Aharonov-Bohm potentials: boundary asymptotics of eigenvalues and splitting phenomena", "categories": ["math.AP"], "comment": null, "summary": "We study a planar magnetic Schr\u00f6dinger operator with an Aharonov-Bohm vector potential, under Neumann boundary conditions. Through a gauge transformation, the corresponding eigenvalue problem can be formulated in terms of the Laplacian on a fractured domain, where the fracture lies along the segment connecting the pole to its projection on the boundary. As the pole approaches the boundary, we prove that the eigenvalues converge to those of the Neumann Laplacian and the variation exhibits a logarithmic vanishing rate. In the case of multiple eigenvalues, when the pole approaches a fixed point of the boundary, we observe a splitting phenomenon, with the largest branch separating from the others.", "AI": {"tldr": "Planar magnetic Schr\u00f6dinger operator with Aharonov-Bohm potential under Neumann BC: eigenvalues converge to Neumann Laplacian as pole approaches boundary with logarithmic rate; multiple eigenvalues split when pole approaches fixed boundary point.", "motivation": "To understand the spectral behavior of magnetic Schr\u00f6dinger operators with Aharonov-Bohm vector potentials as the magnetic pole approaches the domain boundary, particularly under Neumann boundary conditions.", "method": "Use gauge transformation to reformulate eigenvalue problem as Laplacian on fractured domain; analyze asymptotic behavior as pole approaches boundary; study convergence rates and splitting phenomena for multiple eigenvalues.", "result": "Eigenvalues converge to those of Neumann Laplacian with logarithmic vanishing rate; for multiple eigenvalues, splitting occurs when pole approaches fixed boundary point with largest branch separating from others.", "conclusion": "The magnetic field's proximity to boundary significantly affects spectral properties: convergence to Neumann spectrum with logarithmic rate, and splitting phenomena for degenerate eigenvalues reveal subtle boundary effects in magnetic Schr\u00f6dinger operators."}}
{"id": "2602.14545", "pdf": "https://arxiv.org/pdf/2602.14545", "abs": "https://arxiv.org/abs/2602.14545", "authors": ["Ardra A"], "title": "On the first eigenvalue of a nonlinear Schr\u00f6dinger type equation", "categories": ["math.AP"], "comment": null, "summary": "We consider an eigenvalue problem for the generalized nonlinear Schr\u00f6dinger type operator with the Robin boundary condition as given below. \\begin{equation*} \\label{ab-Robin p-Laplace evp with potential term_intro} \\left\\{ \\begin{split} -\u0394_p u+V(x)|u|^{p-2}u&=\u03bb|u|^{p-2}u\\quad &&\\mathrm{in} ~\u03a9,\\\\ |\\nabla u|^{p-2}\\frac{\\partial u}{\\partial\u03b7}+\u03b2|u|^{p-2}u&=0\\quad &&\\mathrm{on}~\\partial\u03a9, \\end{split} \\right. \\end{equation*} where $\u0394_p u := \\operatorname{div}(|\\nabla u|^{p-2}\\nabla u)$ is the $p$-Laplace operator, $\u03a9$ is a bounded domain in $\\mathbb{R}^n$ with smooth boundary, $V \\in C^1(\\mathbb{R}^n),$ $ \u03b7$ denotes the outward unit normal, and $ \u03b2$ is a positive real constant. We study the properties of its first eigenvalue with respect to the potential $V$, the boundary parameter $\u03b2$ as well as the domain. First, we establish some properties of the smallest eigenvalue $\u03bb_1(V)$ with respect to the potential. We then prove the differentiability of $\u03bb_1(V)$ with respect to the Robin boundary parameter $\u03b2$ and give an explicit formula for this derivative, which is then used to investigate some monotonicity properties of $\u03bb_1(V).$ We also obtain a shape derivative formula for the smallest eigenvalue. Using these derivatives, we also study domain monotonicity properties of the first eigenvalue.", "AI": {"tldr": "The paper studies eigenvalue properties of a generalized nonlinear Schr\u00f6dinger operator with p-Laplacian and Robin boundary conditions, focusing on the first eigenvalue's dependence on potential V, boundary parameter \u03b2, and domain shape.", "motivation": "To understand how the first eigenvalue of this nonlinear eigenvalue problem depends on various parameters (potential V, boundary parameter \u03b2, and domain \u03a9), which has applications in nonlinear PDEs and spectral theory.", "method": "Mathematical analysis of the eigenvalue problem using variational methods, establishing properties of the smallest eigenvalue \u03bb\u2081(V), proving differentiability with respect to \u03b2, deriving explicit formulas for derivatives, and investigating monotonicity properties.", "result": "Established properties of \u03bb\u2081(V) with respect to potential V, proved differentiability with respect to \u03b2 with explicit derivative formula, obtained shape derivative formula for smallest eigenvalue, and studied domain monotonicity properties.", "conclusion": "The paper provides comprehensive analysis of parameter dependence for the first eigenvalue of this nonlinear eigenvalue problem, with explicit derivative formulas enabling investigation of monotonicity properties with respect to potential, boundary parameter, and domain shape."}}
{"id": "2602.14581", "pdf": "https://arxiv.org/pdf/2602.14581", "abs": "https://arxiv.org/abs/2602.14581", "authors": ["Arpan Mukherjee", "S\u00e9rgio S. Rodrigues", "Mourad Sini"], "title": "Feedback Stabilization and Tracking for Heat Equations Using Thermo-Plasmonic Nanoparticles as Actuators", "categories": ["math.AP"], "comment": null, "summary": "We propose a feedback strategy to track prescribed heat profiles using plasmonic nanoparticles as actuators. Starting from a thermo--plasmonic Maxwell--heat model, we use a time-domain discrete effective description in which the generated heat is approximated by a superposition of heat kernels centered at particle locations with amplitudes governed by a coupled Volterra system. We recast this dynamics as a heat equation on a bounded domain with finitely many point actuators and design a tracking feedback based on pointwise evaluations of $\\mathcal A^{-1}y$, where $\\mathcal A=I-A_0$ and $A_0$ is the Neumann diffusion operator. Working in the natural $V'$ setting with $V=D(\\mathcal A)$, we prove exponential stabilization of the tracking error via distribution-actuator theory. For non-equilibrium reference profiles, we add a constant feedforward term and a low-mode fixed-point pre-compensation on $X_N$, ensuring exact steady matching on $X_N$ and an explicit bound on the residual tail mismatch.", "AI": {"tldr": "A feedback control strategy using plasmonic nanoparticles to track prescribed heat profiles, with theoretical guarantees for exponential stabilization of tracking errors.", "motivation": "To develop precise control of heat distribution using plasmonic nanoparticles as actuators, enabling tracking of prescribed thermal profiles for applications in nanoscale thermal management and photothermal therapy.", "method": "Uses a thermo-plasmonic Maxwell-heat model reduced to a time-domain discrete effective description with heat approximated by superposition of heat kernels at particle locations. Designs tracking feedback based on pointwise evaluations of operator $\\mathcal{A}^{-1}y$, with distribution-actuator theory in $V'$ setting. For non-equilibrium profiles, adds constant feedforward and low-mode fixed-point pre-compensation on subspace $X_N$.", "result": "Proves exponential stabilization of tracking error via distribution-actuator theory. For non-equilibrium reference profiles, achieves exact steady matching on subspace $X_N$ with explicit bound on residual tail mismatch.", "conclusion": "The proposed feedback strategy successfully enables precise tracking of prescribed heat profiles using plasmonic nanoparticles, with theoretical guarantees for stabilization and compensation mechanisms for non-equilibrium profiles."}}
{"id": "2602.14638", "pdf": "https://arxiv.org/pdf/2602.14638", "abs": "https://arxiv.org/abs/2602.14638", "authors": ["Duv\u00e1n Cardona", "Rafik Yeghoyan", "Michael Ruzhansky"], "title": "Kernel estimates and weak (1,1)-boundedness of pseudo-differential operators on compact Lie groups", "categories": ["math.AP"], "comment": "31 Pages", "summary": "Given a compact Lie group $G$ and its unitary dual $\\widehat{G}$, we establish the weak (1,1) continuity for pseudo-differential operators in the global H\u00f6rmander classes of order $-n(1-\u03c1)/2$ on $G\\times \\widehat{G}$. Our approach consists of proving suitable estimates for the kernel of such operators. Furthermore, we use these kernel estimates to give an alternative proof for the $H^1(G)$-$L^1(G)$-continuity of these classes now allowing the full range $0\\leq\u03b4\\leq\u03c1\\leq1, \\;\u03c1\\neq0,\\;\u03b4\\neq1$. The conditions for the operators are formulated using the H\u00f6rmander classes $S^m_{\u03c1,\u03b4}(G):=S^m_{\u03c1,\u03b4}(G\\times \\widehat{G})$ of symbols in the non-commutative phase space $G\\times \\widehat{G}$, which are extensions of the well-known $(\u03c1,\u03b4)$-classes in the Euclidean space. Our results are formulated in the complete range $0\\leq \u03b4\\leq \u03c1\\leq 1,$ $\u03c1\\neq0,\\;$$\u03b4\\neq 1$.\n  As an application of this boundedness result we provide end-point a-priori $L^1$-estimates for the sub-Laplacian $\\mathcal{L}_{sub}=X^2+Y^2,$ and for the heat type operator $T=Z-X^2-Y^2$ on $SU(2)\\cong \\mathbb{S}^3$ that cannot be obtained by application of the standard pseudo-differential calculus due to H\u00f6rmander. More precisely, we prove that if one considers the subelliptic problem,\n  \\begin{equation}\\label{IVP:abstract} \\begin{cases}Tu=f ,& \\text{ } \\\\u,f\\in \\mathscr{D}'(SU(2)):=(C^\\infty(SU(2)))', & \\text{ } \\end{cases} \\end{equation} then, for $f\\in W^{1,-\\frac{1}{4}}(SU(2)),$ one has that $u\\in L^{1,\\infty}(SU(2)).$", "AI": {"tldr": "The paper establishes weak (1,1) continuity for pseudo-differential operators on compact Lie groups, provides kernel estimates, and applies these to obtain endpoint L\u00b9-estimates for subelliptic operators on SU(2).", "motivation": "To extend weak (1,1) boundedness results for pseudo-differential operators from Euclidean spaces to compact Lie groups, particularly for the full parameter range 0\u2264\u03b4\u2264\u03c1\u22641, and to obtain endpoint estimates for subelliptic operators that cannot be handled by standard calculus.", "method": "Uses global H\u00f6rmander classes S^m_{\u03c1,\u03b4}(G) on the non-commutative phase space G\u00d7\u011c, proves kernel estimates for pseudo-differential operators, and applies these to establish weak (1,1) continuity and H\u00b9-L\u00b9 continuity.", "result": "Proves weak (1,1) continuity for operators of order -n(1-\u03c1)/2, provides kernel estimates, establishes H\u00b9(G)-L\u00b9(G) continuity for full parameter range, and obtains endpoint L\u00b9-estimates for sub-Laplacian and heat-type operators on SU(2).", "conclusion": "The paper successfully extends weak type boundedness results to compact Lie groups, provides a framework for analyzing subelliptic problems on SU(2), and demonstrates applications to operators that fall outside standard pseudo-differential calculus."}}
{"id": "2602.14658", "pdf": "https://arxiv.org/pdf/2602.14658", "abs": "https://arxiv.org/abs/2602.14658", "authors": ["Luca Esposito", "Lorenzo Lamberti"], "title": "Morrey estimates for the gradient in non-linear variational transmission problems", "categories": ["math.AP", "math.OC"], "comment": null, "summary": "We study a class of variational transmission problems driven by nonlinear energies with discontinuous coefficients across a prescribed interface. The model setting consists of integral functionals of the form \\[ \\mathcal{F}(u;E)=\\int_\u03a9\u03c3_E(x)\\,F(\\nabla u)\\,dx, \\] where the coefficient $\u03c3_E$ takes two constant values on complementary regions separated by a $C^1$ hypersurface, and the integrand $F$ satisfies standard $p$-growth and monotonicity conditions with $p>2$.\n  In this nonlinear variational framework, we establish local Morrey-space regularity for the gradient of local minimizers, proving that $\\nabla u\\in L^{2,\u03bb}_{\\mathrm{loc}}(\u03a9)$ for every $0\\leq\u03bb<n$, provided $2<p<\\frac{2n}{n-2}$. The proof is based on quantitative decay estimates for the energy near the interface, first obtained in a flat configuration and then extended to the general case by a suitable approximation argument.", "AI": {"tldr": "The paper studies variational transmission problems with discontinuous coefficients across interfaces, establishing local Morrey-space regularity for gradients of minimizers under specific growth conditions.", "motivation": "To understand regularity properties of solutions to nonlinear variational problems with discontinuous coefficients across interfaces, which arise in various physical and engineering applications involving composite materials or multi-phase systems.", "method": "The authors study integral functionals with discontinuous coefficients \u03c3_E taking two constant values across a C^1 hypersurface. They use quantitative decay estimates for energy near the interface, first analyzing a flat configuration and then extending to general cases via approximation arguments.", "result": "Prove local Morrey-space regularity for gradients of local minimizers: \u2207u \u2208 L^{2,\u03bb}_{loc}(\u03a9) for every 0 \u2264 \u03bb < n, provided 2 < p < 2n/(n-2).", "conclusion": "The nonlinear variational framework with discontinuous coefficients yields improved regularity results for gradient minimizers in Morrey spaces, extending previous regularity theory to transmission problems with interface discontinuities."}}
{"id": "2602.14685", "pdf": "https://arxiv.org/pdf/2602.14685", "abs": "https://arxiv.org/abs/2602.14685", "authors": ["Ruicheng Cheng", "Seung-Yeal Ha", "Jaemoon Lee", "Zhenfu Wang"], "title": "On the kinetic equation arising from the large-scale limit of the Cucker-Smale model", "categories": ["math.AP"], "comment": "32 pages, 3 figures", "summary": "We propose a large-scale scaling viewpoint for deriving mesoscopic dynamics from interacting particle systems and apply it to the Cucker--Smale flocking model. In contrast with the classical mean-field regime leading to the Vlasov-type Cucker--Smale equation with spatially nonlocal (convolution) alignment force, our scaling yields a kinetic equation whose alignment field becomes local in space and nonlocal only in velocity. For the spatially homogeneous case, we obtain an explicit solution and derive quantitative flocking rates. For the spatially inhomogeneous equation we establish a local well-posedness in $W^{1,\\infty}$ and in $C_b^{1,\u03b1}$, highlighting the additional difficulties caused by the absence of a convolution structure. Moreover, for sufficiently small interaction strength we present a global well-posedness and a forward-in-time $L^1$ asymptotic completeness property. Finally, we investigate mono-kinetic solutions and exhibit finite-time blow-up scenarios.", "AI": {"tldr": "The paper proposes a new scaling approach for deriving mesoscopic dynamics from interacting particle systems, applied to the Cucker-Smale flocking model, yielding a kinetic equation with local spatial alignment and nonlocal velocity interactions.", "motivation": "To develop an alternative scaling viewpoint to the classical mean-field regime for interacting particle systems, specifically addressing limitations of the Vlasov-type Cucker-Smale equation with nonlocal spatial convolution alignment forces.", "method": "A large-scale scaling approach is applied to the Cucker-Smale flocking model, deriving a kinetic equation where the alignment field becomes local in space but remains nonlocal in velocity. Mathematical analysis includes explicit solutions for homogeneous cases, well-posedness proofs, and investigation of mono-kinetic solutions.", "result": "For spatially homogeneous cases: explicit solutions and quantitative flocking rates. For inhomogeneous cases: local well-posedness in W^{1,\u221e} and C_b^{1,\u03b1} spaces, global well-posedness for small interaction strength, forward-in-time L^1 asymptotic completeness, and identification of finite-time blow-up scenarios for mono-kinetic solutions.", "conclusion": "The proposed scaling provides a viable alternative to classical mean-field approaches, yielding mathematically tractable kinetic equations with local spatial alignment, though introducing new analytical challenges due to the absence of convolution structure."}}
{"id": "2602.14712", "pdf": "https://arxiv.org/pdf/2602.14712", "abs": "https://arxiv.org/abs/2602.14712", "authors": ["Yannis Angelopoulos", "Istvan Kadar"], "title": "Matching conditions for scattering solutions of scalar wave equations on extremal Reissner-Nordstr\u00f6m spacetimes", "categories": ["math.AP", "gr-qc"], "comment": "46 pages, all comments are welcome", "summary": "We study scattering solutions $\u03c6$ of the linear wave equation on extremal Reissner-Nordstr\u00f6m spacetimes, satisfying the following properties: i) $\u03c6$ attains a prescribed radiation field $\u03c8_{\\mathcal{I}}$ through future null infinity, which decays at an inverse polynomial rate; ii) $\u03c6$ is regular in the exterior region up to and including the future event horizon, i.e. $\u03c6\\in C^N$, where $N\\gg1$ is independent of the decay rate of $\u03c8_{\\mathcal{I}}$. We prove that such solutions exist for arbitrary $N$, and that they are not unique. The proof consists of: 1) finding an approximate solution $\u03c6_{\\mathrm{app}}$ with fast decaying error; 2) the use of backwards energy estimates in order to correct $\u03c6_{\\mathrm{app}}$ to an exact solution. Extremality is used only in the second step. The methods of the linear case described above are then used to show the same results for semilinear equations where the nonlinearity satisfies the null condition, as well as to geometries describing the hyperbolic orbit of multiple extremal Reissner-Nordstr\u00f6m black holes.", "AI": {"tldr": "The paper studies scattering solutions of linear and semilinear wave equations on extremal Reissner-Nordstr\u00f6m spacetimes, showing existence of regular solutions with prescribed radiation fields and establishing non-uniqueness.", "motivation": "To understand the behavior of wave equations on extremal black hole spacetimes, particularly how solutions with prescribed radiation fields at future null infinity behave near the event horizon, and whether such regular solutions exist and are unique.", "method": "Two-step approach: 1) Construct approximate solution with fast decaying error, 2) Use backwards energy estimates to correct approximate solution to exact solution. Methods extended to semilinear equations satisfying null condition and to multiple extremal black hole geometries.", "result": "Proved existence of regular scattering solutions for arbitrary regularity order N, and established non-uniqueness of such solutions. Results hold for both linear wave equations and semilinear equations satisfying null condition, as well as for multiple extremal black hole geometries.", "conclusion": "Regular scattering solutions with prescribed radiation fields exist on extremal Reissner-Nordstr\u00f6m spacetimes but are not unique. The methods work for both linear and semilinear equations and extend to multiple black hole configurations, with extremality playing a crucial role in the correction step."}}
{"id": "2602.14800", "pdf": "https://arxiv.org/pdf/2602.14800", "abs": "https://arxiv.org/abs/2602.14800", "authors": ["Igor I. Skrypnik"], "title": "On the H\u00f6lder continuity of signed solutions to doubly nonlinear parabolic equations in the mixed degenerate/singular cases", "categories": ["math.AP"], "comment": null, "summary": "We prove the H\u00f6lder continuity of sign-changing solutions to the equation of the type $$\\frac{\\partial}{\\partial t}\\big(|u|^{q-1} u\\big)- div\\Big(|D u|^{p-2}\\,D u\\Big)=0,$$ where numbers $p$, $q$ satisfy the conditions $$0<q<p-1\\quad \\text{and}\\quad p<2,$$ or $$q>p-1\\quad\\text{and}\\quad p>2.$$ Our proof uses new versions of the integral Harnack type inequalities for sign-changing solutions.", "AI": {"tldr": "The paper proves H\u00f6lder continuity of sign-changing solutions to a doubly nonlinear parabolic equation with specific parameter ranges for p and q.", "motivation": "The motivation is to establish regularity properties (specifically H\u00f6lder continuity) for sign-changing solutions to doubly nonlinear parabolic equations, which are important in various applications like filtration theory and non-Newtonian fluids.", "method": "The method uses new versions of integral Harnack type inequalities specifically adapted for sign-changing solutions to handle the doubly nonlinear structure and sign changes.", "result": "The main result proves that sign-changing solutions to the given doubly nonlinear parabolic equation are H\u00f6lder continuous under two specific parameter regimes: (1) 0<q<p-1 and p<2, or (2) q>p-1 and p>2.", "conclusion": "The paper successfully establishes H\u00f6lder regularity for sign-changing solutions to doubly nonlinear parabolic equations using novel Harnack inequalities, extending previous results that typically focused on nonnegative solutions."}}
{"id": "2602.14848", "pdf": "https://arxiv.org/pdf/2602.14848", "abs": "https://arxiv.org/abs/2602.14848", "authors": ["Torben J. Fricke", "Raphael Kuess", "Felix Meyer"], "title": "Existence of large-data solutions to a thermo-piezoelectric system and forward operator analysis for associated inverse problems", "categories": ["math.AP"], "comment": null, "summary": "We consider an inverse problem governed by the initial-boundary value problem for the thermoviscoelastic Kelvin-Voigt system \\begin{align*}\\left\\{ \\begin{array}{l} \u03c1(z,t) u_{tt}- \\left(\u0393(\u0398) u_{zt} +p(z,t) u_z + \u03b2\u0398_z\\right)_z=0\\\\ b(z,t) \u0398_t-\\left(k(z,t)\u0398_z\\right)_z - \u0393(\u0398) u_{zt}^2+\u03b2\u0398u_{zt}=0, \\end{array} \\right.\n  \\end{align*} in an open bounded interval $\u03a9\\subset\\mathbb{R}$, for the evolution of the displacement variable $u$, and the temperature $\u0398\\geq 0$. Assuming the material coefficients $\u03c1$, $\u0393$, $p$, $b$ and $k$ are strictly positive and bounded and $\u03b2\\in\\mathbb{R}$ a global-in-time existence result is established for weak solutions. The present manuscript demonstrates that this can be achieved under energy- and entropy-minimal assumptions, in the sense that global weak solutions are shown to exist for any initial data $$u_0\\in W^{1,2}(\u03a9),\\quad u_{0t}\\in L^2(\u03a9)\\quad\\text{and}\\quad 0\\le\u0398_0\\in L^2(\u03a9).$$ The qualitative analysis of the evolution problem then allows to model and analyze the structural properties of the corresponding forward operator that naturally arises in inverse parameter identification settings. Therein, two modeling approaches of the observation operator as approximations of the electrical surface charge are presented and results on their well-definedness and boundedness are established. With the results on well-definedness and boundedness of the model operator, established in this paper as well, results on well-definedness, boundedness and continuous Fr\u00e9chet differentiability of the forward operator are presented.", "AI": {"tldr": "Global existence of weak solutions for thermoviscoelastic Kelvin-Voigt system under minimal energy/entropy assumptions, enabling analysis of forward operator for inverse parameter identification problems.", "motivation": "To establish global-in-time existence of weak solutions for thermoviscoelastic systems under minimal assumptions, which is crucial for analyzing inverse parameter identification problems where the forward operator's properties need to be understood.", "method": "Analysis of thermoviscoelastic Kelvin-Voigt PDE system with energy- and entropy-minimal assumptions, establishing global weak solutions for initial data in Sobolev/L\u00b2 spaces, then modeling observation operators as approximations of electrical surface charge.", "result": "Proved global existence of weak solutions for any initial data u\u2080\u2208W\u00b9,\u00b2(\u03a9), u\u2080\u209c\u2208L\u00b2(\u03a9), \u0398\u2080\u2208L\u00b2(\u03a9) with \u0398\u2080\u22650. Established well-definedness and boundedness of model operator and forward operator, including continuous Fr\u00e9chet differentiability.", "conclusion": "The minimal assumptions framework enables rigorous analysis of forward operators for inverse problems in thermoviscoelasticity, providing mathematical foundation for parameter identification from boundary measurements."}}
{"id": "2602.14946", "pdf": "https://arxiv.org/pdf/2602.14946", "abs": "https://arxiv.org/abs/2602.14946", "authors": ["Siyuan Lu", "Marcin Sroka"], "title": "On Liouville's theorem for the Hessian quotient equation $\u03c3_2/\u03c3_1$", "categories": ["math.AP"], "comment": null, "summary": "We prove Liouville's theorem for semi-convex entire solutions to Hessian quotient equation $\u03c3_2/\u03c3_1=1$ in $\\mathbb{R}^n$. The proof is based on the observation that after rewriting the quotient operator as the $\u03c3_2$ operator, acting on a new function, one can refer to the recent result of Shankar and Yuan on Liouville's theorem for $\u03c3_2$ equation.", "AI": {"tldr": "Liouville theorem proved for semi-convex entire solutions to Hessian quotient equation \u03c3\u2082/\u03c3\u2081=1 in \u211d\u207f using transformation to \u03c3\u2082 operator.", "motivation": "To establish Liouville-type results for Hessian quotient equations, extending existing theory from \u03c3\u2082 equations to more general quotient equations.", "method": "Rewrite the quotient operator \u03c3\u2082/\u03c3\u2081=1 as \u03c3\u2082 operator acting on a transformed function, then apply Shankar and Yuan's recent Liouville theorem for \u03c3\u2082 equations.", "result": "Successfully proved Liouville's theorem for semi-convex entire solutions to Hessian quotient equation \u03c3\u2082/\u03c3\u2081=1 in \u211d\u207f.", "conclusion": "The transformation technique allows extension of existing \u03c3\u2082 results to Hessian quotient equations, providing new Liouville theorems for this class of equations."}}
{"id": "2602.14954", "pdf": "https://arxiv.org/pdf/2602.14954", "abs": "https://arxiv.org/abs/2602.14954", "authors": ["Kyunghoo Mun", "Matthew Rosenzweig"], "title": "Phase transitions and linear stability for the mean-field Kuramoto-Daido model", "categories": ["math.AP", "math-ph"], "comment": "41 pages, 1 figure", "summary": "We consider the mean-field noisy Kuramoto-Daido model, which is a McKean-Vlasov equation on the circle with bimodal interaction $W(\u03b8)=\\cos\u03b8+m\\cos2\u03b8$ for $m\\ge 0$ and interaction strength $K$, generalizing the celebrated noisy Kuramoto model corresponding to $m=0$.\n  Our first contribution is to characterize the phase transition threshold $K_{c}$ by comparing it to the linear stability threshold $K_\\# = \\min (1, m^{-1})$ of the uniform distribution. When $m \\leq 1/2,$ $K_{c}=1$, coinciding with that of the Kuramoto model. On the other hand, for $m \\geq 2$, we show $K_c= m^{-1}$. We also classify the regimes in which the phase transition is continuous or discontinuous.\n  Our second contribution is to analyze the linear stability of a global minimizer $q$ (the ``ordered phase'') of the mean-field free energy in the supercritical regime $K>1$. This stationary solution of the Kuramoto-Daido equation is unique up to translation invariance and distinct from the uniform distribution (the ``disordered phase''). Our approach extends the Dirichlet form method of Bertini et al. from the unimodal to bimodal setting. In particular, for $m \\leq 1.590 \\times 10^{-4}$ and $K>1$, we show an explicit lower bound on the spectral gap of the linearized McKean-Vlasov operator at $q$. To our knowledge, this is the first rigorous stability analysis for this class of models with bimodal interactions.", "AI": {"tldr": "The paper analyzes the mean-field noisy Kuramoto-Daido model with bimodal interactions, characterizing phase transition thresholds and analyzing linear stability of ordered phases.", "motivation": "To extend understanding of synchronization phenomena beyond the classical Kuramoto model by studying bimodal interactions, which generalize the celebrated noisy Kuramoto model and allow for richer phase transition behaviors.", "method": "Theoretical analysis of McKean-Vlasov equation on the circle with bimodal interaction potential W(\u03b8)=cos\u03b8+mcos2\u03b8. Uses phase transition characterization through comparison with linear stability threshold, and extends Dirichlet form method from unimodal to bimodal setting for stability analysis.", "result": "Characterized phase transition threshold K_c: K_c=1 for m\u22641/2, K_c=m^{-1} for m\u22652. Classified continuous vs discontinuous phase transitions. For m\u22641.590\u00d710^{-4} and K>1, provided explicit lower bound on spectral gap of linearized operator at ordered phase q.", "conclusion": "The paper provides rigorous analysis of phase transitions and stability in bimodal Kuramoto-Daido models, extending previous unimodal results and offering first rigorous stability analysis for this class of models with bimodal interactions."}}
{"id": "2602.14996", "pdf": "https://arxiv.org/pdf/2602.14996", "abs": "https://arxiv.org/abs/2602.14996", "authors": ["Justin Forlano", "Younes Zine"], "title": "Invariant Gibbs dynamics for the hyperbolic sinh-Gordon model", "categories": ["math.AP", "math-ph", "math.PR"], "comment": null, "summary": "We study the hyperbolic defocusing sinh-Gordon model with parameter $\u03b2^2>0$ and its associated Gibbs dynamics on the two-dimensional torus. We establish global well-posedness of the model for a certain range of parameters $\u03b2^2>0$ with the corresponding Gibbs measure initial data and prove invariance of the Gibbs measure under the flow, thereby resolving a question posed by Oh, Robert, and Wang (2019). Our physical space approach hinges on developing a novel $L^\\infty$-based well-posedness theory for wave equations with exponential-type nonlinearities, going beyond the classical $L^2$-based framework. This refinement allows us to fully leverage structural properties of Gaussian multiplicative chaos. As a by-product of our method, we also obtain an improved well-posedness theory for the hyperbolic Liouville model.", "AI": {"tldr": "Global well-posedness and Gibbs measure invariance for hyperbolic defocusing sinh-Gordon model on 2D torus, with novel L\u221e-based approach for exponential nonlinearities.", "motivation": "Resolve question posed by Oh, Robert, and Wang (2019) about global well-posedness and Gibbs measure invariance for hyperbolic defocusing sinh-Gordon model with parameter \u03b2\u00b2>0 on 2D torus.", "method": "Develop novel L\u221e-based well-posedness theory for wave equations with exponential-type nonlinearities (beyond classical L\u00b2 framework), leveraging structural properties of Gaussian multiplicative chaos.", "result": "Establish global well-posedness for certain parameter range \u03b2\u00b2>0 with Gibbs measure initial data, prove invariance of Gibbs measure under flow, and obtain improved well-posedness theory for hyperbolic Liouville model as by-product.", "conclusion": "Physical space approach with L\u221e-based theory successfully resolves the open problem, providing complete framework for studying hyperbolic defocusing sinh-Gordon model with Gibbs measure data."}}
{"id": "2602.13968", "pdf": "https://arxiv.org/pdf/2602.13968", "abs": "https://arxiv.org/abs/2602.13968", "authors": ["Ngoc Cuong Nguyen"], "title": "Fine properties of functions in complex Sobolev spaces", "categories": ["math.CV", "math.AP"], "comment": "57 pages", "summary": "We study comprehensively local properties of functions in complex Sobolev spaces on a bounded open subset of $\\mathbb{C}^n$. The main tool is the corresponding functional capacity for the space which is inspired by the global one due to Vigny (2007). An inequality between this capacity and the Bedford-Taylor capacity for plurisubharmonic functions is proved, which is sharp as far as the exponents are concerned. Moreover, it is shown that the functional capacity is a Choquet capacity. The Alexander-Taylor type inequality for the capacity is also proved. This allows us to strengthen the results in the works of Dinh, Marinescu and Vu (2023), Vigny and Vu (2024). Lastly, the Moser-Trudinger type inequality in this space is characterized by the volume-capacity inequality.", "AI": {"tldr": "The paper studies local properties of functions in complex Sobolev spaces using functional capacity, establishes sharp inequalities with Bedford-Taylor capacity, proves it's a Choquet capacity, and strengthens previous results.", "motivation": "To comprehensively study local properties of functions in complex Sobolev spaces on bounded open subsets of C^n, building on previous work by Vigny (2007) and others.", "method": "Uses functional capacity inspired by Vigny's global capacity, proves inequalities between this capacity and Bedford-Taylor capacity for plurisubharmonic functions, shows it's a Choquet capacity, and establishes Alexander-Taylor type inequality.", "result": "Proves sharp inequality between functional capacity and Bedford-Taylor capacity, demonstrates functional capacity is a Choquet capacity, strengthens results from Dinh, Marinescu, Vu (2023) and Vigny, Vu (2024), and characterizes Moser-Trudinger type inequality via volume-capacity inequality.", "conclusion": "The functional capacity approach provides powerful tools for analyzing local properties in complex Sobolev spaces, yielding sharp inequalities and strengthening previous results in pluripotential theory."}}
{"id": "2602.14361", "pdf": "https://arxiv.org/pdf/2602.14361", "abs": "https://arxiv.org/abs/2602.14361", "authors": ["Ziwei Li", "Dachun Yang", "Wen Yuan"], "title": "Matrix-Weighted Poincar\u00e9-Type Inequalities with Applications to Logarithmic Haj\u0142asz--Besov Spaces on Spaces of Homogeneous Type", "categories": ["math.FA", "math.AP", "math.CA"], "comment": "46 pages. Submitted", "summary": "Let ${\\mathcal {X}}$ be a space of homogeneous type. In this article, based on the reducing operators of matrix $A_p$-weights, the authors introduce the vector-valued Haj\u0142asz gradient sequences and establish some related matrix-weighted Poincar\u00e9-type inequalities on ${\\mathcal {X}}$. As an application, the authors introduce the matrix-weighted logarithmic Besov spaces on ${\\mathcal {X}}$ and establish their pointwise characterization via Haj\u0142asz gradient sequences. The novelty of this article lies in that, by means of both the $A_p$ dimension and its properties of matrix $A_p$-weights and the wavelet reproducing formula with exponential decay of P. Auscher and T. Hyt\u00f6nen, all the main results get rid of the dependence on the reverse doubling conditions of both weights and ${\\mathcal {X}}$ under consideration and these results are also completely new even for unweighted logarithmic Besov spaces on ${\\mathcal {X}}$.", "AI": {"tldr": "The paper establishes matrix-weighted Poincar\u00e9-type inequalities and introduces matrix-weighted logarithmic Besov spaces on homogeneous type spaces, removing dependence on reverse doubling conditions.", "motivation": "To develop vector-valued Haj\u0142asz gradient sequences and matrix-weighted Poincar\u00e9-type inequalities on homogeneous type spaces, eliminating the need for reverse doubling conditions on both weights and the underlying space.", "method": "Using reducing operators of matrix A_p-weights, introducing vector-valued Haj\u0142asz gradient sequences, and employing wavelet reproducing formula with exponential decay by Auscher and Hyt\u00f6nen.", "result": "Established matrix-weighted Poincar\u00e9-type inequalities and introduced matrix-weighted logarithmic Besov spaces with pointwise characterization via Haj\u0142asz gradient sequences, all independent of reverse doubling conditions.", "conclusion": "The results are novel as they remove dependence on reverse doubling conditions and are new even for unweighted logarithmic Besov spaces on homogeneous type spaces."}}
{"id": "2602.14527", "pdf": "https://arxiv.org/pdf/2602.14527", "abs": "https://arxiv.org/abs/2602.14527", "authors": ["Shouhei Honda", "Jinpeng Lu"], "title": "Gel'fand's inverse problem under Ricci curvature bounds", "categories": ["math.DG", "math.AP", "math.MG"], "comment": null, "summary": "The classical Gel'fand's inverse problem asks whether a Riemannian manifold is uniquely determined by the knowledge of the heat kernel on any open subset of the manifold. We study this inverse problem in the non-smooth setting in the framework of ${\\rm RCD}(K,N)$ spaces, namely, metric-measure spaces with synthetic Riemannian Ricci curvature bounded below by $K$ and dimension bounded above by $N$. We establish the unique solvability of Gel'fand's inverse problem for the class of compact ${\\rm RCD}(K,N)$ spaces whose regular set admits $C^1$-Riemannian structure. As an application, we obtain the stability of Gel'fand's inverse problem in the class of closed Riemannian manifolds with bounded Ricci curvature, diameter and volume bounded from below. We note that the results are new even for Einstein orbifolds and (weighted) Riemannian manifolds with non-smooth boundary.", "AI": {"tldr": "The paper solves Gel'fand's inverse problem for non-smooth RCD spaces with C\u00b9-regular structure, establishing uniqueness from heat kernel data on open subsets, with applications to stability in Riemannian manifolds.", "motivation": "Extend the classical Gel'fand's inverse problem (determining a manifold from heat kernel data) to non-smooth metric-measure spaces with synthetic curvature bounds (RCD spaces), which include singular spaces like orbifolds and manifolds with boundaries.", "method": "Study the inverse problem in the framework of RCD(K,N) spaces (metric-measure spaces with synthetic Ricci curvature bounded below by K and dimension bounded above by N). Focus on compact RCD(K,N) spaces whose regular set admits C\u00b9-Riemannian structure.", "result": "Prove unique solvability of Gel'fand's inverse problem for compact RCD(K,N) spaces with C\u00b9-regular structure. Obtain stability results for the inverse problem in the class of closed Riemannian manifolds with bounded Ricci curvature, diameter, and volume bounded from below.", "conclusion": "The classical Gel'fand's inverse problem can be extended to singular geometric settings, with applications to stability in smooth Riemannian manifolds. Results are new even for Einstein orbifolds and weighted Riemannian manifolds with non-smooth boundaries."}}
{"id": "2602.14558", "pdf": "https://arxiv.org/pdf/2602.14558", "abs": "https://arxiv.org/abs/2602.14558", "authors": ["Thibault Lefeuvre", "Rafael Potrie"], "title": "Propagation of regularity along unstable manifolds", "categories": ["math.DS", "math.AP", "math.DG"], "comment": "40 pages. Comments are welcome", "summary": "Let $\\varphi_t : M \\to M$ be a flow on a smooth closed connected manifold $M$ that preserves and expands a foliation $F$. We establish a theorem of propagation of regularity along the leaves of $F$ for sections of vector bundles satisfying a transport equation involving the generator of a cocycle over $\\varphi_t$. As a consequence, we prove a regularity result for Pollicott-Ruelle resonant states: if such state is smooth in restriction to a piece of an unstable leaf, then it is in fact smooth over the entire manifold. We also announce further applications related to joint integrability of extreme bundles of partially hyperbolic diffeomorphisms. The proofs rely on a leafwise semiclassical pseudodifferential calculus adapted to a foliated space, which may be of independent interest.", "AI": {"tldr": "The paper establishes propagation of regularity along foliation leaves for solutions of transport equations, with applications to regularity of Pollicott-Ruelle resonant states and partially hyperbolic diffeomorphisms.", "motivation": "To understand regularity properties of solutions to transport equations on foliated manifolds, particularly for Pollicott-Ruelle resonant states in dynamical systems, and to develop tools for studying partially hyperbolic diffeomorphisms.", "method": "Develops a leafwise semiclassical pseudodifferential calculus adapted to foliated spaces, then applies it to prove propagation of regularity along leaves for sections of vector bundles satisfying transport equations involving cocycle generators.", "result": "Proves that if a Pollicott-Ruelle resonant state is smooth on a piece of an unstable leaf, then it is smooth on the entire manifold. Also establishes propagation of regularity theorem for transport equations on foliated manifolds.", "conclusion": "The developed leafwise pseudodifferential calculus provides powerful tools for analyzing regularity propagation in foliated dynamical systems, with applications to resonant states and partially hyperbolic diffeomorphisms."}}
{"id": "2602.14651", "pdf": "https://arxiv.org/pdf/2602.14651", "abs": "https://arxiv.org/abs/2602.14651", "authors": ["Aires E. M. Barbieri", "Jos\u00e9 A. G\u00e1lvez", "Yuanyuan Lian", "Kai Zhang"], "title": "Asymptotic behavior at infinity of Weingarten surfaces", "categories": ["math.DG", "math.AP"], "comment": null, "summary": "We derive the asymptotic expansion at infinity for embedded ends of uniformly elliptic Weingarten surfaces with finite total curvature in $\\mathbb{R}^3$, and we establish a maximum principle at infinity. Furthermore, we solve the Dirichlet problem for the uniformly elliptic Weingarten equation in dimension two on strictly convex bounded domains.", "AI": {"tldr": "This paper studies uniformly elliptic Weingarten surfaces in \u211d\u00b3, deriving asymptotic expansions for embedded ends with finite total curvature, establishing a maximum principle at infinity, and solving the Dirichlet problem on strictly convex bounded domains.", "motivation": "The motivation is to understand the asymptotic behavior of embedded ends of uniformly elliptic Weingarten surfaces with finite total curvature, and to develop analytical tools (maximum principle at infinity) for studying these surfaces. Additionally, the paper aims to solve the Dirichlet problem for uniformly elliptic Weingarten equations in two dimensions.", "method": "The authors use asymptotic analysis to derive expansions at infinity for embedded ends of uniformly elliptic Weingarten surfaces with finite total curvature. They establish a maximum principle at infinity for these surfaces. For the Dirichlet problem, they work on strictly convex bounded domains in two dimensions and solve the uniformly elliptic Weingarten equation.", "result": "1. Derivation of asymptotic expansion at infinity for embedded ends of uniformly elliptic Weingarten surfaces with finite total curvature. 2. Establishment of a maximum principle at infinity for these surfaces. 3. Solution of the Dirichlet problem for the uniformly elliptic Weingarten equation in dimension two on strictly convex bounded domains.", "conclusion": "The paper provides comprehensive results on the asymptotic behavior of uniformly elliptic Weingarten surfaces with finite total curvature, introduces a useful maximum principle at infinity, and successfully solves the Dirichlet problem for these equations on convex domains, advancing the understanding of these geometric PDEs."}}
{"id": "2602.14801", "pdf": "https://arxiv.org/pdf/2602.14801", "abs": "https://arxiv.org/abs/2602.14801", "authors": ["Andreas Hartmann", "Marcu-Antone Orsoni"], "title": "Identifying Bergman space functions from intervals", "categories": ["math.CV", "math.AP", "math.FA", "math.OC"], "comment": "19 pages, 4 figures", "summary": "We characterize functions of a Bergman space on a square by their values and derivatives on the diagonals. This problem is connected with the reachable space of the one-dimensional heat equation on a finite interval with boundary $L^2$-controls.", "AI": {"tldr": "Characterization of Bergman space functions on a square by their values and derivatives on diagonals, connected to reachable spaces of 1D heat equation with boundary controls.", "motivation": "To establish connections between function theory in Bergman spaces on squares and control theory problems, specifically understanding how functions can be characterized by their behavior on diagonals and relating this to the reachable space of the heat equation with boundary controls.", "method": "Analyzes functions in Bergman spaces on squares by examining their values and derivatives restricted to the diagonals, establishing connections to the reachable space of the one-dimensional heat equation on finite intervals with L^2 boundary controls.", "result": "Provides characterization theorems showing that functions in Bergman spaces on squares can be uniquely determined by their values and derivatives on the diagonals, establishing a precise connection to the reachable space of the heat equation control problem.", "conclusion": "The paper establishes a deep connection between complex analysis (Bergman spaces) and control theory (heat equation reachable spaces), showing that diagonal restrictions provide complete information about functions in these spaces, with implications for both fields."}}
