<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 11]
- [math.AP](#math.AP) [Total: 16]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 2]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [math.OC](#math.OC) [Total: 3]
- [nucl-th](#nucl-th) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [stat.ML](#stat.ML) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [physics.flu-dyn](#physics.flu-dyn) [Total: 1]
- [cs.LG](#cs.LG) [Total: 2]
- [cs.GT](#cs.GT) [Total: 1]
- [math.DS](#math.DS) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 2]
- [math.PR](#math.PR) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [math-ph](#math-ph) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [The spectral fractional Laplacian with measure valued right hand sides: analysis and approximation](https://arxiv.org/abs/2602.11423)
*Enrique Otarola,Abner J. Salgado*

Main category: math.NA

TL;DR: Analysis of fractional Laplace operator with singular forcing in 2D: well-posedness in fractional Sobolev spaces, optimal control for pointwise tracking, and finite element schemes with error bounds.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the need to handle singular forcing terms in fractional diffusion problems, which arise in various applications. There's a gap in understanding weak formulations and numerical methods for fractional Laplace operators with singular data.

Method: 1) Introduces weak formulation in fractional Sobolev spaces for fractional Laplace operator with singular forcing in 2D. 2) Analyzes pointwise tracking optimal control problem. 3) Develops finite element scheme with continuous piecewise linear functions. 4) Proposes practical scheme using diagonalization technique with regularization.

Result: 1) Proves well-posedness of weak formulation. 2) Derives convergence results in energy norm for FEM. 3) Obtains error bounds in L²(Ω) for both FEM and diagonalization schemes. 4) Provides analysis for optimal control problem.

Conclusion: The paper establishes rigorous mathematical framework for fractional diffusion with singular forcing, develops effective numerical methods with proven error bounds, and demonstrates applicability to optimal control problems.

Abstract: We consider the spectral definition of the fractional Laplace operator and study a basic linear problem involving this operator and singular forcing. In two dimensions, we introduce an appropriate weak formulation in fractional Sobolev spaces and prove that it is well-posed. As an application of these results, we analyze a pointwise tracking optimal control problem for fractional diffusion. We also develop a finite element scheme for the linear problem using continuous, piecewise linear functions, prove a convergence result in energy norm, and derive an error bound in $L^2(Ω)$. Finally, we propose a practical scheme based on a diagonalization technique and derive an error bound in $L^2(Ω)$ using a regularization argument.

</details>


### [2] [Adapting the Lanczos algorithm to matrices with almost continuous spectra](https://arxiv.org/abs/2602.11449)
*Jörn Zimmerling,Vladimir Druskin*

Main category: math.NA

TL;DR: A new method for approximating B^T(A+sI)^{-1}B using Kreĭn-Nudelman semi-infinite strings to model continuous spectral measures instead of resolving discrete eigenvalues, improving wave propagation computations.


<details>
  <summary>Details</summary>
Motivation: Traditional Krylov methods (Lanczos, conjugate gradients) inefficiently resolve individual eigenvalues of dense discretizations while ignoring the underlying continuous spectral measures of problems like linear time-invariant PDEs on unbounded domains. There's a need to model the inherent branch cut of original operators rather than exhaustively resolving artificial point spectra from discretization.

Method: Formulates a quadratic terminator using Kreĭn-Nudelman semi-infinite strings with adaptively chosen parameters to maximize relative energy outflow. This creates a low-rank modification to the (block) Lanczos matrix dependent on √s with O(n) additional cost. Replaces conventional Lanczos spectral decomposition with representation in terms of continuous Kreĭn-Nudelman spectrum.

Result: Demonstrates significant error reductions for large-scale self-adjoint PDE discretizations in unbounded domains, including 2D/3D Maxwell's equations in diffusive regimes. Particularly advantageous for computing state-space solutions for wave propagation (2D wave and 3D Maxwell's operators). Transforms standing-wave artifacts into outgoing propagating waves.

Conclusion: The approach provides qualitative improvement in finite-difference approximations by modeling continuous spectral measures rather than discrete eigenvalues, effectively handling wave propagation in unbounded domains with better computational efficiency and accuracy.

Abstract: We consider the approximation of $B^T (A+sI)^{-1} B$ where $A\in\mathbb{R}^{n\times n}$ is large, symmetric positive definite, and has a dense spectrum, and $B\in\mathbb{R}^{n\times p}$, $p\ll n$. Our target application is the computation of Multiple-Input Multiple-Output transfer functions arising from large-scale discretizations of problems with continuous spectral measures, such as linear time-invariant PDEs on unbounded domains. Traditional Krylov methods, such as Lanczos or conjugate gradients, focus on resolving individual eigenvalues of a dense discretization, while ignoring the underlying continuous spectral measure that these points approximate. We argue that it is more efficient to model the inherent branch cut of the original operator than to exhaustively resolve the artificial point spectrum induced by discretization. We place this problem in a framework, known in the physics literature as the square-root terminator. To overcome its limitations, we formulate a quadratic terminator using Kreĭn--Nudelman semi-infinite strings, with parameters chosen adaptively to maximize relative energy outflow.
  This approach results in a low-rank modification to the (block) Lanczos matrix, dependent on $\sqrt{s}$, with an additional $O(n)$ cost. We demonstrate significant error reductions for large-scale self-adjoint PDE discretizations in unbounded domains, including two- and three-dimensional Maxwell's equations in diffusive regimes. The method proves particularly advantageous in computing state-space solutions for wave propagation, specifically for 2D wave and 3D Maxwell's operators. Implicitly replacing the conventional Lanczos spectral decomposition with a representation in terms of the continuous Kreĭn--Nudelman spectrum, we obtain a qualitative improvement in finite-difference approximations, effectively transforming standing-wave artifacts into outgoing propagating waves.

</details>


### [3] [On the Block-Diagonalization and Multiplicative Equivalence of Quaternion $Z$-Block Circulant Matrices with their Applications](https://arxiv.org/abs/2602.11493)
*Daochang Zhang,Yue Zhao,Jingqian Li,Dijana Mosic*

Main category: math.NA

TL;DR: This paper develops algorithms for quaternion tensor computations using z-block circulant matrices, establishes equivalence between QT-product and matrix product, and applies these to tensor decompositions and video rotation.


<details>
  <summary>Details</summary>
Motivation: The paper has two main motivations: 1) To investigate block-diagonalization of z-block circulant matrices and develop algorithms for computing their inverses, and 2) To establish the equivalence between QT-product of tensors and product of corresponding z-block circulant matrices for large-scale Tikhonov-regularized model analysis.

Method: The method involves: 1) Developing the bcirc_z-inv algorithm for computing inverses of z-block circulant matrices, 2) Establishing mathematical equivalence between QT-product and z-block circulant matrix product, 3) Deriving various quaternion tensor decompositions (QT-Polar, QT-PLU, QT-LU, QT-SVD) using this equivalence, and 4) Applying these to video rotation analysis.

Result: The paper provides: 1) Properties of quaternion z-block circulant matrices, 2) Multiple quaternion tensor decompositions under QT-product, 3) Corresponding algorithms with large-scale tests and scalability analysis, and 4) Video rotation applications showing stable, color-accurate performance with inter-frame consistency.

Conclusion: The paper successfully establishes the theoretical framework connecting quaternion tensor operations with z-block circulant matrices, develops practical algorithms for tensor decompositions, and demonstrates their effectiveness in real-world applications like video rotation while maintaining computational stability and color accuracy.

Abstract: The motivation of this paper is twofold. First, we investigate the block-diagonalization of the $z$-block circulant matrix $\mathtt{bcirc_z}(\mathcal A)$, based on this block-diagonal structure, and develop the algorithm $\mathtt{bcirc_z}$-inv for computing the inverse of $\mathtt{bcirc_z}(\mathcal A)$. Second, we establish the equivalence between the QT-product of tensors and the product of the corresponding $z$-block circulant matrices. Based on this equivalence and in combination with the algorithm $\mathtt{bcirc_z}$-inv, large-scale tests and scalability analysis of the Tikhonov-regularized model are conducted.
  As a by-product of the analysis, some relevant and straightforward properties of the quaternion $z$-block circulant matrices are provided. As applications, a series of quaternion tensor decompositions under the QT-product and their corresponding $z$-block circulant matrices decompositions are obtained, including the QT-Polar decomposition, the QT-PLU decomposition, and the QT-LU decomposition. Meanwhile, the QT-SVD is rederived based on the relation between $\mathcal A$ and $\mathtt{bcirc_z}(\mathcal A)$. Furthermore, we develop corresponding algorithms and present several large-scale tests and scalability analysis. In addition, applications in video rotation are presented to evaluate several rotation strategies based on the QT-Polar decomposition, which shows the decomposition remains stable and inter-frame consistent while accurately maintaining color reproduction.

</details>


### [4] [On the convergence rates of generalized conditional gradient method for fully discretized Mean Field Games](https://arxiv.org/abs/2602.11640)
*Haruka Nakamura,Norikazu Saito*

Main category: math.NA

TL;DR: Analysis of convergence rates for generalized conditional gradient method applied to discretized Mean Field Games, providing unified error estimates for both discretization and iteration errors.


<details>
  <summary>Details</summary>
Motivation: While convergence rates of GCG method have been established at continuous PDE level, there's a gap in rigorous analysis that simultaneously accounts for time-space discretization and iteration errors in MFG systems.

Method: Discretize MFG system using finite difference method and analyze the resulting fully discrete GCG scheme. Establish discrete maximum principles and derive explicit error estimates under suitable structural assumptions on Hamiltonian and coupling terms.

Result: Derived explicit error estimates quantifying both discretization and iteration errors within unified framework. Convergence rates depend on mesh sizes and iteration number, showing non-uniform behavior with respect to iteration. Higher convergence rates achievable under additional regularity assumptions.

Conclusion: Provides rigorous convergence analysis for fully discretized GCG method in MFG systems, revealing important dependencies between discretization parameters and iteration behavior, with numerical experiments confirming theoretical predictions.

Abstract: We study convergence rates of the generalized conditional gradient (GCG) method applied to fully discretized Mean Field Games (MFG) systems. While explicit convergence rates of the GCG method have been established at the continuous PDE level, a rigorous analysis that simultaneously accounts for time-space discretization and iteration errors has been missing. In this work, we discretize the MFG system using finite difference method and analyze the resulting fully discrete GCG scheme. Under suitable structural assumptions on the Hamiltonian and coupling terms, we establish discrete maximum principles and derive explicit error estimates that quantify both discretization errors and iteration errors within a unified framework. Our estimates show how the convergence rates depend on the mesh sizes and the iteration number, and they reveal a non-uniform behavior with respect to the iteration. Moreover, we prove that higher convergence rates can be achieved under additional regularity assumptions on the solution. Numerical experiments are presented to illustrate the theoretical results and to confirm the predicted convergence behavior.

</details>


### [5] [Fast Evaluation of Truncated Neumann Series by Low-Product Radix Kernels](https://arxiv.org/abs/2602.11843)
*Piyush Sao*

Main category: math.NA

TL;DR: The paper presents new higher-radix kernels for evaluating truncated Neumann series more efficiently, introducing exact rational kernels for radix 9 and approximate kernels for radix 15, achieving better asymptotic rates than previous methods.


<details>
  <summary>Details</summary>
Motivation: Truncated Neumann series are important for approximate matrix inversion and polynomial preconditioning, but their evaluation is computationally expensive. While splitting methods like repeated squaring reduce the cost from O(k) to O(log k), further improvements require higher-radix kernels that were not previously available beyond radix 5, and the existence of exact rational kernels was unclear.

Method: The authors construct radix kernels for T_m(B)=I+B+...+B^{m-1} and use them to build faster series algorithms. For radix 9, they derive an exact 3-product kernel with rational coefficients. For radix 15, they use numerical optimization to obtain a 4-product kernel. They also introduce a residual-based radix-kernel framework to handle approximate kernels with spillover (extra terms) that break standard telescoping updates.

Result: The radix-9 kernel achieves 5log_9 k = 1.58log_2 k products, a 21% reduction from repeated squaring. The radix-15 kernel attains 6/log_2 15 ≈ 1.54, which is the best known asymptotic rate. Numerical experiments confirm the predicted product-count savings and associated runtime improvements.

Conclusion: The paper successfully constructs higher-radix kernels for truncated Neumann series evaluation, including the first exact rational kernel beyond radix 5, and introduces a framework that accommodates approximate kernels with spillover, achieving significant computational savings over existing methods.

Abstract: Truncated Neumann series $S_k(A)=I+A+\cdots+A^{k-1}$ are used in
  approximate matrix inversion and polynomial preconditioning. In dense
  settings, matrix-matrix products dominate the cost of evaluating $S_k$.
  Naive evaluation needs $k-1$ products, while splitting methods reduce this
  to $O(\log k)$. Repeated squaring, for example, uses $2\log_2 k$
  products, so further gains require higher-radix kernels that extend the
  series by $m$ terms per update. Beyond the known radix-5 kernel, explicit
  higher-radix constructions were not available, and the existence of exact
  rational kernels was unclear.
  We construct radix kernels for $T_m(B)=I+B+\cdots+B^{m-1}$ and use them to
  build faster series algorithms. For radix 9, we derive an exact 3-product
  kernel with rational coefficients, which is the first exact construction
  beyond radix 5. This kernel yields $5\log_9 k=1.58\log_2 k$ products, a
  21% reduction from repeated squaring. For radix 15, numerical optimization
  yields a 4-product kernel that matches the target through degree 14 but
  has nonzero spillover (extra terms) at degrees $\ge 15$. Because spillover
  breaks the standard telescoping update, we introduce a residual-based
  radix-kernel framework that accommodates approximate kernels and retains
  coefficient $(μ_m+2)/\log_2 m$. Within this framework, radix 15 attains
  $6/\log_2 15\approx 1.54$, the best known asymptotic rate. Numerical
  experiments support the predicted product-count savings and associated
  runtime trends.

</details>


### [6] [Data-driven discovery of chemical reaction networks](https://arxiv.org/abs/2602.11849)
*Abraham Reyes-Velazquez,Stefan Güttel,Igor Larrosa,Jonas Latz*

Main category: math.NA

TL;DR: A unified framework for reconstructing chemical reaction networks from concentration data using integral formulations of differential equations with automated mechanism recovery.


<details>
  <summary>Details</summary>
Motivation: To enable fully automated, data-driven discovery of chemical mechanisms by developing a robust method for reconstructing complete chemical reaction networks from experimental concentration data.

Method: Uses an integral formulation of the differential equations governing chemical reactions, followed by an automatic procedure to recover admissible mass-action mechanisms from the equations. Provides theoretical justification with analytical and numerical error bounds.

Result: The integral formulation demonstrates superior robustness to noise and improved accuracy in both rate-law and graph recovery compared to other commonly used formulations.

Conclusion: The framework advances the goal of fully automated, data-driven chemical mechanism discovery by providing a unified approach for mechanistic reconstruction of chemical reaction networks.

Abstract: We propose a unified framework that allows for the full mechanistic reconstruction of chemical reaction networks (CRNs) from concentration data. The framework utilizes an integral formulation of the differential equations governing the chemical reactions, followed by an automatic procedure to recover admissible mass-action mechanisms from the equations. We provide theoretical justification for the use of integral formulations using analytical and numerical error bounds. The integral formulation is demonstrated to offer superior robustness to noise and improved accuracy in both rate-law and graph recovery when compared to other commonly used formulations. Together, our developments advance the goal of fully automated, data-driven chemical mechanism discovery.

</details>


### [7] [Avoiding stabilization terms in virtual elements for eigenvalue problems: The Reduced Basis Virtual Element Method](https://arxiv.org/abs/2602.11870)
*Silvia Bertoluzza,Fabio Credali,Francesca Gardini*

Main category: math.NA

TL;DR: A novel Reduced Basis Virtual Element Method (rbVEM) is introduced for solving Laplace eigenvalue problems, combining virtual element method with reduced basis technique to achieve fully conforming discretization without stabilization.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient method for solving Laplace eigenvalue problems that avoids stabilization terms while maintaining conformity and optimal error estimates.

Method: Combines virtual element method with reduced basis technique to obtain explicit representation of virtual (non-polynomial) contributions to discrete space, resulting in fully conforming discretization.

Result: The method provides correct spectral approximation with optimal error estimates, validated by comprehensive numerical investigation.

Conclusion: rbVEM successfully solves Laplace eigenvalue problems with fully conforming discretization, avoiding stabilization while maintaining optimal convergence properties.

Abstract: We present the novel Reduced Basis Virtual Element Method (rbVEM) for solving the Laplace eigenvalue problem. This approach is based on the virtual element method and exploits the reduced basis technique to obtain an explicit representation of the virtual (non-polynomial) contribution to the discrete space. rbVEM yields a fully conforming discretization of the considered problem, so that stabilization terms are avoided. We prove that rbVEM provides the correct spectral approximation with optimal error estimates. Theoretical results are supplemented by an exhaustive numerical investigation.

</details>


### [8] [Splitting Schemes for ODEs with Goal-Oriented Error Estimation](https://arxiv.org/abs/2602.11972)
*Erik Weyl,Andreas Bartel,Manuel Schaller*

Main category: math.NA

TL;DR: Hybrid error estimator combining dynamic iteration methods with dual weighted residual method to balance dynamic iteration error and discretization error for ODEs discretized by finite elements.


<details>
  <summary>Details</summary>
Motivation: To enable adaptive and flexible discretization of time domain for ODEs solved with finite elements, allowing different discretizations for different variables to handle multiple time scales and improve computational efficiency.

Method: Combines classical dynamic iteration methods (for splitting-based distributed simulation) with dual weighted residual method to create a hybrid a-priori/a-posteriori goal oriented error estimator that evaluates both dynamic iteration error and discretization error.

Result: The error estimators enable adaptive mesh refinement and serve as stopping criteria for dynamic iteration, with efficient numerical linear algebra solvers ensuring applicability to complex problems.

Conclusion: The approach allows flexible time domain discretization where variables can be discretized differently to match both goal and solution requirements, particularly useful for problems with multiple time scales, as demonstrated in numerical experiments comparing adaptive approach to uniform refinement.

Abstract: We present a hybrid a-priori/a-posteriori goal oriented error estimator for a combination of dynamic iteration-based solution of ordinary differential equations discretized by finite elements. Our novel error estimator combines estimates from classical dynamic iteration methods, usually used to enable splitting-based distributed simulation, and from the dual weighted residual method to be able to evaluate and balance both, the dynamic iteration error and the discretization error in desired quantities of interest. The obtained error estimators are used to conduct refinements of the computational mesh and as a stopping criterion for the dynamic iteration. In particular, we allow for an adaptive and flexible discretization of the time domain, where variables can be discretized differently to match both goal and solution requirements, e.g. in view of multiple time scales. We endow the scheme with efficient solvers from numerical linear algebra to ensure its applicability to complex problems. Numerical experiments compare the adaptive approach to a uniform refinement.

</details>


### [9] [Lambda admissible subspaces of self adjoint matrices](https://arxiv.org/abs/2602.11976)
*Francisco Arrieta Zuccalli,Pedro Massey*

Main category: math.NA

TL;DR: The paper introduces Λ-admissible subspaces for matrices with clustered eigenvalues, showing that approximations near these subspaces have good properties, and analyzes how iterative methods approach them with error bounds.


<details>
  <summary>Details</summary>
Motivation: When dealing with self-adjoint matrices that have clustered eigenvalues, traditional subspace approximation methods may not perform optimally. There's a need for a theoretical framework that characterizes subspaces that are particularly well-suited for approximating eigenvalues in clusters.

Method: The paper introduces the novel concept of Λ-admissible subspaces for self-adjoint matrices with clustered eigenvalues. It analyzes properties of low-rank approximations using these subspaces, proves that iterative methods (Subspace Iteration, Krylov methods) converge to Λ-admissible subspaces, derives error bounds for Rayleigh-Ritz approximations, and analyzes the condition number of the Λ-admissible subspace mapping.

Result: Theoretical results show that approximations near Λ-admissible subspaces have desirable properties. Upper bounds are established for distances between Rayleigh-Ritz subspaces and Λ-admissible subspaces, as well as for the condition number of the Λ-admissible subspace mapping. Numerical examples demonstrate advantages in clustered eigenvalue settings.

Conclusion: Λ-admissible subspaces provide a valuable theoretical framework for understanding and improving subspace approximation methods in the presence of clustered eigenvalues, with practical implications for iterative algorithms and error analysis.

Abstract: Given a self-adjoint matrix $A$ and an index $h$ such that $λ_h(A)$ lies in a cluster of eigenvalues of $A$, we introduce the novel class of $Λ$-admissible subspaces of $A$ of dimension $h$. First, we show that the low-rank approximation of the form $P_{\mathcal{T}} A P_{\mathcal{T}}$, for a subspace $\mathcal{T}$ that is close to any $Λ$-admissible subspace of $A$, has nice properties. Then, we prove that some well-known iterative algorithms (such as the Subspace Iteration Method, or the Krylov subspace method) produce subspaces that become arbitrarily close to $Λ$-admissible subspaces. We obtain upper bounds for the distance between subspaces obtained by the Rayleigh-Ritz method applied to $A$ and the class of $Λ$-admissible subspaces. We also find upper bounds for the condition number of the (set-valued) map computing the class of $Λ$-admissible subspaces of $A$. Finally, we include numerical examples that show the advantage of considering this new class of subspaces in the clustered eigenvalue setting.

</details>


### [10] [Mesh-free numerical method for Dirichlet eigenpairs of the Laplacian with potential](https://arxiv.org/abs/2602.12008)
*Dragoş Manea*

Main category: math.NA

TL;DR: A mesh-free method for approximating Dirichlet eigenpairs of -Δ+V on 2D domains with radial potentials, using basis functions from solutions on a containing ball and boundary minimization.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient numerical method for approximating Dirichlet eigenpairs of Schrödinger-type operators with radial potentials on arbitrary simply connected domains, overcoming the limitation of needing explicit basis functions like Bessel functions when V=0.

Method: 1. Consider the eigenvalue problem on a ball containing Ω without boundary conditions for discretized λ values. 2. Use polar coordinates and Fourier expansion to decouple into ODEs. 3. Solve ODEs numerically with 1D FEM to create basis functions. 4. Approximate eigenvalues by minimizing boundary values on ∂Ω among linear combinations of basis functions.

Result: The method provides a mesh-free approach that is highly memory-efficient compared to standard FEM, enabling eigenvalue approximation without domain meshing.

Conclusion: A novel mesh-free method for Dirichlet eigenvalue problems with radial potentials is developed, overcoming the lack of explicit basis functions through numerical solution on a containing ball and boundary minimization, offering significant memory efficiency advantages.

Abstract: This paper is concerned with the numerical approximation of the $L^2$ Dirichlet eigenpairs of the operator $-Δ+ V$ on a simply connected $C^2$ bounded domain $Ω\subset \mathbb{R}^2$ containing the origin, where $V$ is a radial potential.
  We propose a mesh-free method inspired by the Method of Particular Solutions for the Laplacian (i.e. $V=0$). Extending this approach to general $C^1$ radial potentials is challenging due to the lack of explicit basis functions analogous to Bessel functions. To overcome this difficulty, we consider the equation $-Δu + V u = λu$ on a ball containing $Ω$, without imposing boundary conditions, for a collection of values $λ$ forming a fine discretisation of the interval in which eigenvalues are sought. By rewriting the problem in polar coordinates and applying a Fourier expansion with respect to the angular variable, we obtain a decoupled system of ordinary differential equations. These equations are solved numerically using a one-dimensional Finite Element Method, yielding a family of basis functions that are solutions of the equation $-Δu + V u = λu$ on the ball and are independent of the domain $Ω$.
  Dirichlet eigenvalues of $-Δ+ V$ are then approximated by minimising the boundary values on $\partial Ω$ among linear combinations of the basis functions and identifying those values of $λ$ for which the computed minimum is sufficiently small. The proposed method is highly memory-efficient compared to the standard Finite Element approach.

</details>


### [11] [Low T-Phase Rank Approximation of Third Order Tensors](https://arxiv.org/abs/2602.12121)
*Taehyeong Kim,Hayoung Choi,Yimin Wei*

Main category: math.NA

TL;DR: The paper introduces T-phase-rank approximation for sectorial third-order tensors using tensor T-product, develops tensor phase-majorization inequalities, and provides exact optimal solutions for positive-imaginary tensors.


<details>
  <summary>Details</summary>
Motivation: To extend matrix phase concepts to tensors for analyzing sectorial third-order tensors under the tensor T-product framework, enabling tensor approximations with phase constraints.

Method: Introduce canonical T-phases and T-phase rank, formulate approximation as minimizing symmetric gauge of canonical phase vector, develop tensor phase-majorization inequality via block-circulant representation lifting.

Result: Exact optimal-value formula and explicit optimal half-phase truncation family for positive-imaginary regime; tensor counterparts of classical matrix phase inequalities; tensor small phase theorem for MIMO LTI systems.

Conclusion: Successfully extends matrix phase theory to tensors, providing analytical tools for tensor phase approximation with applications to MIMO linear time-invariant systems.

Abstract: We study low T-phase-rank approximation of sectorial third-order tensors $\mathscr{A}\in\mathbb{C}^{n\times n\times p}$ under the tensor T-product. We introduce canonical T-phases and T-phase rank, and formulate the approximation task as minimizing a symmetric gauge of the canonical phase vector under a T-phase-rank constraint. Our main tool is a tensor phase-majorization inequality for the geometric mean, obtained by lifting the matrix inequality through the block-circulant representation. In the positive-imaginary regime, this yields an exact optimal-value formula and an explicit optimal half-phase truncation family. We further establish tensor counterparts of classical matrix phase inequalities and derive a tensor small phase theorem for MIMO linear time-invariant systems.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [12] [Global propagation of analyticity and unique continuation for semilinear conservative PDEs](https://arxiv.org/abs/2602.11240)
*Camille Laurent,Cristóbal Loyola*

Main category: math.AP

TL;DR: A new method for proving global unique continuation for conservative PDEs using global propagation of analyticity and finite determining modes property.


<details>
  <summary>Details</summary>
Motivation: To develop a new approach for establishing global unique continuation properties for conservative partial differential equations, addressing fundamental questions about solution uniqueness and propagation of information in PDE systems.

Method: The method relies on proving global propagation of analyticity and utilizes the property of finite determining modes. It's an abstract approach that can be applied to various PDE types including semilinear wave, plates, and Schrödinger equations.

Result: Development of a new technique for proving global unique continuation results, with applications demonstrated for several important classes of conservative PDEs.

Conclusion: The paper presents a novel abstract method for global unique continuation in conservative PDEs based on analyticity propagation and finite determining modes, with successful applications to multiple equation types.

Abstract: We review some recent results in which we develop a new method for proving global unique continuation for some conservative PDEs. The main tool is to prove some global propagation of analyticity. We first present some known results on the subject. Then, we sketch the abstract method we use, which relies on the property of finite determining modes. We give applications to semilinear wave, plates and Schr\''odinger equations. This note was written for the \emph{Proceedings of the Journ{é}es EDP 2025}.

</details>


### [13] [Time-periodic oscillating Néel walls in ferromagnetic thin films](https://arxiv.org/abs/2602.11420)
*Antonio Capella,Valentin Linse,Christof Melcher,Lauro Morales,Ramón G. Plaza*

Main category: math.AP

TL;DR: The paper proves existence, structure, and spectral stability of time-periodic oscillating 180-degree Néel walls in ferromagnetic thin films under weak periodic external magnetic fields.


<details>
  <summary>Details</summary>
Motivation: To study time-periodic coherent structures in ferromagnetic thin films when perturbed by periodic external magnetic fields, extending the understanding of static Néel walls to dynamic oscillating configurations.

Method: Uses the reduced model for in-plane magnetization by Capella, Melcher, and Otto. Analyzes linearization around time-periodic Néel walls using evolution system of generators and Floquet spectrum analysis of the monodromy map.

Result: Proves existence of time-periodic oscillating Néel walls under weak periodic external magnetic fields. Shows Floquet spectrum of monodromy map is contained in complex unit circle, establishing linear stability of oscillating solutions.

Conclusion: Time-periodic oscillating Néel walls exist and are spectrally stable at linear level when perturbed by weak periodic external magnetic fields, extending stability results from static to dynamic configurations.

Abstract: This paper studies the existence, the structure and the spectral stability of time-periodic oscillating 180-degree Néel walls in ferromagnetic thin films. It is proved that time-periodic coherent structures do exist as solutions to the reduced model for the in-plane magnetization proposed by Capella, Melcher, and Otto (Nonlinearity 20 (2007), no. 11, 2519--2537) when a weak and $T$-periodic external magnetic field is applied in the direction of the easy axes of the film, perturbing in this fashion the well-known static 180-degree Néel wall. The linearization around this time-periodic Néel wall is constituted by a family of linear operators, parametrized by the time variable, which generates an evolution system of generators (or propagator) for the linear problem. Profiting from the stability of the static Néel wall, it is shown that the Floquet spectrum of the monodromy map for the propagator is contained in the complex unit circle, proving stability of the oscillating solution at least at a linear level.

</details>


### [14] [The sharp interface limit of the matrix-valued Allen-Cahn equation](https://arxiv.org/abs/2602.11485)
*Xingyu Wang*

Main category: math.AP

TL;DR: The paper analyzes a matrix-valued Allen-Cahn equation with Saint Venant-Kirchhoff potential using modulated energy method, avoiding complex spectral analysis and relaxing initial data assumptions.


<details>
  <summary>Details</summary>
Motivation: To study the matrix-valued Allen-Cahn equation with Saint Venant-Kirchhoff potential while avoiding the complex spectral analysis of linearized operators at quasi-minimal orbits and the construction of asymptotic expansions that previous approaches required.

Method: Uses the modulated energy method combined with weak convergence methods for nonlinear PDEs. This approach avoids spectrum analysis of linearized operators and asymptotic expansions while relaxing assumptions on admissible initial data exhibiting phase transitions along interfaces.

Result: Successfully analyzes the matrix-valued Allen-Cahn equation with Saint Venant-Kirchhoff potential. As a byproduct, constructs a weak solution to the limiting harmonic heat flow system with both minimal pair and Neumann-type boundary conditions across the interface.

Conclusion: The modulated energy method provides an effective alternative approach for studying matrix-valued Allen-Cahn equations, simplifying analysis by avoiding complex spectral methods while achieving results including weak solutions to related harmonic heat flow systems.

Abstract: In this work, we study a matrix-valued Allen-Cahn equation with a Saint Venant-Kirchhoff potential $F(\mathbf{A})=\frac{1}{4}\|\mathbf{A}\mathbf{A}^\top-\mathbf{I}\|^2$. Our approach employs the modulated energy method together with weak convergence methods for nonlinear partial differential equations. This avoids the subtle spectrum analysis of the linearized operator at the so-called quasi-minimal orbits as well as the construction of asymptotic expansion. Moreover, it relaxes the assumption on the admissible initial data, which exhibits a phase transition along an initial interface. As a byproduct, we construct a weak solution to the limiting harmonic heat flow system with both minimal pair and Neumann-type boundary conditions across the interface.

</details>


### [15] [A blow-up approach for a priori bounds in semilinear planar elliptic systems: the Brezis-Merle critical case](https://arxiv.org/abs/2602.11720)
*Laura Baldelli,Gabriele Mancini,Giulio Romani*

Main category: math.AP

TL;DR: The paper establishes uniform a priori estimates for solutions of semilinear planar Hamiltonian elliptic systems with Dirichlet boundary conditions, extending scalar theory to Hamiltonian systems and solving an open problem.


<details>
  <summary>Details</summary>
Motivation: To extend the scalar theory of uniform a priori bounds for elliptic equations to Hamiltonian systems, addressing an open problem in the literature regarding coupled nonlinearities with asymptotic critical behavior.

Method: Uses blow-up analysis combined with Liouville-type theorems and integral estimates to establish uniform a priori estimates for solutions of semilinear planar Hamiltonian elliptic systems in a ball with Dirichlet boundary conditions.

Result: Successfully extends scalar theory to Hamiltonian case, solves an open problem, and as a consequence proves existence of positive solutions using Fixed Point Index theory.

Conclusion: The approach is novel for this setting and provides a complete extension of uniform a priori bounds theory from scalar to Hamiltonian elliptic systems, with applications to existence results.

Abstract: We establish uniform a priori estimates for solutions of semilinear planar Hamiltonian elliptic systems in a ball with Dirichlet boundary conditions. We consider a broad class of coupled nonlinearities with asymptotic critical behaviour in the sense of Brezis--Merle. The approach we follow is based on a blow-up analysis combined with Liouville--type theorems and integral estimates. Our results extend the scalar theory of uniform a priori bounds to the Hamiltonian case, and solve an open problem in [de Figueiredo D.G., do Ó J.M., Ruf B., Adv. Nonlinear Stud. 6 (2006), no. 2]. We believe that this approach is new in this setting. As a consequence of our a priori estimates, we prove the existence of a positive solution by means of Fixed Point Index theory.

</details>


### [16] [Global Multiplicity and Comparison Principles for Singular Problems driven by Mixed Local-Nonlocal Operators](https://arxiv.org/abs/2602.11889)
*R. Dhanya,Sarbani Pramanik*

Main category: math.AP

TL;DR: This paper studies a singular elliptic problem with mixed local-nonlocal operators, establishes global multiplicity results with respect to parameter λ, develops a Hopf-type strong comparison principle, and investigates qualitative properties of solutions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to analyze singular elliptic problems involving mixed local-nonlocal operators, which combine classical p-Laplacian with fractional q-Laplacian. Such problems arise in various applications and present analytical challenges due to the singular behavior near zero and critical growth at infinity.

Method: The authors use variational methods and develop analytical tools including a Hopf-type strong comparison principle adapted to the nonlinear setting. They employ techniques to handle the singular term λ/u^δ and the mixed local-nonlocal operator structure.

Result: Main results: 1) Global multiplicity result with respect to parameter λ, identifying sharp threshold separating existence, non-existence, and multiplicity regimes; 2) Hopf-type strong comparison principle; 3) Uniform L^∞-estimate; 4) Sobolev versus Hölder local minimizer result.

Conclusion: The paper establishes comprehensive results for singular problems with mixed local-nonlocal operators, develops novel analytical tools, and provides a complete picture of solution behavior with respect to parameter λ. The developed techniques have broader applicability to other mixed operator problems.

Abstract: We study a singular elliptic problem driven by a mixed local-nonlocal operator of the form \begin{equation*}
  \begin{aligned}
  -Δ_p u + (-Δ_q)^s u &= \fracλ{u^δ} + u^r \text{ in } Ω\newline
  u > 0 \text{ in } Ω,\ u &= 0 \text{ in } \mathbb{R}^N \setminus Ω
  \end{aligned} \end{equation*} where $p > sq$, $0<δ<1$ and $λ> 0$ is a parameter. The nonlinearity exhibits a singular power-type behavior near zero and displays at most a critical growth at infinity. We establish a global multiplicity result with respect to the parameter $λ$ by identifying a sharp threshold that separates existence, non-existence, and multiplicity regimes, a result that is new for singular problems involving mixed local-nonlocal operators. We also derive a Hopf-type strong comparison principle adapted to this nonlinear setting, which provides the main analytical tool for the global multiplicity result. Additionally, we investigate qualitative properties of solutions that are essential for the variational analysis, such as a uniform $L^{\infty}$-estimate and a Sobolev versus Hölder local minimizer result. The analytical tools developed herein are of independent mathematical interest, with their applicability extending over a broader class of mixed local-nonlocal problems.

</details>


### [17] [Eigenfracture approximation of quasi-static crack growth in brittle materials](https://arxiv.org/abs/2602.11915)
*Ba Duc Duong,Manuel Friedrich*

Main category: math.AP

TL;DR: The paper presents an approximation scheme for quasi-static crack growth using eigendeformations that converges to Griffith fracture theory as ε→0.


<details>
  <summary>Details</summary>
Motivation: To develop a variational approximation scheme for quasi-static crack growth that bridges eigendeformation models with classical Griffith fracture theory, providing a rigorous mathematical framework for crack evolution.

Method: Uses an eigendeformation approach with energy functionals depending on parameter ε and two fields (displacement and eigendeformation). Imposes irreversibility conditions and employs incremental minimization to define quasi-static evolution.

Result: Shows that as ε→0, the eigendeformation-based evolutions converge to quasi-static crack evolutions for Griffith brittle fracture energy, satisfying irreversibility, global stability, and energy balance.

Conclusion: The eigendeformation approximation scheme provides a valid mathematical framework that converges to classical Griffith fracture theory, establishing a rigorous connection between these approaches to crack growth modeling.

Abstract: We study an approximation scheme for a variational theory of quasi-static crack growth based on an eigendeformation approach. We consider a family of energy functionals depending on a small parameter $\varepsilon$ and on two fields, the displacement field and an eigendeformation field that approximates the crack in the material. By imposing a suitable irreversibility condition and adopting an incremental minimization scheme, we define a notion of quasi-static evolution for this model. We then show that, as $\varepsilon \to 0$, these evolutions converge to a quasi-static crack evolution for the Griffith energy of brittle fracture, characterized by irreversibility, global stability, and an energy balance.

</details>


### [18] [Recovery of an Anisotropic Conductivity from the Neumann-to-Dirichlet Map in a Semilinear Elliptic Equation](https://arxiv.org/abs/2602.11987)
*Elena Beretta,Elisa Francini,Dario Pierotti,Eva Sincich*

Main category: math.AP

TL;DR: The paper proves uniqueness for anisotropic conductivity tensor γ in a nonlinear inverse boundary value problem motivated by cardiac electrophysiology, using first-order linearization around pacing currents.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by pacing-guided ablation in cardiac electrophysiology, where detecting non-uniform conductivity (ischemic regions) is crucial. The inverse problem aims to determine anisotropic conductivity from boundary measurements to identify abnormal cardiac tissue.

Method: The authors study a stationary nonlinear PDE modeling cardiac tissue with anisotropic conductivity γ and nonlinear ionic response α. They use a first-order linearization approach around nontrivial pacing currents (Neumann data) to transform the nonlinear inverse problem into a linear one, then prove uniqueness for γ from the Neumann-to-Dirichlet map.

Result: The main result is a uniqueness theorem for the anisotropic conductivity tensor γ from Neumann-to-Dirichlet data in this nonlinear setting, assuming α and the ischemic subdomain D are known. This addresses a gap in previous work where uniqueness with anisotropic conductivities in nonlinear settings hadn't been analyzed.

Conclusion: The paper successfully establishes uniqueness for anisotropic conductivity in cardiac electrophysiology inverse problems using linearization techniques, providing theoretical foundation for pacing-guided ablation procedures to detect ischemic regions.

Abstract: We study the inverse boundary value problem of detecting a non-uniform conductivity motivated by pacing-guided ablation in cardiac electrophysiology. At the stationary level, the transmembrane potential $u$ in a region \(Ω\subset\mathbb{R}^3\) of cardiac tissue satisfies \[ -\nabla\!\cdot(γ\nabla u)+αu^3=0 \quad \text{in }Ω,\qquad γ\nabla u\cdotν=g \quad \text{on }\partialΩ, \] where $γ$ is an anisotropic conductivity tensor and $α$ a nonlinear ionic response coefficient. The Neumann data $g$ represent pacing currents, and the boundary values $u|_{\partialΩ}$ correspond to invasive voltage measurements. Ischemic regions are modeled by a subdomain $D\subsetΩ$ where $γ$ is piecewise constant. We address the inverse problem of determining $γ$ from the Neumann-to-Dirichlet (NtD) map, assuming that $α$ and $D$ are known. To our knowledge, uniqueness in the case of NtD data with anisotropic conductivities in this nonlinear setting has not been analyzed in previous work. Using a first-order linearization around a nontrivial pacing current, we prove uniqueness for $γ$.

</details>


### [19] [Improved Interior Gradient Estimates for the Mean Curvature Equation under Nonlinear Assumptions](https://arxiv.org/abs/2602.11991)
*Fanheng Xu*

Main category: math.AP

TL;DR: Sharp interior gradient estimates for solutions to mean curvature-type equations with nonlinear right-hand side, establishing gradient bounds depending on solution oscillation and enabling higher regularity and Liouville-type theorems.


<details>
  <summary>Details</summary>
Motivation: To establish gradient estimates for solutions to mean curvature equations with various nonlinear terms, particularly under weakened regularity assumptions, and to develop tools for proving higher regularity and global rigidity results.

Method: Investigates interior gradient estimates under assumption u∈C¹(B_R)∩C³({|∇u|>0}), establishes sharp gradient bounds depending on solution oscillation, applies to wide class of nonlinear terms including elliptic regularization of inverse mean curvature flow, minimal surface equation, and polynomial/logarithmic growth regimes.

Result: Obtains sharp gradient bounds that imply uniform ellipticity away from critical set, enabling application of classical elliptic regularity theory for higher regularity in noncritical regions. When solutions grow at most linearly, results apply in Moser's theory to establish affine linear rigidity of global solutions.

Conclusion: The gradient estimates provide powerful tools for analyzing mean curvature-type equations, leading directly to Liouville-type theorems for global solutions without requiring additional proofs, and establishing connections between gradient bounds, regularity, and global solution behavior.

Abstract: In this paper, we investigate interior gradient estimates for solutions to the mean curvature equation $$ \dive \left( \frac{\nabla u}{\sqrt{1 + |\nabla u|^2}} \right) = f(\nabla u)$$ under various nonlinear assumptions on the right-hand side. Under the weakened initial assumption $u\in C^1(B_R) \cap C^3(\{|\nabla u|>0\})$, we establish sharp gradient bounds that depend on the oscillation of the solution. These estimates are applicable to a wide class of nonlinear terms, including the specific forms arising from the elliptic regularization of the inverse mean curvature flow ($f=\varepsilon\sqrt{1+|\nabla u|^2}$ ), minimal surface equation ($f=0$) and several polynomial and logarithmic growth regimes. As applications, the gradient bounds imply uniform ellipticity of the equation away from the critical set,which allows one to apply classical elliptic regularity theory and obtain higher regularity of solutions in the noncritical region. Moreover, when the solution grows at most linearly, all cases of our results can be applied in Moser's theory to establish the affine linear rigidity of global solutions. This directly leads to the Liouville-type theorems for global solutions without requiring additional proofs.

</details>


### [20] [Inner regularity and Liouville theorems for stable solutions to the mean curvature equation](https://arxiv.org/abs/2602.12001)
*Fanheng Xu*

Main category: math.AP

TL;DR: The paper studies stable solutions of the mean curvature equation with a forcing term. It establishes optimal Morrey regularity for ∇u in local settings and proves Liouville-type theorems for global solutions with specific decay conditions.


<details>
  <summary>Details</summary>
Motivation: To understand the regularity properties of stable solutions to mean curvature equations and establish global non-existence results (Liouville-type theorems) for such solutions, extending classical results from semilinear equations to this geometric setting.

Method: Analytical study of stable solutions to the mean curvature equation with forcing term f(u). Uses techniques from elliptic PDE theory, Morrey space analysis, and geometric analysis. Examines both local regularity (inner Morrey estimates) and global behavior (Liouville theorems).

Result: 1. Local: ∇u satisfies optimal inner Morrey regularity M^{p_n} with explicit exponent p_n depending on dimension n. 2. Radial solutions: symmetry center is at most a removable singularity. 3. Global: Liouville-type theorem showing any stable solution with specific decay conditions must be constant. 4. No nonconstant radial stable solutions exist in dimensions 2≤n≤6.

Conclusion: The paper establishes optimal regularity for stable solutions of mean curvature equations and extends classical Liouville theorems to this geometric setting. Results reveal both similarities and differences compared to semilinear equations, with dimension-dependent critical exponents playing a crucial role.

Abstract: Let $f\in C^1(\mathbb{R})$. We study stable solutions $u$ of the mean curvature equation \[ \operatorname{div}\left( \frac{\nabla u}{\sqrt{1+|\nabla u|^2}} \right) = -f(u) \qquad \text{in}\ Ω\subset \mathbb{R}^n. \] In the local setting we prove that $\nabla u$ satisfies inner Morrey regularity $M^{p_n}$, where \[ p_n := \left\{ \begin{array}{ll} n,\qquad & \text{if}\ 2\leq n\leq 5, \\ \frac{n}{n-4\sqrt{n-1}+4},\qquad & \text{if}\ n\geq 6, \end{array} \right. \] together with the estimate \[ \|\nabla u\|_{M^{p_n}(B_1)} \leq C \left( 1+\|\nabla u\|_{L^1(B_2)} \right). \] The exponent $p_n$ is optimal for $n\leq5$, as shown by an explicit one-dimensional example. For radial solutions we show that the symmetry center is at most a removable singularity.
  Globally, we establish Liouville-type theorem: any stable solution satisfying the growth condition \[ |\nabla u(x)| = \left\{ \begin{array}{lll} o(|x|^{-1}) \ & \text{as}\ |x|\rightarrow +\infty& \text{when}\ 2\leq n\leq 10, \\ o(|x|^{-n/2+\sqrt{n-1}+1}) \ & \text{as}\ |x|\rightarrow +\infty& \text{when}\ n\geq 11, \end{array} \right. \] must be constant. In particular, no nonconstant radial stable solution exists in dimensions \(2\leq n\leq6\), which highlights a global rigidity of stable radial solutions in low dimensions and extend the classical Liouville theorem of Farina and Navarro.
  Several exponents appearing in our results are new for mean curvature equations, showing both similarities and differences with the corresponding theorems for semilinear equations.

</details>


### [21] [Density of Neumann regular smooth functions in Sobolev spaces of subanalytic manifolds](https://arxiv.org/abs/2602.12007)
*Guillaume Valette*

Main category: math.AP

TL;DR: Characterizes when Neumann regular functions are dense in Sobolev spaces for bounded subanalytic smooth submanifolds, with different conditions for p∈[1,2] vs large p.


<details>
  <summary>Details</summary>
Motivation: To understand when smooth functions with specific boundary behavior (Neumann regular functions) can approximate Sobolev functions, which is important for PDE analysis and numerical methods on domains with boundaries.

Method: Uses geometric analysis of bounded subanalytic smooth submanifolds, constructs Lipschitz Neumann regular partitions of unity, and proves density results through connectivity conditions at boundary points.

Result: For p∈[1,2]: density holds iff M is connected at almost every boundary point. For large p: density holds iff M is connected at every boundary point. The construction of Lipschitz Neumann regular partitions of unity is a key technical achievement.

Conclusion: The density of Neumann regular functions in Sobolev spaces depends crucially on the connectivity properties of the submanifold at its boundary, with different thresholds for different Sobolev exponents p.

Abstract: We give characterizations of the bounded subanalytic $\mathscr{C}^\infty$ submanifolds $M$ of $\mathbb{R}^n$ for which the space of Neumann regular functions is dense in Sobolev spaces. By ``Neumann regular function'', we mean a function which is smooth at almost every boundary point and whose gradient is tangent to the boundary. In the case $p\in [1,2]$, we prove that the Neumann regular elements of $\mathscr{C}^\infty(\overline{M})$ are dense in $W^{1,p}(M)$ if and only if $M$ is connected at almost every boundary point. In the case $p$ large, we show that the Neumann regular Lipschitz elements of $\mathscr{C}^\infty(M)$ are dense in $W^{1,p}(M)$ if and only if $M$ is connected at every boundary point. The proof involves the construction of Lipschitz Neumann regular partitions of unity, which is of independent interest.

</details>


### [22] [On the interplay between $(p,q)$-growth and $x$-dependence of the energy integrand: a limit case](https://arxiv.org/abs/2602.12033)
*M. Eleuteri,P. Marcellini,E. Mascolo,A. Passarelli di Napoli*

Main category: math.AP

TL;DR: The paper establishes local Lipschitz regularity for minimizers of non-autonomous integral functionals with (p,q)-growth conditions, using a unified approach that covers both standard and limit cases.


<details>
  <summary>Details</summary>
Motivation: To extend regularity theory for minimizers of integral functionals beyond the autonomous case, addressing the challenging scenario where the energy density has (p,q)-growth and depends on the spatial variable with Sobolev regularity.

Method: The authors develop a unified approach using variational methods and regularity theory for partial differential equations. They work with functionals where the energy density F(x,ξ) satisfies (p,q)-growth conditions and belongs to the Sobolev class W^{1,φ} in the x-variable, with φ(t)=t^r log^α(e+t), r≥n, α≥0.

Result: Proves local Lipschitz regularity of local minimizers under the condition 1 ≤ q/p ≤ 1 + 1/n - 1/r, including the limit case q/p = 1 + 1/n - 1/r. The results generalize and unify previous work from cited references.

Conclusion: The paper provides a comprehensive regularity theory for minimizers of non-autonomous functionals with (p,q)-growth, establishing optimal conditions for Lipschitz regularity and unifying previous results in the literature.

Abstract: We establish the local Lipschitz regularity of the local minimizers of non autonomous integral funtionals of the form \[ \int_ΩF(x, Dz)\,dx, \] where $Ω$ is a bounded open set of $\mathbb{R}^n$, $n \ge 2$. The energy density $F(x,ξ)$ satisfies $(p,q)-$growth conditions with respect to the gradient variable and belongs to the Sobolev class $W^{1,φ}$, with $φ(t)=t^r\log^α(e+t),$ $r\ge n$, $α\ge 0$, as a function of the $x$ variable, under the condition $$ 1\le\frac{q}{p} \le 1 + \frac{1}{n} - \frac{1}{r}. $$ We present a unified approach that covers the limit case $$ \frac{q}{p} = 1 + \frac{1}{n} - \frac{1}{r} $$ and retrieves the results in \cite{EMM16} and in \cite{CGHPdN20}.

</details>


### [23] [Local boundedness for solutions to parabolic $p,q$-problems with degenerate coefficients](https://arxiv.org/abs/2602.12046)
*Flavia Giannetti,Antonia Passarelli di Napoli,Christoph Scheven*

Main category: math.AP

TL;DR: The paper proves local boundedness of solutions to degenerate parabolic equations with p,q-growth conditions and unbounded coefficients, establishing two main results: boundedness from above for subsolutions in energy space, and existence of locally bounded variational solutions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to extend regularity theory to parabolic equations with degenerate coefficients and p,q-growth conditions, where traditional methods fail due to unbounded coefficients and the gap between p and q.

Method: The authors study parabolic equations with structure conditions involving p,q-growth and degenerate coefficients. They assume integrability conditions on the possibly unbounded functions a^{-1} and b, and work under a certain assumption on the gap between p and q.

Result: Two main results: (1) Subsolutions in the natural energy space are locally bounded from above; (2) For parabolic equations with variational structure, these bounds lead to existence of locally bounded variational solutions.

Conclusion: The paper establishes local boundedness results for solutions to degenerate parabolic equations with p,q-growth conditions, extending regularity theory to cases with unbounded coefficients and overcoming challenges posed by the gap between p and q.

Abstract: We investigate the local boundedness of solutions $u:Ω_T\to\mathbb{R}$ to parabolic equations of the form \begin{equation*}
  \partial_tu-\mathrm{div}\,\mathcal{A}(x,t,Du)=0 \qquad\mbox{in }Ω_T=Ω\times(0,T) \end{equation*} that satisfy $p,q$-growth conditions and have degenerate coefficients. More precisely, we assume structure conditions of the type \begin{align*} |\mathcal{A}(x,t,ξ)|&\le b(x,t)(μ^2+|ξ|^2)^{\frac{q-1}{2}},\\ \langle \mathcal{A}(x,t,ξ),ξ\rangle&\ge a(x,t)(μ^2+|ξ|^2)^{\frac {p-2}{2}}|ξ|^2, \end{align*} for $2\le p\le q$ and $μ\in[0,1]$, where the functions $a^{-1}, b:Ω_T\to\mathbb{R}$ are possibly unbounded and only satisfy some integrability condition. Under a certain assumption on the gap between $p$ and $q$, we prove two main results. First, we show that subsolutions that are contained in the natural energy space are locally bounded from above. Second, for parabolic equations with a variational structure, we use these bounds to show the existence of locally bounded variational solutions.

</details>


### [24] [Some remarks on monodromy](https://arxiv.org/abs/2602.12073)
*Tove Dahn*

Main category: math.AP

TL;DR: Analysis of hypoelliptic symbols over regular Lie groups and monodromy in spectral stratification using Nilsson-Bäcklund results.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of hypoelliptic symbols over structured Lie groups and explore monodromy phenomena in spectral stratification, building on established mathematical frameworks.

Method: Utilizes results from Nilsson and Bäcklund to analyze monodromy in spectral stratification of hypoelliptic symbols over very regular Lie groups.

Result: Develops theoretical framework connecting hypoelliptic symbols, Lie group structure, and monodromy properties in spectral stratification.

Conclusion: The paper establishes connections between hypoelliptic analysis on Lie groups and monodromy theory, providing insights into spectral stratification using classical results.

Abstract: We consider hypoelliptic symbols over a very regular Lie group and discuss monodromy for a spectral stratification using results of Nilsson and Bäcklund.

</details>


### [25] [The initial-to-final-state inverse problem with critically-singular potentials](https://arxiv.org/abs/2602.12122)
*Manuel Cañizares,Pedro Caro,Ioannis Parissis,Thanasis Zacharopoulos*

Main category: math.AP

TL;DR: The paper proves that for time-independent potentials, the initial-to-final-state map uniquely determines the Hamiltonian -Δ+V, requiring only L¹-type decay at infinity and allowing Lq-type singularities, improving previous results.


<details>
  <summary>Details</summary>
Motivation: To determine whether the evolution map (initial-to-final-state map) of a quantum system uniquely determines the Hamiltonian that generates it, particularly for time-independent potentials with minimal decay assumptions.

Method: Uses a refinement of the Kenig-Ruiz-Sogge resolvent estimate instead of classical Agmon-Hörmander estimates. Avoids complex geometrical optics solutions by exploiting the time-independent setting.

Result: Uniqueness holds for time-independent potentials V ∈ L¹(ℝⁿ)∩Lq(ℝⁿ), with q>1 if n=2 or q≥n/2 if n≥3, requiring only L¹-type decay at infinity and allowing Lq-type singularities.

Conclusion: The paper significantly improves previous uniqueness results by weakening decay requirements from polynomial/super-exponential to L¹-type decay, enabled by refined resolvent estimates and the time-independent setting.

Abstract: The Schrödinger equation in high dimensions describes the evolution of a quantum system. Assume that we are given the evolution map sending each initial state $f\in L^2(\mathbb{R}^n)$ of the system to the corresponding final state at a fixed time $T$. The main question we address in this paper is whether this initial-to-final-state map uniquely determines the Hamiltonian $-Δ+V$ that generates the evolution. We restrict attention to time-independent potentials $V$ and show that uniqueness holds provided $V \in L^1(\mathbb{R}^n)\cap L^q(\mathbb{R}^n)$, with $q>1$ if $n=2$ or $q\geq n/2$ if $n\geq 3$. This should be compared with the results of Caro and Ruiz, who proved that in the time-dependent case, uniqueness holds under the stronger assumption that the potential exhibits super-exponential decay at infinity, for both bounded and unbounded potentials. This paper extends earlier work of the same authors, where uniqueness was obtained for bounded time-independent potentials with polynomial decay at infinity. Here we only require $L^1$-type decay at infinity and allow for $L^q$-type singularities. We reach this improvement by providing a refinement of the Kenig-Ruiz-Sogge resolvent estimate, which replaces the classical Agmon-Hörmander estimates used previously. Crucially, the time-independent setting allows us to avoid the use of complex geometrical optics solutions and thereby dispense with strong decay assumptions at infinity.

</details>


### [26] [NLS with exponential nonlinearity on compact surfaces](https://arxiv.org/abs/2602.12163)
*Filone G. Longmou-Moffo,Mouhamadou Sy*

Main category: math.AP

TL;DR: The paper establishes a probabilistic global theory in H^1 for NLS with Moser-Trudinger nonlinearity on compact surfaces, addressing existence, uniqueness, and continuity for large data in supercritical regimes.


<details>
  <summary>Details</summary>
Motivation: Previous work on this 2D energy-critical Schrödinger equation showed trichotomy based on energy size, with supercritical regimes exhibiting instabilities and lack of flow continuity. While distributional non-unique probabilistic solutions existed for large data, they couldn't handle uniqueness for H^1 data or define a proper flow. The authors aim to create a unified probabilistic framework that provides existence, uniqueness, and continuity in H^1.

Method: Uses a probabilistic framework combining Yudowich argument for uniqueness and continuity, and IID limit procedure for probabilistic estimates. Key challenge was designing a dissipation operator that balances flow continuity with large data in the reference measure's support. The method handles the borderline nature of the context and the tension between continuity properties and large data requirements.

Result: Establishes a probabilistic global theory in H^1 with existence, uniqueness, and continuity with respect to initial data. For supercritical regimes, shows that a modified energy (with regularity similar to original total energy) can attain arbitrarily high values, suggesting the constructed data set contains supercritical data.

Conclusion: Successfully builds a single probabilistic framework that overcomes previous limitations by providing both existence, uniqueness, and continuity in H^1 for NLS with Moser-Trudinger nonlinearity on compact surfaces, even handling supercritical regimes through modified energy analysis.

Abstract: In this paper, we establish a probabilistic global theory in $H^1$ for the NLS with a Moser-Trudinger nonlinearity posed on compact surfaces. This equation is known to be the two dimensional counterpart to the classical energy-critical Schrödinger equations \cite{CollianderIbrahimMajdoubMasmoudi2009}. The authors of \cite{CollianderIbrahimMajdoubMasmoudi2009} also identified a trichotomy around the criticality of the equation based on the size of the total energy. In particular, for supercritical regimes (large energy), the equation is known to exhibit instabilities : the (uniform) continuity of the flow fails to hold. Large data distributional non unique probabilistic solutions have been obtained in \cite{CasterasMonsaingeon2024}. The setting of \cite{CasterasMonsaingeon2024} does not handle the uniqueness issue for the $H^1$-data and therefore could not define a flow for this regularity. Our main focus here is to build a single probabilistic framework that provides both existence, uniqueness, and continuity with respect to the initial data in $H^1$. Our uniqueness and continuity are based on the so-called Yudowich argument \cite{Judovic1963}, and the probabilistic estimates are derived through the IID limit procedure \cite{Sy2019}. Beyond the difficulties related to the borderline nature of the context, the major challenge resides in the need to satisfy two features that tend to play against each other : obtaining both continuity property of the flow and large data in the support of the reference measure. This made the design of the dissipation operator inherent in the method, as well as the analysis of the resulting quantities, particularly difficult. Regarding the supercritical regime, we show that a modified energy, with regularity similar to the original total energy, admits values as high as desired, suggesting that the constructed set of data contains supercritical ones.

</details>


### [27] [Global solutions and large time stabilization in a model for thermoacoustics in a standard linear solid](https://arxiv.org/abs/2602.12171)
*Tobias Black,Michael Winkler*

Main category: math.AP

TL;DR: The paper proves global existence and exponential stabilization for a coupled thermoacoustic system modeling heat generation in Zener materials, under a stability condition αb > τ and small initial data.


<details>
  <summary>Details</summary>
Motivation: To analyze the simplified modeling of heat generation in Zener type materials subject to stress from acoustic waves, and establish rigorous mathematical results about global solvability and stabilization for the coupled system.

Method: The authors study a one-dimensional coupled system of third-order wave equation (Moore-Gibson-Thompson type) with heat equation, using a Neumann type initial-boundary value problem framework. They impose the stability condition αb > τ and prove existence of small parameter ν depending on system parameters such that for sufficiently small initial data (in terms of derivatives and temperature bounds), global strong solutions exist.

Result: For all Θ_⋆ > 0, there exists ν > 0 such that when initial temperature satisfies ‖Θ₀‖_{L^∞} ≤ Θ_⋆ and initial derivatives are sufficiently small (< ν), the Neumann problem admits a unique time-global strong solution. The solution features exponential stabilization for both components, and the stability condition αb > τ coincides with the full stability regime of the corresponding Moore-Gibson-Thompson equation despite strong nonlinear coupling.

Conclusion: The coupled thermoacoustic system exhibits global well-posedness and exponential stabilization under the same stability condition as the uncoupled Moore-Gibson-Thompson equation, even with strong nonlinear temperature coupling, provided initial data are sufficiently small.

Abstract: This manuscript is concerned with the one-dimensional system \[
  \begin{array}{l}
  τu_{ttt} + αu_{tt} = b \big(γ(Θ) u_{xt}\big)_x + \big( γ(Θ) u_x\big)_x, \\[1mm]
  Θ_t = D Θ_{xx} + bγ(Θ) u_{xt}^2,
  \end{array} \] which is connected to the simplified modeling of heat generation in Zener type materials subject to stress from acoustic waves. Under the assumption that the coefficients $τ>0, b>0$ and $α\geq0$ satisfy \begin{align}\tag{$\star$}
  αb >τ, \end{align} it is shown that for all $Θ_\star>0$ one can find $ν=ν(D,τ,α,b,Θ_\star,γ)>0$ such that an associated Neumann type initial-boundary value problem with Neumann data admits a unique time-global solution in a suitable framework of strong solvability whenever the initial temperature distribution fulfills $$\|Θ_0\|_{L^\infty(Ω)}\leq Θ_\star$$ and the derivatives of the initial data are sufficiently small in the sense of satisfying $$\int_Ωu_{0xx}^2 + \int_Ω(u_{0t})_{xx}^2 + \int_Ω(u_{0tt})_x^2 < ν\quad\text{and}\quad
  \|Θ_{0x}\|_{L^\infty(Ω)}
  + \|Θ_{0xx}\|_{L^\infty(Ω)}
  < ν.$$ The constructed solution moreover features an exponential stabilization property for both components.
  In particular, the parameter range described by ($\star$) coincides with the full stability regime known for the corresponding Moore--Gibson--Thompson equation despite the fairly strong nonlinear coupling to the temperature variable.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [28] [Stochastic Point Kinetics Model of Circulating-Fuel Reactors under Perfect Mixing Approximation](https://arxiv.org/abs/2602.11191)
*Lubomír Bureš,Valeria Raffuzzi*

Main category: physics.comp-ph

TL;DR: Stochastic framework for low-population dynamics in circulating-fuel reactors that models delayed-neutron precursor transport without delay terms, using both Monte Carlo and SDE approaches.


<details>
  <summary>Details</summary>
Motivation: To develop a minimal yet representative model for low-population kinetics in circulating-fuel reactors that captures delayed-neutron precursor transport dynamics without using delay terms, which is important for understanding stochastic effects in reactor transients.

Method: Starting from a modified point-kinetics model with two perfectly-mixed volumes, the authors derive equivalent discrete-event dynamics and an Itô stochastic differential equation system. They implement two solvers: an analog Monte Carlo engine and a semi-implicit Milstein SDE solver.

Result: Transient benchmarks show perfect agreement of AMC/SDE means with deterministic solutions, but reveal that the SDE approach underestimates DNP variances in selected regimes (potentially due to neglect of DNP noise). The framework also shows that the estimator for reactivity loss due to precursor drift is negatively biased.

Conclusion: The developed framework provides a minimal yet representative model for CFR low-population kinetics. Future work will focus on re-deriving and testing SDE noise terms and applying the framework to transient applications like start-up analyses of CFRs.

Abstract: We present a stochastic framework for low-population dynamics in circulating-fuel reactors (CFRs) that captures delayed-neutron precursor (DNP) transport without delay terms. Starting from a modified point-kinetics model with two perfectly-mixed volumes, we derive equivalent discrete-event dynamics and an Itô stochastic differential equation (SDE) system. Two solvers are implemented: an analog Monte Carlo (AMC) engine and a semi-implicit Milstein SDE solver. Transient benchmarks demonstrate perfect agreement of AMC/SDE means with deterministic solutions, while revealing that the SDE approach underestimates DNP variances in selected regimes, potentially due to the neglect of DNP noise. We further recast reactivity loss due to precursor drift in this stochastic setting and show that its estimator is negatively biased. Overall, the developed framework provides a minimal yet representative model for CFR low-population kinetics. Future work will re-derive and test SDE noise terms and apply the framework to selected transient applications such as start-up analyses of CFRs.

</details>


### [29] [Addressing the ground state of the deuteron by physics-informed neural networks](https://arxiv.org/abs/2602.11193)
*Lorenzo Brevi,Antonio Mandarino,Carlo Barbieri,Enrico Prati*

Main category: physics.comp-ph

TL;DR: PINNs successfully solve nuclear many-body Schrödinger equation for deuteron with high accuracy, achieving relative error of 10^-6 in binding energy compared to numerical benchmarks.


<details>
  <summary>Details</summary>
Motivation: Physics-Informed Neural Networks (PINNs) show promise for solving integro-differential problems like the many-body Schrödinger equation, but haven't been demonstrated for extracting nuclear eigenstates yet.

Method: Use PINNs with realistic nucleon-nucleon interactions in momentum space (including strong high-momentum correlations), introduce efficient variational energy expression for loss function, and provide coordinate space benchmarks.

Result: Highly accurate results for deuteron with relative error of 10^-6 between PINN-predicted binding energy and numerical benchmarks, demonstrating PINNs can handle realistic nuclear interactions.

Conclusion: The approach successfully demonstrates PINNs for nuclear structure problems and paves the way for applying PINNs to more complex atomic nuclei.

Abstract: Machine learning techniques have proven to be effective in addressing the structure of atomic nuclei. Physics$-$Informed Neural Networks (PINNs) are a promising machine learning technique suitable for solving integro-differential problems such as the many-body Schrödinger problem. So far, there has been no demonstration of extracting nuclear eigenstates using such method. Here, we tackle realistic nucleon-nucleon interaction in momentum space, including models with strong high-momentum correlations, and demonstrate highly accurate results for the deuteron. We further provide additional benchmarks in coordinate space. We introduce an expression for the variational energy that enters the loss function, which can be evaluated efficiently within the PINNs framework. Results are in excellent agreement with proven numerical methods, with a relative error between the value of the predicted binding energy by the PINN and the numerical benchmark of the order of $10^{-6}$. Our approach paves the way for the exploitation of PINNs to solve more complex atomic nuclei.

</details>


### [30] [Ultra-Fast 3D Porous Media Generation: a GPU- Accelerated List-Indexed Explicit Time-Stepping QSGS Algorithm](https://arxiv.org/abs/2602.11734)
*Ruofan Wang,Mohammed Al-Kobaisi*

Main category: physics.comp-ph

TL;DR: LIETS algorithm accelerates 3D microstructure generation by tracking active growth front instead of scanning entire grid, achieving 24s generation for 400^3 domain vs minutes with traditional QSGS.


<details>
  <summary>Details</summary>
Motivation: Classical QSGS algorithms become prohibitively expensive for large 3D grids in digital rock physics, needing faster high-resolution microstructure generation.

Method: List-indexed explicit time-stepping (LIETS) formulation restricts stochastic growth to explicit active front, implemented in Python with NumPy/CuPy, using seed-spacing control via diamond dilation and volume-fraction-dependent directional growth probability.

Result: For 400^3 domain, LIETS reduces generation time to ~24s on RTX 4060 (vs minutes for traditional methods), achieving 2.7x10^7 nodes/s throughput. Reproduces Fontainebleau sandstone properties with optimal seed spacing s=30 voxels.

Conclusion: LIETS enables efficient high-resolution 3D microstructure generation for digital rock physics, matching experimental permeability-porosity trends while dramatically reducing computational time.

Abstract: Efficient generation of high-resolution synthetic microstructures is essential in digital rock physics, yet classical Quartet Structure Generation Set (QSGS) algorithms become prohibitively expensive on large three-dimensional grids. We develop a list-indexed explicit time-stepping (LIETS) formulation of QSGS that restricts stochastic growth operations to an explicit active front instead of the entire voxel grid. The method is implemented in Python using NumPy on CPUs and CuPy on GPUs, and incorporates seed-spacing control via diamond dilation together with a volume-fraction-dependent directional growth probability. For a 400^3 domain, LIETS reduces generation time from tens of minutes for a serial CPU implementation and several minutes for vectorized CPU and GPU QSGS to about 24 s on a consumer-grade RTX 4060, achieving peak throughputs up to 2.7x10^7 nodes/s. A Fontainebleau sandstone benchmark at 500^3 resolution shows that LIETS reproduces the dependence of pore and grain size distributions on seed spacing (optimal s=30 voxels) and yields permeability-porosity trends within the experimental envelope and consistent with previously published Fast-QSGS results.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [31] [Investigation of Toroidal Rotation Effects on Spherical Torus Equilibria using the Fast Spectral Solver VEQ-R](https://arxiv.org/abs/2602.11422)
*Xingyu Li,Huasheng Xie,Lai Wei,Zhengxiong Wang*

Main category: physics.plasm-ph

TL;DR: VEQ-R is a fast spectral solver for tokamak plasma equilibria with strong toroidal rotation, using Chebyshev expansion and matrix acceleration to achieve 5ms convergence while capturing complex geometric distortions.


<details>
  <summary>Details</summary>
Motivation: Standard reduced models fail to adequately describe the complex geometric response of tokamak plasmas to strong toroidal rotation, especially in sonic regimes where M ~ 1.0.

Method: Uses a 12-parameter shifted Chebyshev spectral expansion to resolve radial variations in high-order shaping profiles, combined with a novel "Matrix-Kernel" acceleration technique that transforms the problem into pre-computed algebraic matrix operations.

Result: Achieves convergence in approximately 5 ms while maintaining exceptional geometric fidelity compared to high-resolution benchmarks. The solver captures rotation-induced flux compression that leads to a monotonic decrease in core safety factor q₀, pushing it dangerously close to unity.

Conclusion: VEQ-R provides an efficient, accurate solver for tokamak equilibria with arbitrary toroidal flow, effectively capturing structural deformation mechanisms in challenging sonic regimes while balancing speed and accuracy.

Abstract: Standard reduced models often fail to adequately describe the complex geometric response of tokamak plasmas to strong toroidal rotation. In this work, we present VEQ-R, a computationally efficient spectral solver designed to calculate fixed-boundary equilibria with arbitrary toroidal flow. In contrast to computationally intensive grid-based codes, our model employs a 12-parameter shifted Chebyshev spectral expansion to explicitly resolve radial variations in high-order shaping profiles--such as dynamic elongation and triangularity. This capability allows the solver to accurately capture differential flux surface distortions (non-rigid effects) even in challenging sonic regimes ($M \sim 1.0$). By synergizing this compact variational formulation with a novel ``Matrix-Kernel'' acceleration technique, we transform the problem into pre-computed algebraic matrix operations. This approach achieves convergence in approximately 5 ms, maintaining exceptional geometric fidelity compared to high-resolution benchmarks while balancing speed and accuracy. Our analysis reveals that rotation-induced flux compression leads to a monotonic decrease in the core safety factor $q_0$, pushing it dangerously close to unity--a structural deformation mechanism effectively captured by this approximate yet robust solver.

</details>


### [32] [Tuning Optical Properties of FTO via Carbonaceous Al2O3 Microdot Deposition by DC plasma sputtering](https://arxiv.org/abs/2602.11970)
*Sarah Salah,Ahmed Atlam,Nagat Elkahwagy,Abdelhamid Elshaer,Mohammed Shihab*

Main category: physics.plasm-ph

TL;DR: DC plasma sputtering of carbonaceous Al2O3 microdots on FTO reduces reflectance for better light-trapping in solar cells.


<details>
  <summary>Details</summary>
Motivation: FTO's high reflectance limits light-trapping efficiency in photovoltaic and optoelectronic devices, requiring anti-reflective coatings.

Method: Simple DC plasma sputtering to deposit carbonaceous Al2O3 microdots on FTO under controlled Ar, O2, and Ar-O2 atmospheres, with plasma density 10^-9 cm^-3 and temperature of 2 eV.

Result: Ar-O2 coatings achieved lowest reflectance across visible range; gas composition tuned microdot size/distribution (0.89 um radius in Ar, agglomerated in O2, intermediate in mixed); gamma-Al2O3 with carbon incorporation confirmed.

Conclusion: Establishes link between sputtering parameters, surface morphology, and optical performance, offering scalable route to anti-reflective coatings for next-generation solar cells.

Abstract: Fluorine-doped tin oxide (FTO) is a key transparent conductive oxide for photovoltaic and optoelectronic devices, yet its high reflectance limits light-trapping efficiency. This work demonstrates a simple DC plasma sputtering approach to deposit carbonaceous Al2O3 microdots on FTO under controlled Ar, O2, and Ar-O2 atmospheres. For plasma discharge in the normal mode, with plasma density 10^-9 cm^-3 and temperature of 2 eV, Volmer-Weber growth produced discrete microdots whose size and distribution were tuned by gas composition: dense, uniform dots in Ar (approximately 0.89 um radius), agglomerated structures in O2, and intermediate morphologies in mixed atmospheres. Structural analysis confirmed gamma-Al2O3 formation with carbon incorporation, while SEM revealed morphology-driven optical behavior. UV-Vis measurements showed that Ar-O2 coatings achieved the lowest reflectance across the visible range, outperforming bare FTO and other conditions. These findings establish a clear link between sputtering parameters, surface morphology, and optical performance, offering a scalable route to anti-reflective, light-trapping coatings for next-generation solar cells and optoelectronic devices.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [33] [Phase-Space Topology and Spectral Flow in Screened Magnetized Plasmas](https://arxiv.org/abs/2602.11763)
*Xianhao Rao,Adil Yolbarsop,Hong Li,Wandong Liu*

Main category: cond-mat.mes-hall

TL;DR: A phase-space framework for topological waves in continuous media (screened magnetized plasma) using pseudo-Hermitian formulation, enabling generalized Schrödinger description and Weyl-symbol analysis, with strip-gap Chern numbers governing interface mode spectral flow.


<details>
  <summary>Details</summary>
Motivation: Topological wave phenomena in continuous media face fundamental challenges due to unbounded spectra and absence of compact Brillouin zone, which obstruct conventional bulk-interface formulations.

Method: Developed unified phase-space framework for screened magnetized plasma using pseudo-Hermitian formulation with positive-definite metric, enabling generalized Schrödinger description and Weyl-symbol analysis of bulk generator. Introduced strip-gap Chern number associated with finite real-frequency strips of bulk spectrum.

Result: Bulk symbol hosts isolated band degeneracies acting as Berry-Chern monopoles, including higher-order spin-1 degeneracy with topological charge +2 that splits into two spin-½ Weyl points under symmetry breaking. Net spectral flow across strip gap determined by enclosed monopole charge. Correspondence persists under collisional damping if finite strip gap remains and no exceptional points enter it.

Conclusion: Provides systematic phase-space framework for topological wave transport in continuous media beyond compact-band and idealized Hermitian settings, establishing bulk-interface correspondence at phase-space symbol level.

Abstract: Topological wave phenomena in continuous media are fundamentally challenged by unbounded spectra and the absence of a compact Brillouin zone, which obstruct conventional bulk--interface formulations. We develop a unified phase-space framework for screened magnetized plasma based on a pseudo-Hermitian formulation with a positive-definite metric, enabling a generalized Schrödinger description and a Weyl-symbol analysis of the bulk generator. We show that the bulk symbol hosts isolated band degeneracies acting as Berry--Chern monopoles, including a higher-order spin-1 degeneracy with topological charge $+2$ that generically splits into two spin-$\tfrac{1}{2}$ Weyl points under symmetry breaking. To characterize topology in this noncompact setting, we introduce a strip-gap Chern number associated with finite real-frequency strips of the bulk spectrum, extending band Chern topology to continuum systems. This invariant governs the spectral flow of interface modes induced by spatial variations of the magnetic field and establishes a bulk--interface correspondence at the level of phase-space symbols. By solving the interface eigenvalue problem, we demonstrate that the net spectral flow across the strip gap is determined by the enclosed monopole charge. We further show that this correspondence persists under collisional damping, provided that a finite strip gap remains and no exceptional points enter it. Our results provide a systematic phase-space framework for topological wave transport in continuous media beyond compact-band and idealized Hermitian settings.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [34] [From Consensus-Based Optimization to Evolution Strategies: Proof of Global Convergence](https://arxiv.org/abs/2602.11677)
*Massimo Fornasier,Hui Huang,Jona Klemenc,Greta Malaspina*

Main category: math.OC

TL;DR: The paper introduces new variants of Consensus-based Optimization (CBO) to address limitations of the original method, including δ-CBO with nonvanishing diffusion, Consensus Freezing for numerical stability, and Consensus Hopping as an evolution strategy, with theoretical analysis of invariant measures and convergence rates.


<details>
  <summary>Details</summary>
Motivation: To address practical and theoretical limitations of the original CBO formulation, particularly premature collapse to suboptimal states and numerical instability with large time steps.

Method: Three new CBO variants: 1) δ-CBO with nonvanishing diffusion to prevent premature convergence, 2) Consensus Freezing scheme that freezes consensus points over intervals for numerical stability with large time steps, and 3) Consensus Hopping scheme derived from time rescaling that functions as a (1,λ)-Evolution Strategy.

Result: Characterization of invariant measures for all proposed schemes and establishment of global convergence results with exponential convergence rates, connecting the models through appropriate asymptotic limits.

Conclusion: The paper presents enhanced CBO variants that overcome limitations of the original method while maintaining theoretical guarantees, providing both practical improvements (numerical stability) and theoretical advances (convergence analysis) for high-dimensional nonconvex optimization.

Abstract: Consensus-based optimization (CBO) is a powerful and versatile zero-order multi-particle method designed to provably solve high-dimensional global optimization problems, including those that are genuinely nonconvex or nonsmooth. The method relies on a balance between stochastic exploration and contraction toward a consensus point, which is defined via the Laplace principle as a proxy for the global minimizer.
  In this paper, we introduce new CBO variants that address practical and theoretical limitations of the original formulation of this novel optimization methodology. First, we propose a model called $δ$-CBO}, which incorporates nonvanishing diffusion to prevent premature collapse to suboptimal states. We also develop a numerically stable implementation, the Consensus Freezing scheme, that remains robust even for arbitrarily large time steps by freezing the consensus point over time intervals. We connect these models through appropriate asymptotic limits. Furthermore, we derive from the Consensus Freezing scheme by suitable time rescaling and asymptotics a further algorithm, the Consensus Hopping scheme, which can be interpreted as a form of $(1,λ)$-Evolution Strategy. For all these schemes, we characterize for the first time the invariant measures and establish global convergence results, including exponential convergence rates.

</details>


### [35] [Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs](https://arxiv.org/abs/2602.12273)
*Yongcun Song,Xiaoming Yuan,Hangrui Yue,Tianyou Zeng*

Main category: math.OC

TL;DR: iUzawa-Net: A deep neural network approach combining inexact Uzawa method with neural networks for real-time solutions to nonsmooth PDE optimal control problems.


<details>
  <summary>Details</summary>
Motivation: To develop the first solver capable of real-time solutions for nonsmooth optimal control problems of linear PDEs by synergizing model-based optimization algorithms with data-driven deep learning techniques.

Method: Unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks.

Result: Proves universal approximation properties and establishes asymptotic ε-optimality for iUzawa-Net, demonstrating promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems.

Conclusion: Provides a versatile framework for designing optimization-informed deep learning approaches to optimal control and PDE-constrained optimization problems, combining merits of both model-based optimization and data-driven deep learning.

Abstract: We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.

</details>


### [36] [Local convergence of mean-field Langevin dynamics: from gradient flows to linearly monotone games](https://arxiv.org/abs/2602.11999)
*Guillaume Wang,Lénaïc Chizat*

Main category: math.OC

TL;DR: Paper establishes exponential local convergence in χ²-divergence for diffusive mean-field systems under Poincaré inequality and monotonicity conditions, without requiring displacement convexity.


<details>
  <summary>Details</summary>
Motivation: To understand convergence properties of diffusive mean-field systems including Wasserstein gradient flows, min-max dynamics, and multi-species games, particularly for non-gradient systems where convergence results were previously unavailable.

Method: Design of a Lyapunov functional mixing χ²-divergence with weighted negative Sobolev norms, using Poincaré inequality and monotonicity conditions without displacement convexity assumptions.

Result: Established exponential local convergence with sharp rates governed by Poincaré constant (not log-Sobolev constant), extended results to linearly monotone multi-player games, partially answering an open question from COLT 2024.

Conclusion: The approach provides local convergence results for non-gradient systems using a novel Lyapunov functional, advancing understanding of mean-field dynamics beyond gradient flows.

Abstract: We study the local convergence of diffusive mean-field systems, including Wasserstein gradient flows, min-max dynamics, and multi-species games. We establish exponential local convergence in $χ^2$-divergence with sharp rates, under two main assumptions: (i) the stationary measures satisfy a Poincaré inequality, and (ii) the velocity field satisfies a monotonicity condition, which reduces to linear convexity of the objective in the gradient flow case. We do not assume any form of displacement convexity or displacement monotonicity.
  In the gradient flow case, global exponential convergence is already known under our linear convexity assumption, with an asymptotic rate governed by the log-Sobolev constant of the stationary measure. Our contribution in this setting is to identify the sharp rate near equilibrium governed instead by the Poincaré constant. This rate coincides with the one suggested by Otto calculus (i.e. by a tight positivity estimate of the Wasserstein Hessian), and refines some results of Tamura (1984), extending them beyond quadratic objectives.
  More importantly, our proof technique extends to certain non-gradient systems, such as linearly monotone two-player and multi-player games. In this case, we obtain explicit local exponential convergence rates in $χ^2$-divergence, thereby partially answering the open question raised by the authors at COLT 2024. While that question concerns global convergence (which remains open), even local convergence results were previously unavailable.
  At the heart of our analysis is the design of a Lyapunov functional that mixes the $χ^2$-divergence with weighted negative Sobolev norms of the density relative to equilibrium.

</details>


<div id='nucl-th'></div>

# nucl-th [[Back]](#toc)

### [37] [Rotation catalyzed chiral magnetovortical instability](https://arxiv.org/abs/2602.11228)
*Shuai Wang,Xu-Guang Huang*

Main category: nucl-th

TL;DR: Background rotation catalyzes chiral magnetovortical instability by splitting Alfven waves into circularly polarized magneto-Coriolis waves, with one becoming unstable due to chiral vortical effect.


<details>
  <summary>Details</summary>
Motivation: To understand how background rotation affects chiral magnetohydrodynamics and potentially enables new dynamo mechanisms in rotating chiral plasmas.

Method: Analyzing chiral magnetohydrodynamics with background rotation, studying how rotation splits linearly polarized Alfven waves into circularly polarized magneto-Coriolis waves, and examining stability conditions with chiral vortical effect.

Result: Rotation catalyzes chiral magnetovortical instability; one of the magneto-Coriolis waves always becomes unstable with even weak chiral vortical effect, potentially enabling new dynamo mechanisms.

Conclusion: Background rotation significantly enhances chiral magnetovortical instability, making low-frequency magneto-Coriolis waves unstable and potentially enabling new dynamo mechanisms in various rotating chiral plasmas.

Abstract: We demonstrate that a background rotation significantly catalyzes the chiral magnetovortical instability in chiral magnetohydrodynamics. The rotation splits the linearly polarized Alfven wave into two circularly polarized magneto-Coriolis waves, one of which exhibits a lower frequency than the original Alfven wave. We find that this low-frequency magneto-Coriolis wave is always unstable in the presence of even a weak chiral vortical effect. This instability may enable new dynamo mechanism applicable to various rotating chiral plasmas.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [38] [Sub--Riemannian boundary value problems for Optimal Geometric Locomotion](https://arxiv.org/abs/2602.12199)
*Oliver Gross,Florine Hartwig,Martin Rumpf,Peter Schröder*

Main category: cs.RO

TL;DR: Geometric model for optimal shape-change-induced motions of slender locomotors using sub-Riemannian geodesics to compute energy-efficient deformation gaits.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive geometric framework that captures overall locomotion efficiency by accounting for both environmental drag energy and internal metabolic/actuator energy dissipated during shape changes in slender locomotors like snakes and spermatozoa.

Method: Formulates Lagrangian least-dissipation principles as boundary value problems solved by sub-Riemannian geodesics. Includes continuous model with consistent time-space discretization for numerical computation of optimal deformation gaits under three boundary conditions.

Result: Optimal deformation gaits qualitatively match observed motion trajectories of biological organisms (snakes, spermatozoa) and known optimality results for low-dimensional systems like Purcell's swimmers. Provides new insights into locomotion mechanisms of generalized Purcell's swimmers.

Conclusion: The geometric model successfully captures overall locomotion efficiency and enables computation of optimal shape-change motions that align with biological observations and theoretical predictions, offering a flexible framework for studying slender locomotors.

Abstract: We propose a geometric model for optimal shape-change-induced motions of slender locomotors, e.g., snakes slithering on sand. In these scenarios, the motion of a body in world coordinates is completely determined by the sequence of shapes it assumes. Specifically, we formulate Lagrangian least-dissipation principles as boundary value problems whose solutions are given by sub-Riemannian geodesics. Notably, our geometric model accounts not only for the energy dissipated by the body's displacement through the environment, but also for the energy dissipated by the animal's metabolism or a robot's actuators to induce shape changes such as bending and stretching, thus capturing overall locomotion efficiency. Our continuous model, together with a consistent time and space discretization, enables numerical computation of sub-Riemannian geodesics for three different types of boundary conditions, i.e., fixing initial and target body, restricting to cyclic motion, or solely prescribing body displacement and orientation. The resulting optimal deformation gaits qualitatively match observed motion trajectories of organisms such as snakes and spermatozoa, as well as known optimality results for low-dimensional systems such as Purcell's swimmers. Moreover, being geometrically less rigid than previous frameworks, our model enables new insights into locomotion mechanisms of, e.g., generalized Purcell's swimmers. The code is publicly available.

</details>


<div id='stat.ML'></div>

# stat.ML [[Back]](#toc)

### [39] [Estimation of instrument and noise parameters for inverse problem based on prior diffusion model](https://arxiv.org/abs/2602.11711)
*Jean-François Giovannelli*

Main category: stat.ML

TL;DR: Bayesian framework for estimating observation parameters in inverse problems using diffusion process priors, with efficient MCMC sampling for uncertainty quantification.


<details>
  <summary>Details</summary>
Motivation: Address the challenging problem of estimating observation parameters (response and error parameters) in inverse problems, particularly when regularization is introduced in a Bayesian framework with diffusion process priors, where posterior sampling is known to be difficult.

Method: Proposes a Bayesian approach with diffusion process priors for regularization, using a recently developed simple and effective posterior sampling method. The strategy enables optimal estimation of both observation parameters and the image of interest, with MCMC algorithms for efficient computation of estimates and posterior properties.

Result: Numerical experiments confirm computational efficiency and quality of both parameter estimates and uncertainty quantification. The method provides remarkable flexibility for estimating observation parameters while offering guarantees through MCMC algorithms.

Conclusion: The proposed Bayesian framework with diffusion process priors and efficient MCMC sampling successfully addresses the challenging problem of observation parameter estimation in inverse problems, providing both optimal estimators and reliable uncertainty quantification with computational efficiency.

Abstract: This article addresses the issue of estimating observation parameters (response and error parameters) in inverse problems. The focus is on cases where regularization is introduced in a Bayesian framework and the prior is modeled by a diffusion process. In this context, the issue of posterior sampling is well known to be thorny, and a recent paper proposes a notably simple and effective solution. Consequently, it offers an remarkable additional flexibility when it comes to estimating observation parameters. The proposed strategy enables us to define an optimal estimator for both the observation parameters and the image of interest. Furthermore, the strategy provides a means of quantifying uncertainty. In addition, MCMC algorithms allow for the efficient computation of estimates and properties of posteriors, while offering some guarantees. The paper presents several numerical experiments that clearly confirm the computational efficiency and the quality of both estimates and uncertainties quantification.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [40] [Signatures of Damping Nonlinear Oscillations by KHI-induced Turbulence in Synthetic Observations](https://arxiv.org/abs/2602.11884)
*Sihui Zhong,Andrew Hillier,Iñigo Arregui*

Main category: astro-ph.SR

TL;DR: Nonlinear damping in coronal loop oscillations driven by Kelvin-Helmholtz instability turbulence is studied via 3D MHD simulations and synthetic EUV observations, revealing time-varying frequency shifts, higher-order modes, and observational signatures for seismological inference.


<details>
  <summary>Details</summary>
Motivation: Large-amplitude decaying kink oscillations in coronal loops are influenced by nonlinear processes like Kelvin-Helmholtz instability and turbulence, but comprehensive theory and observational confirmation remain limited. The paper aims to investigate observational signatures of nonlinear damping by KHI-induced turbulence.

Method: Using 3D magnetohydrodynamic simulations and forward-modelled EUV images to study nonlinear damping in impulsively driven transverse loop oscillations. Bayesian fitting is applied to analyze oscillation parameters and damping profiles.

Result: Simulations show time-varying frequency shifts and damping rates consistent with nonlinear turbulence-damping theory, excitation of higher-order modes, slightly increased periods, and reduced displacement amplitudes. Synthetic observations preserve these features but require higher spatial resolution for higher-order modes. Hotter EUV channels show faster decay with smaller displacements and larger phase shifts. Bayesian fitting reveals robust constraints on initial amplitude and kink period but degeneracy in damping parameters.

Conclusion: The study provides a quantitative basis for identifying nonlinear damping and detecting KHI-driven turbulence in transverse loop oscillations, though additional observables are needed for reliable seismological inference of damping profiles.

Abstract: Large-amplitude decaying kink oscillations of coronal loops are strongly influenced by nonlinear processes, such as Kelvin-Helmholtz instability (KHI) and turbulence, though comprehensive theory and observational confirmation remain limited. Building on the recently developed theory on nonlinear damping by KHI-induced turbulence in impulsively driven transverse loop oscillations, we investigate its observational signatures using 3D magnetohydrodynamic simulations and forward-modelled EUV images. The simulated oscillations exhibit time-varying frequency shifts and damping rates, which are broadly consistent with nonlinear turbulence-damping theory. Additionally, they exhibit excitation of higher-order modes, slightly increased periods relative to the linear kink period, and reduced displacement amplitudes. These features are generally preserved in synthetic observations, though resolving higher-order modes requires higher spatial resolution than currently available. For loops embedded in a hotter background, hotter channels (e.g., 193 Angstroms) are more sensitive to boundary dynamics, thus their oscillations decay faster with smaller displacements and larger phase shifts than those in cooler channels (e.g., 171 Angstroms). Comparisons of simulated and synthetic oscillations show close agreement at the early stage. At later times, synthetic oscillations exhibit smaller displacements and larger phase shifts, due to turbulence-induced asymmetry in the loop cross-section. Bayesian fitting shows that the initial oscillation amplitude and kink period are robustly constrained, whereas parameters controlling the damping profile are degenerate, indicating that additional observables would aid reliable seismological inference. These results provide a quantitative basis for identifying nonlinear damping and detecting KHI-driven turbulence in transverse loop oscillations.

</details>


<div id='physics.flu-dyn'></div>

# physics.flu-dyn [[Back]](#toc)

### [41] [On Capturing Laminar/Turbulent Regions Over a Wing Using WMLES](https://arxiv.org/abs/2602.11377)
*P. Balakumar,Prahladh S. Iyer*

Main category: physics.flu-dyn

TL;DR: WMLES study on NACA0012 airfoil shows conflicting grid resolution needs for laminar vs turbulent regions; precursor RANS-based adaptive grid with disturbance injection improves results.


<details>
  <summary>Details</summary>
Motivation: To determine grid resolution requirements for WMLES to accurately predict both laminar and turbulent regions on airfoil surfaces, addressing the conflicting resolution needs between these flow regimes.

Method: Used unstructured-grid finite-volume solver with equilibrium wall function; simulated NACA0012 airfoil at Re=3M with two scenarios (fully turbulent vs partially laminar); employed precursor RANS to generate adaptive grid based on varying boundary layer thickness; introduced unsteady disturbances at most amplified frequencies upstream of neutral point.

Result: Standard grid captured turbulent skin friction well but failed in laminar regions; refined wall-normal grid captured laminar region but degraded turbulent resolution; adaptive grid improved laminar results but delayed transition; adding disturbances enabled satisfactory capture of transition process and turbulent skin friction.

Conclusion: Successful WMLES of transitional airfoil flow requires adaptive grid resolution based on local boundary layer thickness combined with disturbance injection to trigger natural transition, reconciling conflicting resolution requirements between laminar and turbulent regions.

Abstract: Wall-modeled large-eddy simulation (WMLES) is performed for flow over a wing with a focus on documenting grid resolution requirements to predict both the laminar and turbulent regions accurately. Flow over a spanwise extruded NACA0012 airfoil at 0-degree angle of attack and freestream chord-based Reynolds numbers of 3 million is simulated using an unstructured-grid finite-volume solver. An equilibrium wall function with the first off-wall grid point as the exchange location is used. Two scenarios are simulated wherein either the entire airfoil surface, or only a portion of it, is assumed turbulent based on linear stability calculations. For the latter scenario, the regular no-slip wall boundary condition is imposed in laminar regions. Using the same grid that was employed in the fully turbulent case, WMLES captured the skin friction in the turbulent region close to the RANS results. However, the skin friction is not well captured in the laminar region, due to far few grid points inside the boundary layer. When the near-wall grid was refined in the wall normal direction, the laminar region was captured accurately, but the turbulent region was not resolved well because the first off-wall point moved below the buffer-layer. To reconcile differing resolution requirements in the laminar and turbulent regions, a grid was generated based on the varying boundary layer thickness estimated from a precursor RANS simulation with a specified transition location. This grid produced improved results in the laminar region but resulted in a delayed transition location. Unsteady disturbances with the most amplified frequencies were introduced upstream of the neutral point. The transition process in the laminar region and the skin friction in the turbulent region were then captured satisfactorily.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [42] [Toward Adaptive Non-Intrusive Reduced-Order Models: Design and Challenges](https://arxiv.org/abs/2602.11378)
*Amirpasha Hedayat,Alberto Padovan,Karthik Duraisamy*

Main category: cs.LG

TL;DR: Adaptive non-intrusive ROMs that update both latent subspace and reduced dynamics online outperform static ROMs when dynamics evolve beyond training manifold.


<details>
  <summary>Details</summary>
Motivation: Static projection-based ROMs become ineffective when systems leave their training manifold, limiting practical utility for evolving dynamics.

Method: Three adaptive formulations: Adaptive OpInf (sequential basis/operator refits), Adaptive NiTROM (joint Riemannian optimization of encoder/decoder and polynomial dynamics), and a hybrid approach combining both.

Result: On perturbed lid-driven cavity flow: Adaptive OpInf suppresses amplitude drift; Adaptive NiTROM achieves near-exact energy tracking; Hybrid approach is most reliable under regime changes with minimal offline data.

Conclusion: Predictive ROMs must be cost-aware with clear separation of training/adaptation/deployment regimes; adaptive non-intrusive ROMs provide self-correcting capability for evolving dynamics beyond initial manifold.

Abstract: Projection-based Reduced Order Models (ROMs) are often deployed as static surrogates, which limits their practical utility once a system leaves the training manifold. We formalize and study adaptive non-intrusive ROMs that update both the latent subspace and the reduced dynamics online. Building on ideas from static non-intrusive ROMs, specifically, Operator Inference (OpInf) and the recently-introduced Non-intrusive Trajectory-based optimization of Reduced-Order Models (NiTROM), we propose three formulations: Adaptive OpInf (sequential basis/operator refits), Adaptive NiTROM (joint Riemannian optimization of encoder/decoder and polynomial dynamics), and a hybrid that initializes NiTROM with an OpInf update. We describe the online data window, adaptation window, and computational budget, and analyze cost scaling. On a transiently perturbed lid-driven cavity flow, static Galerkin/OpInf/NiTROM drift or destabilize when forecasting beyond training. In contrast, Adaptive OpInf robustly suppresses amplitude drift with modest cost; Adaptive NiTROM is shown to attain near-exact energy tracking under frequent updates but is sensitive to its initialization and optimization depth; the hybrid is most reliable under regime changes and minimal offline data, yielding physically coherent fields and bounded energy. We argue that predictive claims for ROMs must be cost-aware and transparent, with clear separation of training/adaptation/deployment regimes and explicit reporting of online budgets and full-order model queries. This work provides a practical template for building self-correcting, non-intrusive ROMs that remain effective as the dynamics evolve well beyond the initial manifold.

</details>


### [43] [ArGEnT: Arbitrary Geometry-encoded Transformer for Operator Learning](https://arxiv.org/abs/2602.11626)
*Wenqian Chen,Yucheng Fu,Michael Penwarden,Pratanu Roy,Panos Stinis*

Main category: cs.LG

TL;DR: ArGEnT is a geometry-aware Transformer architecture for operator learning that encodes geometric information from point clouds and integrates with DeepONet to create surrogates that generalize across varying geometries without explicit geometric parameterization.


<details>
  <summary>Details</summary>
Motivation: Learning solution operators for systems with complex, varying geometries and parametric physical settings is challenging, especially in many-query regimes like design optimization, control, and inverse problems where surrogates must generalize across geometries while allowing flexible evaluation at arbitrary spatial locations.

Method: Proposes Arbitrary Geometry-encoded Transformer (ArGEnT) with three attention variants (self-attention, cross-attention, hybrid-attention) to encode geometric information from point-cloud representations. Integrates ArGEnT into DeepONet as the trunk network to learn operator mappings dependent on both geometric and non-geometric inputs without explicit geometry parameterization as branch network input.

Result: Significantly improved prediction accuracy and generalization performance compared to standard DeepONet and other existing geometry-aware surrogates across benchmark problems in fluid dynamics, solid mechanics, and electrochemical systems. Cross-attention variant enables accurate geometry-conditioned predictions with reduced reliance on signed distance functions.

Conclusion: ArGEnT provides a scalable surrogate modeling framework combining flexible geometry encoding with operator-learning capabilities, suitable for optimization, uncertainty quantification, and data-driven modeling of complex physical systems with varying geometries.

Abstract: Learning solution operators for systems with complex, varying geometries and parametric physical settings is a central challenge in scientific machine learning. In many-query regimes such as design optimization, control and inverse problems, surrogate modeling must generalize across geometries while allowing flexible evaluation at arbitrary spatial locations. In this work, we propose Arbitrary Geometry-encoded Transformer (ArGEnT), a geometry-aware attention-based architecture for operator learning on arbitrary domains. ArGEnT employs Transformer attention mechanisms to encode geometric information directly from point-cloud representations with three variants-self-attention, cross-attention, and hybrid-attention-that incorporates different strategies for incorporating geometric features. By integrating ArGEnT into DeepONet as the trunk network, we develop a surrogate modeling framework capable of learning operator mappings that depend on both geometric and non-geometric inputs without the need to explicitly parametrize geometry as a branch network input. Evaluation on benchmark problems spanning fluid dynamics, solid mechanics and electrochemical systems, we demonstrate significantly improved prediction accuracy and generalization performance compared with the standard DeepONet and other existing geometry-aware saurrogates. In particular, the cross-attention transformer variant enables accurate geometry-conditioned predictions with reduced reliance on signed distance functions. By combining flexible geometry encoding with operator-learning capabilities, ArGEnT provides a scalable surrogate modeling framework for optimization, uncertainty quantification, and data-driven modeling of complex physical systems.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [44] [Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition](https://arxiv.org/abs/2602.11835)
*Yutong Chao,Jalal Etesami*

Main category: cs.GT

TL;DR: The paper extends the Polyak-Łojasiewicz (PL) condition to multi-player games, proposes gradient-based algorithms for finding Nash equilibria, and develops adapted variants when standard methods fail.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop efficient first-order gradient-based algorithms for finding Nash equilibria in general-sum games, especially when standard gradient descent methods fail to converge.

Method: The authors introduce an n-sided PL condition extending the gradient dominance condition to multi-player settings, analyze convergence of gradient descent algorithms under this condition, and propose adapted variants (including block coordinate descent) for cases where standard GD fails.

Result: The paper establishes convergence guarantees for various gradient-based algorithms under the n-sided PL condition, demonstrates scenarios where standard GD fails, and shows that proposed adapted variants successfully converge to Nash equilibria with analyzed convergence rates.

Conclusion: The n-sided PL condition provides a useful framework for analyzing gradient-based methods in multi-player games, and the proposed adapted algorithms offer effective solutions for finding Nash equilibria even when standard gradient descent methods fail.

Abstract: We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\in\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-Łojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.

</details>


<div id='math.DS'></div>

# math.DS [[Back]](#toc)

### [45] [Twisted Pollicott--Ruelle resonances and zeta function at zero on surfaces](https://arxiv.org/abs/2602.12166)
*Tristan Humbert,Zhongkai Tao*

Main category: math.DS

TL;DR: The paper studies twisted Ruelle zeta functions for surfaces with Anosov geodesic flow, showing vanishing orders at s=0 depend on whether representations factor through the surface's fundamental group, and relates non-vanishing values to Reidemeister-Turaev torsion.


<details>
  <summary>Details</summary>
Motivation: To extend Fried's conjecture about Ruelle zeta functions to a broader class of representations, specifically to generic sets of acyclic (not necessarily unitary) representations for surfaces with Anosov geodesic flow.

Method: The authors compute dimensions of spaces of generalized twisted Pollicott-Ruelle resonant states at zero for representations in an open subset U_g of finite-dimensional irreducible representations, whose complement has complex codimension at least one.

Result: For representations in U_g: if ρ factors through π₁(Σ), the twisted Ruelle zeta function vanishes at s=0 to order dim(ρ)(2G-2); otherwise it doesn't vanish, and ζ_{g,ρ}(0) equals the Reidemeister-Turaev torsion.

Conclusion: This extends Fried's conjecture to a generic set of acyclic representations (not necessarily unitary) for surfaces with Anosov geodesic flow, establishing precise vanishing orders and connections to topological invariants.

Abstract: For an orientable closed surface $(Σ,g)$ of genus $G$ with Anosov geodesic flow, we show the existence of an open subset $U_g$ of finite-dimensional irreducible representations of the fundamental group of its unit tangent bundle, whose complement has complex codimension at least one and such that for any $ρ\in U_g$, the twisted Ruelle zeta function $ζ_{g,ρ}(s)$ vanishes at $s=0$ to order ${\rm dim}(ρ)(2G-2)$ if $ρ$ factors through $π_1(Σ)$, and does not vanish otherwise. In the second case, we show that $ζ_{g,ρ}(0)$ is given by the Reidemeister--Turaev torsion, thus extending Fried's conjecture to a generic set of acyclic (but not necessarily unitary) representations. Our proof relies on computing the dimensions of the spaces of generalized twisted Pollicott--Ruelle resonant states at zero for any $ρ\in U_g$.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [46] [Vision Transformer for Multi-Domain Phase Retrieval in Coherent Diffraction Imaging](https://arxiv.org/abs/2602.12255)
*Jialun Liu,David Yang,Ian Robinson*

Main category: physics.optics

TL;DR: Fourier Vision Transformer solves strong-phase Bragg coherent diffraction imaging problems where traditional methods fail, achieving better performance on both synthetic and experimental data.


<details>
  <summary>Details</summary>
Motivation: Bragg coherent diffraction imaging (BCDI) phase retrieval becomes difficult in strong-phase regimes (beyond ±π/2) where crystals contain distortions beyond half a lattice spacing. Traditional iterative solvers often stagnate or return inconsistent solutions for multi-domain crystals with sharp phase jumps at domain walls.

Method: Introduces an unsupervised Fourier Vision Transformer (Fourier ViT) that directly solves block-phase, multi-domain phase-retrieval from measured 2D Bragg diffraction intensities. The architecture couples reciprocal-space information globally through multiscale Fourier token mixing, while using shallow convolutional front and back-ends for local filtering and reconstruction.

Result: On synthetic datasets of Voronoi multi-domain crystals with strong-phase contrast under realistic noise, Fourier ViT achieves the lowest reciprocal-space mismatch (χ²) among compared methods and preserves domain-resolved phase reconstructions as domain numbers increase. On experimental La₂₋ₓCaₓMnO₄ nanocrystal data, it matches iterative benchmark χ² while improving robustness to random initializations and achieving higher success rate of low-χ² reconstructions than CNN baselines.

Conclusion: Fourier ViT provides an effective unsupervised solution for challenging strong-phase BCDI problems, outperforming traditional iterative methods and neural network baselines in both accuracy and robustness, particularly for multi-domain crystals with sharp phase boundaries.

Abstract: Bragg coherent diffraction imaging (BCDI) phase retrieval becomes rapidly difficult in the strong-phase regime, where a crystal contains distortions beyond half a lattice spacing. An important special case is the phase domain problem, where blocks of a crystal are displaced with sharp jumps at domain walls. The strong-phase, here defined as beyond $\pm π/2$, generates split Bragg peaks and dense fringe structure for which classical iterative solvers often stagnate or return different solutions from different initialisations. Here, we introduce an unsupervised Fourier Vision Transformer (Fourier ViT) to solve this block-phase, multi-domain phase-retrieval problem directly from measured 2D Bragg diffraction intensities. Fourier ViT couples reciprocal-space information globally through multiscale Fourier token mixing, while shallow convolutional front and back-ends provide local filtering and reconstruction. We validate the approach on large-scale synthetic datasets of Voronoi multi-domain crystals with strong-phase contrast under realistic noise corruptions, and on experimental diffraction from a $\mathrm{La}_{2-x}\mathrm{Ca}_x\mathrm{MnO}_4$ nanocrystal. Across the regimes considered, Fourier ViT achieves the lowest reciprocal-space mismatch ($χ^2$) among the compared methods and preserves domain-resolved phase reconstructions for increasing numbers of domains. On experimental data, with the same real-space support, Fourier ViT matches the iterative benchmark $χ^2$ while improving robustness to random initialisations, yielding a higher success rate of low-$χ^2$ reconstructions than the complex convolutional neural network baseline.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [47] [A critical assessment of bonding descriptors for predicting materials properties](https://arxiv.org/abs/2602.12109)
*Aakash Ashok Naik,Nidal Dhamrait,Katharina Ueltzen,Christina Ertural,Philipp Benner,Gian-Marco Rignanese,Janine George*

Main category: cond-mat.mtrl-sci

TL;DR: Quantum-chemical bonding descriptors improve ML models for materials properties and enable intuitive symbolic expressions.


<details>
  <summary>Details</summary>
Motivation: Chemical bonding is valuable for predicting materials properties but hasn't been integrated into ML pipelines at scale due to lack of systematic bonding databases.

Method: Extended Quantum-Chemical Bonding Database to ~13,000 materials, derived new bonding descriptors, used statistical significance tests to evaluate their impact on ML models predicting elastic, vibrational, and thermodynamic properties.

Result: Bonding descriptors improve predictive performance and help identify intuitive symbolic expressions for properties like projected force constant and lattice thermal conductivity.

Conclusion: Quantum-chemical bonding descriptors enhance ML models for materials science and provide interpretable insights through symbolic regression.

Abstract: Most machine learning models for materials science rely on descriptors based on materials compositions and structures, even though the chemical bond has been proven to be a valuable concept for predicting materials properties. Over the years, various theoretical frameworks have been developed to characterize bonding in solid-state materials. However, integrating bonding information from these frameworks into machine learning pipelines at scale has been limited by the lack of a systematically generated and validated database. Recent advances in high-throughput bonding analysis workflows have addressed this issue, and our previously computed Quantum-Chemical Bonding Database for Solid-State Materials was extended to include approximately 13,000 materials. This database is then used to derive a new set of quantum-chemical bonding descriptors. A systematic assessment is performed using statistical significance tests to evaluate how the inclusion of these descriptors influences the performance of machine-learning models that otherwise rely solely on structure- and composition-derived features. Models are built to predict elastic, vibrational, and thermodynamic properties typically associated with chemical bonding in materials. The results demonstrate that incorporating quantum-chemical bonding descriptors not only improves predictive performance but also helps identify intuitive expressions for properties such as the projected force constant and lattice thermal conductivity via symbolic regression.

</details>


### [48] [Bond failure in peridynamics: Nonequivalence of critical stretch and critical energy density criteria](https://arxiv.org/abs/2602.12061)
*Pablo Seleson,Pablo Raúl Stinga,Mary Vaughan*

Main category: cond-mat.mtrl-sci

TL;DR: The paper proves that two common bond-failure criteria in peridynamic fracture modeling (critical stretch vs critical energy density) are not equivalent and produce different fracture behaviors.


<details>
  <summary>Details</summary>
Motivation: To rigorously analyze and compare two fundamental bond-failure criteria in peridynamic theory, as understanding their differences is crucial for accurate fracture modeling in solid mechanics.

Method: Analytical mathematical proof and numerical simulations comparing critical stretch criterion (bonds fail at specific stretch value) and critical energy density criterion (bonds fail when energy density exceeds threshold) in bond-based peridynamic models.

Result: Mathematically proves the two criteria are not equivalent in general, and numerical examples demonstrate striking differences in crack dynamics including crack tip evolution, propagation patterns, and branching behavior.

Conclusion: The choice between critical stretch and critical energy density criteria significantly impacts fracture modeling outcomes, highlighting the importance of careful criterion selection in peridynamic simulations of material failure.

Abstract: This paper rigorously analyzes bond failure in the peridynamic theory of solid mechanics, which is a fundamental component of fracture modeling. We compare analytically and numerically two common bond-failure criteria:~{\em critical stretch} and~{\em critical energy density}. In the former, bonds fail when they stretch to a critical value, whereas in the latter, bonds fail when the bond energy density exceeds a threshold. By focusing the analysis on bond-based models, we prove mathematically that the critical stretch criterion and the critical energy density criterion are not equivalent in general and result in different bond-breaking and fracture phenomena. Numerical examples showcase the striking differences between the effect of the two criteria on crack dynamics, including the crack tip evolution, crack propagation, and crack branching.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [49] [Quantifying the effect of graph structure on strong Feller property of SPDEs](https://arxiv.org/abs/2602.11484)
*Jianbo Cui,Tonghe Dang,Jialin Hong,Zhengkai Wang*

Main category: math.PR

TL;DR: SPDEs on tree graphs with space-time white noise: graph structure affects strong Feller property and irreducibility; noise-free edges have sharp bounds; chain graphs need noise on any single edge, star graphs allow at most one noise-free edge; dissipative condition ensures unique invariant measure with exponential ergodicity.


<details>
  <summary>Details</summary>
Motivation: To understand how graph topology influences SPDE behavior on finite tree graphs with edge-driven noise, particularly regarding ergodic properties like strong Feller property and irreducibility.

Method: Introduces graph-based null decomposition approach; examines zero entries in graph Laplacian eigenfunctions; establishes bounds on noise-free edges; analyzes chain and star graphs as special cases; proves results under dissipative conditions.

Result: Sharp upper bound on noise-free edges for strong Feller property and irreducibility; chain graphs require noise on any single edge; star graphs allow at most one noise-free edge; existence and exponential ergodicity of unique invariant measure under dissipative condition.

Conclusion: Graph structure crucially determines SPDE ergodic properties on trees; noise distribution across edges has precise requirements; dissipative systems converge to unique invariant measure exponentially fast.

Abstract: This paper investigates how the structure of the underlying graph influences the behavior of stochastic partial differential equations (SPDEs) on finite tree graphs, where each edge is driven by space-time white noise. We first introduce a novel graph-based null decomposition approach to analyzing the strong Feller property of the Markov semigroup generated by SPDEs on tree graphs. By examining the positions of zero entries in eigenfunctions of the graph Laplacian operator, we establish a sharp upper bound on the number of noise-free edges that ensures both the strong Feller property and irreducibility. Interestingly, we find that the addition of noise to any single edge is sufficient for chain graphs, whereas for star graphs, at most one edge can remain noise-free without compromising the system's properties. Furthermore, under a dissipative condition, we prove the existence and exponential ergodicity of a unique invariant measure.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [50] [Intermediate Thermal Equilibrium Stages in Molecular Dynamics Simulations of two Bodies in Contact](https://arxiv.org/abs/2602.11489)
*Jonathas N. da Silva,Octavio D. Rodriguez Salmon,Minos A. Neto*

Main category: cond-mat.stat-mech

TL;DR: Molecular dynamics simulations analyze intermediate stages of thermal equilibrium between ideal gases, showing how heat conduction influences time to reach equilibrium according to the Zeroth Law of Thermodynamics.


<details>
  <summary>Details</summary>
Motivation: To go beyond just studying the final equilibrium state and examine the detailed intermediate stages leading to thermal equilibrium between systems, specifically investigating how heat conduction influences the time to reach equilibrium in accordance with the Zeroth Law of Thermodynamics.

Method: Classical molecular dynamics simulations of two- and three-region models with argon atoms, analyzing fluctuations, correlations, and temperature distributions during the approach to equilibrium.

Result: The study reveals detailed intermediate stages of thermal equilibrium, showing how heat conduction between regions influences the time to reach equilibrium, with observations of fluctuations, correlations, and temperature distributions during the process.

Conclusion: The work provides a detailed analysis of the intermediate stages leading to thermal equilibrium, demonstrating how heat conduction affects the equilibration process and validating the Zeroth Law of Thermodynamics through molecular dynamics simulations.

Abstract: The Zeroth Law of Thermodynamics states that if two systems are in thermal equilibrium with a third one, then they are also in equilibrium with each other. This study explores not only the final state of thermal equilibrium between ideal gases separated by heat-conducting walls, but also the intermediate stages leading up to equilibrium, using classical molecular dynamics simulations. Two- and three-region models with argon atoms are analyzed. Fluctuations, correlations, and temperature distributions are observed, highlighting how heat conduction between regions influences the time to reach equilibrium. This work is distinguished by its detailed analysis of the intermediate stages that occur until the system reaches thermal equilibrium, in accordance with the Zeroth Law of Thermodynamics.

</details>


<div id='math-ph'></div>

# math-ph [[Back]](#toc)

### [51] [On the interaction between a rigid-body and a viscous-fluid: existence of a weak solution and a suitable Théorème de Structure](https://arxiv.org/abs/2602.11787)
*Paolo Maremonti,Filippo Palma*

Main category: math-ph

TL;DR: Existence and partial regularity of weak solutions for rigid body-fluid interaction in body-attached frame, with new techniques for Navier-Stokes problems.


<details>
  <summary>Details</summary>
Motivation: To study the interaction between a rigid body and viscous incompressible Newtonian fluid, particularly addressing analytical challenges in the body-attached reference frame where the term ω×x·∇u appears in momentum equations.

Method: Using a frame attached to the rigid body, developing new analytical techniques different from standard Navier-Stokes approaches to handle the rotational term ω×x·∇u, proving existence of weak solutions and providing a new proof of Leray's Structure Theorem.

Result: Proved existence of weak solutions and obtained partial regularity, but only for large times (weaker than Leray's result). Provided original existence proof and new proof of Leray's Structure Theorem.

Conclusion: The body-attached frame approach requires novel techniques for fluid-body interaction problems, yielding existence and partial regularity results, though with temporal limitations compared to classical Navier-Stokes regularity theory.

Abstract: In this paper, we prove the existence and a partial regularity of a weak solution to the system governing the interaction between a rigid body and a viscous incompressible Newtonian fluid. The evolution of the system body-fluid is studied in a frame attached to the body. The choice of this special frame becomes critical from an analytical point of view due to the presence of the term $ω\times x\cdot\nabla u$ in the balance of momentum equation for the fluid. As a consequence, we are forced to look for a technique that is different from the ones usually employed both for the existence and for the partial regularity of a weak solution to the Navier-Stokes problem. Hence, we prove the existence of a weak solution in an original way and give a new proof of the celebrated Théorème de Structure due to Leray. However, the regularity obtained for our weak solution is only for large times, hence our result is weaker compared to the one obtained by Leray.

</details>
