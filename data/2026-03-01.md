<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 7]
- [math.AP](#math.AP) [Total: 21]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [physics.plasm-ph](#physics.plasm-ph) [Total: 6]
- [math.DG](#math.DG) [Total: 1]
- [astro-ph.SR](#astro-ph.SR) [Total: 1]
- [quant-ph](#quant-ph) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 1]
- [astro-ph.CO](#astro-ph.CO) [Total: 1]
- [cs.SC](#cs.SC) [Total: 1]
- [cs.AI](#cs.AI) [Total: 1]
- [physics.space-ph](#physics.space-ph) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]
- [physics.optics](#physics.optics) [Total: 1]
- [math.PR](#math.PR) [Total: 1]
- [cs.CV](#cs.CV) [Total: 2]
- [astro-ph.HE](#astro-ph.HE) [Total: 1]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 1]
- [cs.MS](#cs.MS) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [A Reduced Order Model approach for First-Principles Molecular Dynamics Computations](https://arxiv.org/abs/2602.22390)
*Siu Wun Cheung,Youngsoo Choi,Jean-Luc Fattebert,Jonas Kaufman,Daniel Osei-Kuffuor*

Main category: math.NA

TL;DR: Data-driven framework bypasses iterative wavefunction optimization in DFT by using pre-sampled configurations to build reduced basis for efficient ground state determination.


<details>
  <summary>Details</summary>
Motivation: To exploit redundancy in electronic structure computations during molecular dynamics and avoid computationally expensive iterative wavefunction optimization in Kohn-Sham DFT.

Method: Sample representative atomic configurations a priori, construct low-dimensional basis approximating electronic structure subspace, use reduced basis in direct solver for electronic density matrix.

Result: Accurately reproduces structural properties (bond lengths, bond angle) of water molecule in Born-Oppenheimer MD compared to full first-principles MD.

Conclusion: Data-driven approaches show potential for developing efficient electronic structure solvers for first-principles simulations by bypassing iterative optimization.

Abstract: To leverage the redundancy between the electronic structure computed at each step of first-principles molecular dynamics, we present a data-driven modeling framework for Kohn-Sham Density Functional Theory that bypasses the explicit optimization of electronic wavefunctions. We sample a priori representative atomic configurations and construct a low-dimensional basis that efficiently approximates the electronic structure subspace. Subsequently, we employ this reduced basis in a direct solver for the electronic single particle density matrix, thereby enabling the efficient determination of ground state without iterative wavefunction optimization. We demonstrate the efficacy of our approach in a Born-Oppenheimer molecular dynamics of a water molecule, showing that the resulting simulations accurately reproduce key structural properties, such as bond lengths and bond angle, obtained from full first-principles molecular dynamics. This work highlights the potential of data-driven approaches to develop efficient electronic structure solvers for first-principles simulations.

</details>


### [2] [Error Analysis of Parameter Prediction via Gaussian Process Regression and Its Application to Weighted Jacobi Iteration](https://arxiv.org/abs/2602.22679)
*Tiantian Sun,Juan Zhang*

Main category: math.NA

TL;DR: Novel theoretical framework for Gaussian process regression error analysis using function-space decomposition, leading to weighted Jacobi iterative method with GP-based parameter prediction and convergence analysis.


<details>
  <summary>Details</summary>
Motivation: To develop a more general theoretical framework for analyzing Gaussian process regression errors and create an accelerated iterative method by combining GP regression with Jacobi iterations.

Method: Function-space decomposition framework for GP regression error analysis, weighted Jacobi iterative method using GP regression for parameter prediction, and convergence analysis with compatible error bounds.

Result: GP-predicted parameters significantly accelerate Jacobi iteration convergence speed, and the framework enables more general analysis through compatible convergence conditions.

Conclusion: The proposed framework successfully integrates GP regression with iterative methods, providing both theoretical analysis and practical acceleration benefits for convergence.

Abstract: In this paper, we introduce a novel theoretical framework for Gaussian process regression error analysis, leveraging a function-space decomposition. Based on this framework, we develop a weighted Jacobi iterative method that utilizes Gaussian process regression for parameter prediction and provide a corresponding convergence analysis. Moreover, the convergence conditions are designed to be compatible with other error bounds, enabling a more general analysis. Experimental results show that the parameters predicted based on Gaussian process regression significantly accelerate the convergence speed of Jacobi iterations.

</details>


### [3] [Comparison of Structure-Preserving Methods for the Cahn-Hilliard-Navier-Stokes Equations](https://arxiv.org/abs/2602.22861)
*Jimmy Kornelije Gunnarsson,Robert Klöfkorn*

Main category: math.NA

TL;DR: Structure-preserving DG methods for Cahn-Hilliard-Navier-Stokes with degenerate mobility, featuring enhanced coercivity-stability control and optimal convergence while preserving key physical properties.


<details>
  <summary>Details</summary>
Motivation: To develop robust numerical methods for coupled Cahn-Hilliard-Navier-Stokes systems with degenerate mobility that preserve essential physical properties (mass conservation, energy dissipation, maximum principle) while maintaining computational efficiency.

Method: Proposed SWIPD-L and SIPGD-L discontinuous Galerkin methods with parametrized mobility fluxes and edge-wise mobility treatments for enhanced coercivity-stability control. Methods incorporate generalized trilinear form and prove coercivity properties.

Result: Proved coercivity for generalized trilinear form, demonstrated optimal convergence rates while preserving mass conservation, energy dissipation, and discrete maximum principle. Comparisons show similar stability to existing SIPG-L and SWIP-L methods. Validation on hp-adaptive meshes shows significant computational savings without accuracy loss.

Conclusion: The developed structure-preserving DG methods successfully handle degenerate mobility in Cahn-Hilliard-Navier-Stokes systems, maintaining physical properties while achieving computational efficiency through hp-adaptive meshes and optimal convergence rates.

Abstract: We develop structure-preserving discontinuous Galerkin methods for the Cahn-Hilliard-Navier-Stokes equations with degenerate mobility. The proposed SWIPD-L and SIPGD-L methods incorporate parametrized mobility fluxes with edge-wise mobility treatments for enhanced coercivity-stability control. We prove coercivity for the generalized trilinear form and demonstrate optimal convergence rates while preserving mass conservation, energy dissipation, and the discrete maximum principle. Comparisons with existing SIPG-L and SWIP-L methods confirm similar stability. Validation on $hp$-adaptive meshes for both standalone Cahn-Hilliard and coupled systems shows significant computational savings without accuracy loss.

</details>


### [4] [A Reduced Magnetic Vector Potential Approach with Higher-Order Splines](https://arxiv.org/abs/2602.22997)
*Merle Backmeyer,Laura A. M. D'Angelo,Brahim Ramdane,Sebastian Schöps*

Main category: math.NA

TL;DR: High-order isogeometric method for magnetoquasistatic eddy-current problems using Biot-Savart-driven source fields and finite-element reaction fields, avoiding coil meshing and enabling high-order field approximation.


<details>
  <summary>Details</summary>
Motivation: To develop an efficient high-order formulation for magnetoquasistatic eddy-current problems that avoids the computational burden of coil meshing while supporting arbitrary winding paths and achieving high-order accuracy.

Method: Decomposition into Biot-Savart-driven source fields and finite-element reaction fields, generalization of reduced magnetic vector potential framework to quasistatic regime, consistent high-order spline discretization, and surface-only Biot-Savart evaluation.

Result: Method avoids coil meshing, supports arbitrary winding paths, enables high-order field approximation within reduced computational domain, establishes optimal convergence rates, and identifies practical requirements for high-order accuracy.

Conclusion: The proposed high-order isogeometric formulation successfully addresses magnetoquasistatic eddy-current problems with practical advantages, though achieving high-order accuracy requires careful attention to geometric regularity, accurate kernel quadrature, and compatible trace spaces.

Abstract: This work presents a high-order isogeometric formulation for magnetoquasistatic eddy-current problems based on a decomposition into Biot-Savart-driven source fields and finite-element reaction fields. Building upon a recently proposed surface-only Biot-Savart evaluation, we generalize the reduced magnetic vector potential framework to the quasistatic regime and introduce a consistent high-order spline discretization. The resulting method avoids coil meshing, supports arbitrary winding paths, and enables high-order field approximation within a reduced computational domain. Beyond establishing optimal convergence rates, the numerical investigation identifies the requirements necessary to recover high-order accuracy in practice, including geometric regularity of the enclosing interface, accurate kernel quadrature, and compatible trace spaces for the source-reaction coupling.

</details>


### [5] [Nearest Reversible Markov Chains with Sparsity Constraints: An Optimization Approach](https://arxiv.org/abs/2602.23059)
*Stefano Cipolla,Fabio Durastante,Miryam Gnazzo,Beatrice Meini*

Main category: math.NA

TL;DR: Formulates non-reversible Markov chain approximation as a matrix nearness problem with sparsity constraints, solved via quadratic programming.


<details>
  <summary>Details</summary>
Motivation: Many applications produce non-reversible Markov chains, but reversibility is crucial for algorithms like Metropolis-Hastings and MCMC methods, creating a need to approximate non-reversible chains with reversible ones while preserving sparsity patterns.

Method: Formulates the approximation as a matrix nearness problem for sparse transition matrices, resulting in a quadratic programming optimization problem that minimizes modifications while enforcing reversibility and sparsity constraints.

Result: Numerical experiments demonstrate the effectiveness of the approach in approximating non-reversible Markov chains with reversible ones while maintaining sparsity patterns.

Conclusion: Provides a principled framework for enforcing reversibility and sparsity in Markov chains with applications in MCMC, computational chemistry, and data-driven modeling.

Abstract: Reversibility is a key property of Markov chains, central to algorithms such as Metropolis-Hastings and other MCMC methods. Yet many applications yield non-reversible chains, motivating the problem of approximating them by reversible ones with minimal modification. We formulate this task as a matrix nearness problem and focus on the practically relevant case of sparse transition matrices. The resulting optimization problem is a quadratic programming problem, and numerical experiments illustrate the effectiveness of the approach. This framework provides a principled way to enforce reversibility and sparsity patterns in Markov chains with applications in MCMC, computational chemistry, and data-driven modeling.

</details>


### [6] [A Hyperbolic Transport Model for Passenger Flow on Tram Networks](https://arxiv.org/abs/2602.23081)
*Thomas Schillinger*

Main category: math.NA

TL;DR: Urban tram network modeling using hyperbolic PDE for passenger transport coupled with stochastic boarding processes, analyzed with measure-valued solutions and uncertainty assessment.


<details>
  <summary>Details</summary>
Motivation: To develop a comprehensive mathematical framework for modeling urban tram networks that captures both deterministic transport dynamics and stochastic passenger behavior, while assessing system robustness under uncertainties.

Method: Hyperbolic partial differential equation for passenger transport along network + family of stochastic processes for passenger boarding; solutions considered in measure-valued sense; extended with uncertainties (delays, service interruptions) in numerical study; robustness assessed using risk measures.

Result: Developed a modeling framework that combines deterministic transport dynamics with stochastic passenger processes, enabling analysis of tram network behavior under uncertainty through numerical studies and risk assessment.

Conclusion: The proposed framework provides a robust mathematical foundation for analyzing urban tram networks under uncertainty, combining PDE-based transport modeling with stochastic processes for comprehensive system assessment.

Abstract: We introduce a modeling framework for an urban tram network based on a hyperbolic partial differential equation describing the transport of passengers along the network, coupled with a family of stochastic processes representing passenger boarding. Solutions are considered in a measure-valued sense. The system is further extended and subjected to uncertainties such as delays and service interruptions through a numerical study. Its robustness is assessed using appropriate risk measures.

</details>


### [7] [On the choice of viscous discontinuous Galerkin discretization for entropy correction artificial viscosity methods](https://arxiv.org/abs/2602.23210)
*Samuel Q. Van Fleet,Jesse Chan*

Main category: math.NA

TL;DR: ECAV is an entropy-corrected artificial viscosity method using LDG discretization with O(h) coefficient bound and contact-preserving properties.


<details>
  <summary>Details</summary>
Motivation: To develop an artificial viscosity method that enforces semi-discrete entropy inequality while avoiding restrictive time-step conditions and preserving contact discontinuities.

Method: Entropy correction artificial viscosity (ECAV) discretized using local discontinuous Galerkin (LDG) method with analysis of coefficient bounds.

Result: Proved O(h) upper bound on ECAV coefficient (no restrictive time-step), showed ECAV is contact preserving, and compared to traditional shock capturing methods.

Conclusion: ECAV with LDG discretization provides effective entropy stabilization without restrictive time-step constraints while maintaining contact discontinuity preservation.

Abstract: Entropy correction artificial viscosity (ECAV) is an approach for enforcing a semi-discrete entropy inequality through an entropy dissipative correction term. The resulting method can be implemented as an artificial viscosity with an extremely small viscosity coefficient. In this work, we analyze ECAV when the artificial viscosity is discretized using a local discontinuous Galerkin (LDG) method. We prove an $O(h)$ upper bound on the ECAV coefficient, indicating that ECAV does not result in a restrictive time-step condition. We additionally show that ECAV is contact preserving, and compare ECAV to traditional shock capturing artificial viscosity methods.

</details>


<div id='math.AP'></div>

# math.AP [[Back]](#toc)

### [8] [Weak Diffeomorphisms and Extremals for Scalar Conservation Laws](https://arxiv.org/abs/2602.22467)
*Prerona Dutta,Barbara Lee Keyfitz*

Main category: math.AP

TL;DR: The paper shows that particle paths (Lagrangian trajectories) for scalar conservation laws are geodesics in the space of diffeomorphisms, and extends this representation to some systems like isentropic gas dynamics.


<details>
  <summary>Details</summary>
Motivation: To establish a geometric interpretation of conservation laws by showing that particle paths correspond to geodesics in the diffeomorphism group, providing a deeper understanding of the Lagrangian formulation.

Method: Uses Lagrangian (particle path) formulation of scalar conservation laws, relates solutions to Cauchy problems on diffeomorphism groups, and demonstrates that particle paths are extremals of action functionals (geodesics) in the space of diffeomorphisms.

Result: Proves that for scalar conservation laws, particle paths are geodesics in some metric on the diffeomorphism group, and shows this representation extends to systems like isentropic gas dynamics.

Conclusion: The Lagrangian formulation of conservation laws has a geometric interpretation where particle paths correspond to geodesics in the diffeomorphism group, analogous to the Lie group-Lie algebra correspondence, providing insight into both scalar and some system conservation laws.

Abstract: Scalar conservation laws in one space variable allow a Lagrangian (particle path) formulation. The Lagrangian trajectory in the infinite-dimensional group of diffeomorphisms on the physical space can be written as a system of conservation laws. The relation between solutions of the Cauchy problem for the conservation law and solutions of the corresponding Cauchy problem on the diffeomorphism group extends to weak solutions of the coresponding problems. The correspondence between particle paths and transport equations is analogous to that between a Lie group and the corresponding Lie algebra.
  This paper establishes that for scalar conservation laws the particle paths are extremals of an action functional on the space of diffeomorphisms; that is, they are geodesics in some metric. In some examples of systems of conservation laws, including the physical example of isentropic gas dynamics in one space dimension, diffeomorphism representations also exist and may be interpreted as extremals of action functionals.

</details>


### [9] [The global well-posedness of the multi-dimensional compressible Euler system with damping in the $L^p$ critical Besov spaces for $p<2$](https://arxiv.org/abs/2602.22550)
*Jianzhong Zhang,Ying Sui,Xiliang Li*

Main category: math.AP

TL;DR: Global well-posedness of compressible Euler system with damping in L^p-type critical Besov spaces for 1≤p<2


<details>
  <summary>Details</summary>
Motivation: To establish global-in-time well-posedness for the compressible Euler system with damping in critical Besov spaces, extending beyond the classical L^2 framework to L^p-type spaces

Method: Develop a new product estimate in L^2-L^p hybrid Besov spaces to handle the nonlinear terms in the compressible Euler system with damping

Result: Proved global well-posedness in L^p-type critical Besov spaces for 1≤p<2, overcoming technical challenges through the new hybrid Besov space product estimate

Conclusion: The compressible Euler system with damping admits global solutions in L^p-type critical Besov spaces for 1≤p<2, enabled by novel product estimates in hybrid spaces

Abstract: In this paper, we study the Cauchy's problem of the compressible Euler system with damping and establish the global-in-time well-posedness in $L^p$-type critical Besov spaces for $1\leq p<2$. To achieve it, a new product estimate is established in $L^2$-$L^p$ hybrid Besov spaces.

</details>


### [10] [Global three-dimensional subsonic Euler flows past an axisymmetric obstacle with large vorticity](https://arxiv.org/abs/2602.22598)
*Dehua Wang,Tian-Yi Wang,Weiqiang Wang*

Main category: math.AP

TL;DR: Existence and uniqueness of subsonic Euler flows past axisymmetric obstacles with prescribed upstream axial velocities, requiring upstream density above critical threshold.


<details>
  <summary>Details</summary>
Motivation: To establish rigorous mathematical results for steady Euler flows past axisymmetric obstacles, extending beyond previous two-dimensional results to handle flows with large vorticity.

Method: Combines strong maximum principle with refined continuity argument to prove non-degeneracy of axial velocity, uses uniform integral estimates for asymptotic behavior analysis.

Result: Proves existence and uniqueness of subsonic solutions for broad class of prescribed positive axial velocities, provided upstream density exceeds critical threshold; accommodates flows with large vorticity under structural condition.

Conclusion: Establishes rigorous mathematical framework for axisymmetric Euler flows, extending previous two-dimensional results and handling more complex flow conditions including large vorticity.

Abstract: In this paper, we prove the existence and uniqueness of subsonic solutions to the steady Euler flows past a smooth, axisymmetric obstacle. Specifically, for a broad class of prescribed positive axial velocities in the upstream, the subsonic Euler flow exists provided that the upstream density exceeds a critical threshold. The non-degeneracy of the axial velocity is rigorously established by combining the strong maximum principle with a refined continuity argument. The asymptotic behavior of the flow is obtained from uniform integral estimates for the difference between the flow and the upstream state. In addition, this result accommodates flows with large vorticity under a structural condition, thereby differing from previous results in the two-dimensional case.

</details>


### [11] [Uniform Stability of Oscillatory Shocks for KdV-Burgers Equation](https://arxiv.org/abs/2602.22652)
*Geng Chen,Namhyun Eun,Moon-Jin Kang,Yannan Shen*

Main category: math.AP

TL;DR: The paper analyzes viscous-dispersive shock profiles with infinite oscillations in the KdVB equation, establishing structural properties and proving L² contraction stability under large perturbations.


<details>
  <summary>Details</summary>
Motivation: To understand the detailed structure and stability properties of shock wave solutions with infinite oscillations in the Korteweg-de Vries-Burgers equation, particularly focusing on how these properties relate to viscosity and dispersion coefficients.

Method: First establishes detailed structures of the shock wave, including convergence rates of local extrema. Then exploits these structural properties to prove L² contraction property under arbitrarily large perturbations, incorporating time-dependent shift functions.

Result: Proves both time-asymptotic stability and uniform stability with respect to viscosity and dispersion coefficients. The uniformity enables zero viscosity-dispersion limits to be established.

Conclusion: The KdVB equation's viscous-dispersive shock profiles with infinite oscillations exhibit robust stability properties that hold uniformly across viscosity and dispersion parameters, allowing for rigorous limiting behavior as these parameters approach zero.

Abstract: In this paper, we study the viscous-dispersive shock profile with infinite oscillations of the Korteweg-de Vries-Burgers (KdVB) equation. First, we establish detail structures of the shock wave, including the rate at which the local extrema converge to the left end state towards the left far field. Then, by exploiting the structural properties of the shock, we show the $L^2$ contraction property of the shock profile under arbitrarily large perturbations, up to a time-dependent shift. This result implies both time-asymptotic stability and uniform stability with respect to the viscosity and dispersion coefficients. This uniformity yields zero viscosity-dispersion limits.

</details>


### [12] [Circle-like concentrated solutions for two-component Bose-Einstein condensates](https://arxiv.org/abs/2602.22672)
*Qidong Guo,Qiaoqiao Hua,Chongyang Tian*

Main category: math.AP

TL;DR: The paper studies normalized solutions for a two-component BEC system with L² constraint, proving existence of synchronized solutions that concentrate on high-dimensional subsets (circles) in ℝ² using finite-dimensional reduction and local Pohozaev identities.


<details>
  <summary>Details</summary>
Motivation: To investigate normalized solutions of two-component Bose-Einstein condensates systems with L² constraint, addressing gaps in understanding high-dimensional concentrated normalized solutions for such systems.

Method: Finite-dimensional reduction method combined with local Pohozaev identities to construct vector radial solutions that concentrate on circles when specific parameter ratios tend to zero.

Result: Existence of synchronized solutions concentrating on high-dimensional subsets (circles) in ℝ² for any α>0, γ>0 and β in specified ranges, filling the blank for high-dimensional concentrated normalized solutions in the system.

Conclusion: The paper successfully establishes existence results for normalized solutions in two-component BEC systems that concentrate on circles, addressing previously unexplored high-dimensional concentration phenomena in such systems.

Abstract: We investigate the normalized solutions of the following two-component Bose-Einstein condensates (BEC) system
  \begin{equation}\left\{ \begin{split}
  -Δu + (λ+P(x))u &= αu^3 +βuv^2, && \text{in } \mathbb{R}^2,\\-Δv + (λ+Q(x))v &= γv^3 +βu^2 v, && \text{in } \mathbb{R}^2, \end{split} \right.\end{equation}
  with $L^2$-constraint $$\int_{\mathbb{R}^2}(u^2+v^2)\,dx = 1.$$ For any $α>0$, $γ> 0$ and $\ β\in (-\sqrt{αγ},0)\cup(0,\min \{α,γ\})\cup \left(\max \{α,γ\} , + \infty\right)$, we establish the existence of synchronized solutions concentrating on high-dimensional subsets of $\mathbb{R}^2$ by employing a finite-dimensional reduction method combined with some local Pohozaev identities. More precisely, we construct vector radial solutions that concentrate on circles when $ \frac{α+ γ- 2β}{αγ- β^2}$ tends to zero. Our results fill the blank in the system for high-dimensional concentrated normalized solutions.

</details>


### [13] [Generically sharp decay and blowing up at infinity for a weak null wave system](https://arxiv.org/abs/2602.22749)
*Shijie Dong,Siyuan Ma,Yue Ma,Xu Yuan*

Main category: math.AP

TL;DR: The paper establishes sharp pointwise decay estimates for solutions to semilinear wave equations satisfying the weak null condition, showing both upper and lower bounds, and applies these estimates to demonstrate energy blow-up at infinity and energy cascade phenomena.


<details>
  <summary>Details</summary>
Motivation: To understand the long-time behavior of solutions to semilinear wave equations that satisfy the weak null condition, which serve as simplified models for the Einstein vacuum equations. The goal is to obtain precise decay estimates that can reveal phenomena like energy blow-up at infinity and energy cascade.

Method: The authors study a system of semilinear wave equations satisfying the weak null condition. They establish precise pointwise decay estimates (both lower and upper bounds) for small data solutions by analyzing the difference between the solution and its leading-order term, showing it's dominated by faster-decaying lower-order terms in the retarded time variable u = t - r.

Result: 1) Sharp pointwise decay estimates are proven for generic small initial data decaying sufficiently fast. 2) One component of the solution generically exhibits energy that grows to infinity as t → +∞ ("blowing up at infinity"). 3) This component also generically shows energy cascade from high to low frequencies.

Conclusion: The paper successfully establishes sharp decay estimates for semilinear wave equations with weak null condition, revealing important long-time dynamical behaviors including energy blow-up at infinity and energy cascade phenomena, providing insights into similar behaviors in the Einstein vacuum equations.

Abstract: We study a system of semilinear wave equations satisfying the weak null condition, which can be regarded as a simplified model for the Einstein vacuum equations. The main objective is to establish precise pointwise decay estimates, as both lower and upper bounds of decay, for small data solutions. Specifically, we show that the difference between the solution and its leading-order term is dominated by lower-order terms that decay faster in the retarded time variable $u=t-r$. Moreover, we prove that these pointwise decay estimates are sharp for a generic class of small initial data decaying sufficiently fast.
  As applications of these estimates, we demonstrate that the energy of one component of the solution admits a lower bound that generically grows to infinity as $t\to +\infty$, which can be interpreted as ``blowing up at infinity." Furthermore, we verify that this component generically exhibits an energy cascade from high to low frequencies.

</details>


### [14] [The regularity of the boundary of vortex patches for the quasi-geostrophic shallow-water equations](https://arxiv.org/abs/2602.22767)
*Marc Magaña,Joan Mateu,Joan Orobitg*

Main category: math.AP

TL;DR: Persistence of boundary smoothness for vortex patches in quasi-geostrophic shallow-water equations and convergence to Euler solutions as Rossby radius parameter ε→0.


<details>
  <summary>Details</summary>
Motivation: The QGSW equations generalize Euler equations with Rossby radius parameter ε⁻¹, modifying streamfunction-vorticity relationship. Need to understand persistence of boundary smoothness for vortex patches in this more complex system.

Method: Prove persistence of boundary smoothness for vortex patches in QGSW equations. Also prove convergence of QGSW solutions to Euler solutions as ε→0 in little Hölder spaces locally in time.

Result: Successfully prove both persistence of boundary smoothness for vortex patches in QGSW equations and convergence of QGSW solutions to Euler solutions as ε→0 in little Hölder spaces locally in time.

Conclusion: QGSW vortex patches maintain boundary smoothness, and QGSW equations properly generalize Euler equations with convergence in the limit as Rossby radius parameter ε→0.

Abstract: We prove the persistence of boundary smoothness of vortex patches for the quasi-geostrophic shallow-water (QGSW) equations. The QGSW equations generalize the Euler equations by including an additional parameter, the Rossby radius $\varepsilon^{-1}$, which modifies the relationship between the streamfunction and the (potential) vorticity. In addition, we prove that solutions of the QGSW equations converge locally in time to the corresponding Euler solutions as $\varepsilon \to 0$ in little Hölder spaces.

</details>


### [15] [Long finite time bubble trees for two co-rotational wave maps](https://arxiv.org/abs/2602.22825)
*Joachim Krieger,José M. Palacios*

Main category: math.AP

TL;DR: The paper constructs n-bubble solutions for the energy critical Wave Maps equation in co-rotational setting, showing arbitrarily many concentric collapsing bubbles with alternating signs can occur in finite time blow-up.


<details>
  <summary>Details</summary>
Motivation: To demonstrate that all cases postulated in the soliton resolution theorem for finite time blow-up actually occur, specifically showing that arbitrarily many concentric collapsing bubbles with alternating signs can form in the energy critical Wave Maps equation.

Method: Construct n-bubble solutions for the co-rotational Wave Maps equation (k=2) where bubbles concentrate at different scales λ₁(t) ≫ λ₂(t) ≫ ... ≫ λₙ(t), with λₙ(t) = t⁻¹|log t|^β (β > 3/2), and λⱼ(t) ≳ exp(∫ₜᵗ⁰ λⱼ₊₁(s)ds) for j < n.

Result: Successfully constructed arbitrarily large numbers of concentrating concentric n-bubble profiles, proving that the entirety of cases postulated in the soliton resolution theorem for finite time blow-up indeed occur when concentric collapsing bubbles have alternating signs.

Conclusion: The energy critical Wave Maps equation in co-rotational setting admits arbitrarily many concentric bubble solutions with alternating signs, confirming the full scope of finite time blow-up scenarios predicted by soliton resolution theory.

Abstract: We show that the energy critical Wave Maps equation from $\mathbb{R}^{2+1}$ into $\mathbb{S}^2$, restricted to the $k=2$ co-rotational setting, admits arbitrarily large numbers of concentrating concentric $n$ bubble profiles. For any $n\in\mathbb{N}$, we construct an $n$-bubble solution concentrating at scales $λ_1(t)\gg λ_2(t)\gg \ldots\gg λ_n(t)$, where $λ_n(t)=t^{-1}\vert \log t\vert^β$, and $λ_j(t)\gtrsim \exp( \int_t^{t_0} λ_{j+1}(s)ds)$, for any $j<n$. Here $β>\tfrac32$ is a parameter that can be chosen arbitrarily. This shows that, as far as finite time blow-up case is concerned, the entirety of cases postulated in the soliton resolution theorem indeed occur, provided the concentric collapsing bubbles have alternating signs.

</details>


### [16] [Long-time propagation of coherent states in a normally hyperbolic setting](https://arxiv.org/abs/2602.22834)
*Roméo Taboada*

Main category: math.AP

TL;DR: Extension of semiclassical coherent state evolution beyond the logarithmic time barrier using anisotropic wavepackets localized on normally hyperbolic invariant submanifolds.


<details>
  <summary>Details</summary>
Motivation: To extend the validity of semiclassical approximations for coherent state evolution beyond the logarithmic time constraint |t| ≤ |log h|/(6λ₀) established by Combescure and Robert, allowing descriptions up to Ehrenfest time scales.

Method: Introduces anisotropic wavepackets combining WKB states in transverse hyperbolic directions and squeezed coherent states along a normally hyperbolic invariant submanifold K, where dynamics is slow compared to transverse hyperbolic directions.

Result: Develops a representation valid up to times |t| ≤ C|log h| with larger C (including Ehrenfest time |log h|/(2λ₀)), describing propagated states as microlocalized on isotropic submanifolds rather than single points.

Conclusion: Propagated coherent states beyond logarithmic time scales should be viewed as anisotropic wavepackets localized on normally hyperbolic invariant submanifolds, extending the squeezed state framework to longer time scales.

Abstract: We present a method to find asymptotics for the evolution of coherent states (or Gaussian wavepackets with standard deviation $\sqrt{h}$) under semiclassical Schrödinger's equation for a given Hamiltonian. These results extend the work of Combescure and Robert, in which the evolution of coherent states can be approximated in the limit $h\to 0$ with deformed Gaussian wavepackets called squeezed coherent states. The description with squeezed states holds for times $t$ that can go to infinity as $h\to 0$, under the constraint $|t|\leq |\log h|/(6λ_0)$ where $λ_0$ is the maximal Lyapunov exponent of the classical dynamics. The breakdown of this approximation at time $|\log h|/(6λ_0)$ is related to the bending of evolved wavepackets: once propagated states spread at a scale $h^{1/3}$, squeezed states no longer provide an appropriate description. To obtain a representation of propagated states valid up to times $|t|\leq C|\log h|$ with a larger $C$ (for instance, up to Ehrenfest's time $|\log h|/(2λ_0)$ where spreading on macroscopic scales is allowed), we make additional assumptions on the flow $Φ_t$ associated to the classical dynamics, imposing constraints on directions of elongation. Namely, we work in a neighborhood of a normally hyperbolic $Φ_t$-invariant submanifold $K$, on which the dynamics is considered as slow in comparison with its transverse directions, along which $Φ_t$ is assumed to be hyperbolic. In this context, we describe the propagated state as a WKB state in transverse directions and a squeezed state along $K$. This description emphasizes the fact that propagated states should no longer be thought of as microlocalized on a point, but rather on an isotropic submanifold (corresponding to transverse unstable directions). Guillemin, Uribe, and Wang presented a similar class of wavefunctions microlocalized on an isotropic submanifold.

</details>


### [17] [Orbital stability of monostable waves for reaction-diffusion systems](https://arxiv.org/abs/2602.22907)
*Louis Garénaux*

Main category: math.AP

TL;DR: Proves convergence to shifted profiles for monostable waves in reaction-diffusion systems under optimal topology conditions, using resolvent kernel estimates to handle weakly localized perturbations and construct phase shifts even when translational eigenvalue isn't associated with Evans function zero.


<details>
  <summary>Details</summary>
Motivation: To establish stability results for monostable waves in reaction-diffusion systems, particularly addressing challenges with weakly localized perturbations and situations where the translational eigenvalue isn't directly linked to zeros of the Evans function.

Method: Uses explicit resolvent kernel estimates to analyze stability, handles weakly localized perturbations, constructs phase shifts through analytical techniques, and distinguishes between Evans and Fourier eigenmodes when marginal group velocities are directed toward wave interfaces.

Result: Proves convergence to shifted wave profiles when initial conditions are close to fast wave profiles in optimal topology, successfully handles weakly localized perturbations, and enables phase shift construction even without Evans function zeros associated with translational eigenvalues.

Conclusion: Develops a robust framework for analyzing stability of monostable waves in reaction-diffusion systems, providing new tools for handling challenging perturbation scenarios and clarifying distinctions between different eigenmode types in stability analysis.

Abstract: We study stability of monostable waves for reaction-diffusion systems. When the solution is initially close to a fast wave profile in optimal topology, we prove convergence to a shifted profile. The proof relies on explicit resolvent kernels estimates, allowing to handle weakly localized perturbations. It allows phase shift construction even when the translational eigenvalue is not associated to a zero of the Evans function.
  We further discuss distinction between Evans and Fourier eigenmodes when the marginal group velocity are directed towards the wave interface.

</details>


### [18] [Optimal sets for a geometric oscillation energy](https://arxiv.org/abs/2602.22910)
*Matteo Novaga,Fumihiko Onoue,Emanuele Paolini*

Main category: math.AP

TL;DR: Study of geometric nonlocal energy based on p-oscillation of normal/tangent vectors, with optimal constants from spherical variational problems and characterization of optimal shapes under constraints.


<details>
  <summary>Details</summary>
Motivation: To understand geometric properties of hypersurfaces and curves through a nonlocal energy functional that measures oscillation of unit normals/tangents, establishing optimal geometric inequalities and characterizing extremal shapes.

Method: Define p-oscillation energy for hypersurface normals/curve tangents, derive optimal constants via variational problems over probability measures on spheres, prove existence of optimal sets under perimeter/volume constraints, and characterize their shapes.

Result: Established optimal constants c(n,p) and C(n,p) from spherical variational problems, proved existence of optimal sets under constraints, and characterized extremal shapes that depend critically on p value.

Conclusion: The p-oscillation energy provides a framework for geometric analysis with optimal inequalities, where extremal measures and optimal shapes exhibit p-dependent behavior, offering insights into geometric variational problems.

Abstract: We investigate the nonlocal energy corresponding to the $p$-oscillation of the unit normal vector for hypersurfaces, or the unit tangent vector for curves. The energy satisfies geometric inequalities with optimal constants $c(n,p)$ and $C(n,p)$ which are determined by a variational problem over the probability measures on the sphere. The extremal measures for such problem depend critically on the value of $p$. We prove existence of optimal sets for this energy under perimeter and volume constraint, and characterize their shape.

</details>


### [19] [Refined wave breaking for the generalized Fornberg-Whitham equation](https://arxiv.org/abs/2602.22924)
*Jean-Claude Saut,Yuexun Wang*

Main category: math.AP

TL;DR: The paper studies blow-up solutions in weakly dispersive perturbations of Burgers equation, showing shock formation with C^{1/3} Hölder regularity at a single point.


<details>
  <summary>Details</summary>
Motivation: To understand finite-time blow-up (shock formation) in non-local equations that are weakly dispersive perturbations of the inviscid Burgers equation, particularly the Fornberg-Whitham equation.

Method: Constructs a blowup solution that develops a 'shock-like' singularity (wave breaking) at a single point, using self-similar variables and asymptotic analysis.

Result: The constructed solution converges asymptotically in self-similar variables to a stable self-similar solution of inviscid Burgers equation and exhibits Hölder C^{1/3} regularity at the blowup point.

Conclusion: The paper provides precise characterization of blow-up behavior in these equations, showing that shock formation occurs with specific regularity properties and asymptotic convergence to Burgers equation solutions.

Abstract: This paper considers a class of non-local equations that are weakly dispersive perturbations of the inviscid Burgers equation, which includes the Fornberg-Whitham equation as a special case. We precise the known results on finite time blow-up (shock formation) by constructing a blowup solution which displays a `shock-like' singularity (called wave breaking) at one single point. Moreover, this solution converges asymptotically in the self-similar variables to a stable self-similar solution of the inviscid Burgers equation, and also possesses a Hölder $C^{1/3}$ regularity at the blowup point.

</details>


### [20] [Blow-Up Theory and Liouville-Type Theorem for Solutions of a Class of Generalized Camassa-Holm-Kadomtsev-Petviashvili Equations](https://arxiv.org/abs/2602.22933)
*Xueli Ke,Jiamin Wang,Aibin Zang*

Main category: math.AP

TL;DR: The paper studies blow-up behavior and Liouville-type theorems for generalized CH-KP equations with nonlinear term g(u), establishing blow-up criteria independent of initial data regularity, proving blow-up theorems under bounded g'(u), extending to polynomially controlled cases, and proving uniqueness theorems.


<details>
  <summary>Details</summary>
Motivation: To understand the blow-up behavior and establish Liouville-type theorems for solutions to generalized Camassa-Holm-Kadomtsev-Petviashvili (CH-KP) equations with general nonlinear terms, extending beyond classical cases to more general nonlinearities.

Method: Uses continuation method to establish blow-up criterion independent of initial data regularity. Employs characteristic lines, a priori estimates, and Riccati inequality to prove blow-up theorems under bounded g'(u). Extends results to polynomially controlled g'(u) cases. Establishes Liouville-type uniqueness theorem using specific growth conditions on g(u).

Result: 1) Blow-up criterion independent of initial data regularity. 2) Blow-up theorem and weighted blow-up result under uniformly bounded g'(u). 3) Extension of blow-up results to polynomially controlled g'(u) cases (including classical CH-KP nonlinearities). 4) Liouville-type uniqueness theorem under condition g(u) ≥ γu² with u ≠ 0, g(u) > γu².

Conclusion: The paper successfully establishes comprehensive blow-up criteria and Liouville-type theorems for generalized CH-KP equations with various nonlinearities, providing theoretical foundations for understanding solution behavior including blow-up phenomena and uniqueness properties.

Abstract: We investigate the blow-up behavior and Liouville-type theorems of solutions to a class of generalized Camassa-Holm-Kadomtsev-Petviashvili (CH-KP) equations with a generally smooth nonlinear term $g(u)$. First, using the continuation method, we establish a blow-up criterion that is independent of the regularity index of initial data. Under the assumption that $ g'(u)$ is uniformly bounded, we prove the blow-up theorem and a weighted blow-up result by means of characteristic lines, a priori estimates and the Riccati inequality. Moreover, we extend these blow-up results to the setting where $g'(u)$ is polynomially controlled, which includes typical nonlinearities such as $ g(u)=κu+3u^2 $ for the classical CH-KP equations. Furthermore, a Liouville-type uniqueness theorem is established under the condition $g(u) \geq γu^2$ with $u \neq 0$, $g(u)>γu^2$.

</details>


### [21] [Local boundedness for weak solutions to fractional porous medium equation](https://arxiv.org/abs/2602.23001)
*Filomena De Filippis*

Main category: math.AP

TL;DR: Local boundedness of solutions to fractional porous medium-type equations in fast diffusion regime with optimal tail assumptions


<details>
  <summary>Details</summary>
Motivation: To establish regularity properties (local boundedness) for solutions to fractional porous medium-type equations in the fast diffusion regime, which is important for understanding the behavior of solutions to these nonlinear nonlocal equations.

Method: Mathematical analysis of fractional porous medium-type equations, likely using techniques from partial differential equations, fractional calculus, and regularity theory. The approach involves working under optimal tail assumptions for the solutions.

Result: Proves local boundedness for solutions to fractional porous medium-type equations in the fast diffusion regime under optimal tail assumptions, establishing important regularity properties.

Conclusion: The paper successfully establishes local boundedness results for solutions to fractional porous medium-type equations in fast diffusion regime, which contributes to the regularity theory for these nonlinear nonlocal equations.

Abstract: We establish local boundedness for solutions to fractional porous medium-type equations in the fast diffusion regime, under optimal tail assumptions.

</details>


### [22] [Unique Determination of Variable Order in Subdiffusion from a Single Measurement](https://arxiv.org/abs/2602.23037)
*Jiho Hong,Bangti Jin,Yavar Kian*

Main category: math.AP

TL;DR: Uniqueness results for recovering piecewise constant variable orders in time-fractional diffusion from boundary flux measurements without monotonicity conditions.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the inverse problem of identifying heterogeneous media in anomalous diffusion processes by recovering spatially dependent variable orders from boundary measurements.

Method: Combines harmonic function properties, linearization technique in Laplace domain, and tools from complex, asymptotic, and geometrical analysis.

Result: Establishes several new uniqueness results for piecewise constant variable orders without monotonicity conditions, weakens regularity assumptions, and extends analysis to higher dimensions.

Conclusion: The approach successfully provides uniqueness guarantees for variable order recovery in fractional diffusion models under less restrictive conditions than previous work.

Abstract: We study the inverse problem of recovering a spatially dependent variable order in a time-fractional diffusion model from the boundary flux measurement generated by a single boundary excitation. It arises in the identification of heterogeneous media in anomalous diffusion processes. In this work, we establish several new uniqueness results for the inverse problem in the case of piecewise constant variable orders, without any monotonicity condition. The analysis follows a new approach that combines properties of harmonic functions, a linearization technique in the Laplace domain, and tools from complex, asymptotic, and geometrical analysis. In addition, we weaken the regularity assumptions on the problem data and extend the analysis of previous contributions to higher-dimensional settings.

</details>


### [23] [A Single Equation Explains Go-or-Grow Dynamics in Cyclic Hypoxia](https://arxiv.org/abs/2602.23042)
*Gopinath Sadhu,Philip K Maini,Mohit Kumar Jolly*

Main category: math.AP

TL;DR: A minimal mathematical framework connects go-or-grow tumor dynamics with distinct migratory and proliferative populations to a reduced single-population model with oxygen-dependent diffusion and proliferation under fast phenotypic switching.


<details>
  <summary>Details</summary>
Motivation: To develop a theoretical understanding of how tumor cells exhibiting go-or-grow behavior (migratory vs. proliferative phenotypes) can be mathematically described and potentially simplified for modeling purposes.

Method: Proposed a minimal mathematical framework with two coupled phenotype-specific equations (migratory cells undergoing linear diffusion, proliferative cells with oxygen-dependent proliferation). Explored reduction to a single mixed-phenotype equation under cyclic hypoxia, connecting to a reduced model with oxygen-dependent diffusion and proliferation in fast-phenotypic-switching regime.

Result: Established a theoretical connection between the go-or-grow model with distinct phenotypic populations and a reduced single-cell population model. Validated the reduction through numerical simulations.

Conclusion: The framework successfully connects complex go-or-grow dynamics to simpler mathematical descriptions, providing theoretical validation for reduced models of tumor cell behavior under oxygen-regulated phenotypic switching.

Abstract: We propose a minimal mathematical framework to describe the go-or-grow dynamics of tumor cells comprising two phenotypically distinct populations. One population is migratory and undergoes linear diffusion, while the other proliferates in an oxygen-dependent manner. The local oxygen concentration governs transitions between these phenotypes. We then ask whether these two coupled phenotype-specific equations can be reduced to a single mixed-phenotype equation under cyclic hypoxia. We establish a connection between the minimal go-or-grow model with distinct phenotypic populations and a reduced model describing a single-cell population with oxygen-dependent diffusion and proliferation in the fast-phenotypic-switching regime. This theoretical reduction is validated through numerical simulations.

</details>


### [24] [Local Invariant Structures in the Dynamics of Capillary Water Jet](https://arxiv.org/abs/2602.23064)
*Chengyang Shao,Haocheng Yang*

Main category: math.AP

TL;DR: The paper provides mathematical justification for Rayleigh-Plateau instability in capillary water jets, proving existence of invariant manifolds for Eulerian free-boundary systems.


<details>
  <summary>Details</summary>
Motivation: To mathematically justify experimental observations of Rayleigh-Plateau instability where capillary water jets are exponentially unstable under long-wave perturbations but stable under short-wave perturbations, and to answer Lin-Zeng's question about existence of invariant manifolds for Eulerian free-boundary systems.

Method: Uses irrotational Eulerian free-boundary system with surface tension modeling. Constructs "paradifferential propagator" for linear paradifferential hyperbolic systems along elliptic directions, enabling Lyapunov-Perron type arguments to balance regularity loss in quasilinear problems.

Result: Proves that unstable/stable directions in linearized system correspond to invariant manifolds in full nonlinear system, and elliptic directions correspond to center invariant sets. Provides positive answer to Lin-Zeng's question about invariant manifolds.

Conclusion: Successfully justifies experimental observations of Rayleigh-Plateau instability mathematically, with methodological innovation in paradifferential propagator construction applicable to broader class of PDEs.

Abstract: Physical experiments show that a capillary water jet is exponentially unstable under long-wave perturbations, while remaining stable under short-wave perturbations. Measurements further indicate that the exponential growth rate in the long-wave regime agrees quantitatively with the classical predictions of Rayleigh and Plateau. This phenomenon is known as the \emph{Rayleigh-Plateau instability}. In this paper, we provide a mathematical justification of these experimental observations. The motion of the water jet is modeled by an irrotational Eulerian free-boundary system governed by surface tension. We prove that the (un)stable directions in the linearized system, corresponding to long-wave perturbations, are indeed tangent to an (un)stable invariant manifold of the full nonlinear system. On the other hand, the elliptic directions, corresponding to short-wave perturbations, are indeed tangent to a center invariant set in a generalized sense. These results give a positive answer to the question raised by Lin-Zeng concerning the existence of invariant manifolds for Eulerian free-boundary systems. The major methodological contribution is the construction of ``paradifferential propagator" corresponding to linear paradifferential hyperbolic systems along elliptic directions, making Lyapunov-Perron type arguments applicable. The method effectively balances the loss of regularity in quasilinear problems and can be generalized to a broader class of PDEs.

</details>


### [25] [Viscous vortex crystals](https://arxiv.org/abs/2602.23134)
*Michele Dolce,Martin Donati*

Main category: math.AP

TL;DR: Analysis of 2D Navier-Stokes solutions from co-rotating vortex crystals, controlling solutions up to sub-diffusive timescales before vortex merging.


<details>
  <summary>Details</summary>
Motivation: To understand the behavior of incompressible Navier-Stokes equations with initial conditions consisting of co-rotating vortex configurations (polygonal crystals with/without central vortex), particularly focusing on timescales before vortex merging occurs.

Method: Exploit symmetries and stability properties of the co-rotating vortex crystal system to describe and mathematically control the solution evolution.

Result: Successfully described and controlled the solution up to sub-diffusive time scales, prior to the expected onset of vortex merging.

Conclusion: The study provides rigorous mathematical control of vortex crystal dynamics in 2D Navier-Stokes equations, extending understanding of vortex interactions before merging occurs.

Abstract: We study the solution to the two-dimensional incompressible Navier-Stokes equations arising from a sum of Dirac masses in a particular co-rotating configuration. This configuration consists of a polygonal vortex crystal with or without a central vortex. By exploiting the symmetries and stability properties of the system, we describe and control the solution up to sub-diffusive time scales, prior to the expected onset of vortex merging.

</details>


### [26] [Remarks on the Pogorelov type estimate for the degenerate $k$-Hessian equation](https://arxiv.org/abs/2602.23185)
*Yasheng Lyu*

Main category: math.AP

TL;DR: Pogorelov type estimate for k-Hessian equation under new condition on degenerate right-hand side f


<details>
  <summary>Details</summary>
Motivation: The paper aims to establish Pogorelov type estimates for the k-Hessian equation, which is important for understanding regularity properties of solutions to these nonlinear elliptic equations. The focus is on degenerate cases where the right-hand side f satisfies certain conditions.

Method: The paper likely uses analytical techniques from PDE theory, particularly methods for establishing a priori estimates for solutions to k-Hessian equations. The approach involves imposing a new condition on the degenerate right-hand side function f to derive Pogorelov type estimates.

Result: The paper proves Pogorelov type estimates for the k-Hessian equation under the new condition on f. These estimates provide bounds on the second derivatives of solutions, which are crucial for establishing existence, regularity, and other qualitative properties of solutions.

Conclusion: The new condition on the degenerate right-hand side f enables the derivation of Pogorelov type estimates for k-Hessian equations, contributing to the understanding of regularity properties for these important nonlinear elliptic equations in degenerate cases.

Abstract: This paper investigates the Pogorelov type estimate for the $k$-Hessian equation under a new condition on the degenerate right-hand side $f$.

</details>


### [27] [Low-Mach-number limit of a compressible two-phase flow system with algebraic closure](https://arxiv.org/abs/2602.23189)
*Cassandre Lebot*

Main category: math.AP

TL;DR: The paper analyzes the low Mach number limit for a bi-fluid isentropic compressible Navier-Stokes system, showing convergence to an incompressible non-homogeneous fluid system with transported volume fractions.


<details>
  <summary>Details</summary>
Motivation: To rigorously justify the low Mach number limit for bi-fluid compressible Navier-Stokes systems with equal pressure and single velocity, establishing convergence from compressible to incompressible regimes in two-phase flows.

Method: Introduces suitable modulated quantities and a novel relative entropy functional adapted to the two-phase structure. Uses an original comparison of L1 and L2 norms of partial densities, exploiting the bi-fluid system's special structure, together with a variant of Csiszar-Kullback-Pinsker inequality.

Result: As Mach number tends to zero, partial densities converge to constant states, velocity converges to a divergence-free vector field, recovering the incompressible non-homogeneous fluid system. Volume fractions remain nontrivial and are transported by the limit flow.

Conclusion: The paper rigorously justifies convergence of weak solutions of the compressible system toward solutions of the corresponding incompressible limit system in the low Mach number regime for bi-fluid two-phase flows.

Abstract: We analyse a bi-fluid isentropic compressible Navier-Stokes system with barotropic pressure laws in a two-phase framework with equal pressure and single velocity. We focus on the rigorous analysis of the low Mach number limit under well-prepared initial data. Our main result shows that, as the Mach number tends to zero, the partial densities converge to constant states while the velocity field converges to a divergence-free vector field, and we recover the incompressible non-homogenous fluid system. The volume fractions remain nontrivial and are transported by the limit flow. Our method is based on the introduction of suitable modulated quantities and a novel relative entropy functional adapted to the two-phase structure. The key novelty lies in an original comparison of L1 and L2 norms of the partial densities, exploiting the special structure of the bi-fluid system, together with a variant of Csiszar-Kullback- Pinsker inequality. It allows us to rigorously justify the convergence of weak solutions of the compressible system toward solutions of the corresponding incompressible limit system in the low Mach number regime.

</details>


### [28] [Properties of hypersurface singular sets of solutions to the $σ_k$-Yamabe equation in the negative cone](https://arxiv.org/abs/2602.23190)
*Jonah A. J. Duncan,Luc Nguyen*

Main category: math.AP

TL;DR: Conformally flat Lipschitz viscosity solutions to σₖ-Yamabe equation with smooth hypersurface singularities; analysis of trace/normal derivatives along hypersurface; for k=2, hypersurface is minimal w.r.t. solution.


<details>
  <summary>Details</summary>
Motivation: Study solutions to σₖ-Yamabe equation with hypersurface singularities, which appear in problems like σₖ-Loewner-Nirenberg on annuli. Understand behavior near singularities and geometric properties.

Method: Consider conformally flat Lipschitz viscosity solutions admitting smooth hypersurface singularities. Under natural regularity assumptions, prove PDE for trace and normal derivatives along hypersurface. For k=2, show hypersurface is minimal with respect to solution and analyze formal expansion near hypersurface.

Result: 1) Trace and normal derivatives satisfy certain PDE along hypersurface under regularity assumptions. 2) For k=2, hypersurface is minimal with respect to Lipschitz solution. 3) Address questions about formal expansion near hypersurface.

Conclusion: Solutions to σₖ-Yamabe equation with hypersurface singularities have specific behavior: derivatives satisfy PDE constraints, and for k=2 case, singular hypersurface exhibits minimality property with respect to the solution.

Abstract: We consider conformally flat Lipschitz viscosity solutions to the $σ_k$-Yamabe equation in the negative cone which admit smooth hypersurface singularities. Under natural regularity assumptions (that are satisfied by solutions to the $σ_k$-Loewner-Nirenberg problem on annuli, for example), we first prove that the trace and normal derivatives of such a solution along the hypersurface satisfy a certain PDE. For $k=2$, we also show that the hypersurface is minimal with respect to the Lipschitz solution and address some questions related to the formal expansion of the solution near the hypersurface.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [29] [Adaptive Patching for Tensor Train Computations](https://arxiv.org/abs/2602.22372)
*Gianluca Grosso,Marc K. Ritter,Stefan Rohshap,Samuel Badr,Anna Kauch,Markus Wallerberger,Jan von Delft,Hiroshi Shinaoka*

Main category: physics.comp-ph

TL;DR: Adaptive patching scheme reduces computational costs for Quantics Tensor Train operations by exploiting block-sparse structures through divide-and-conquer partitioning.


<details>
  <summary>Details</summary>
Motivation: Quantics Tensor Train (QTT) operations like matrix product operator contractions become prohibitively expensive for large bond dimensions, limiting practical large-scale QTT-based computations.

Method: Proposed adaptive patching scheme that exploits block-sparse QTT structures using divide-and-conquer approach, adaptively partitioning tensors into smaller patches with reduced bond dimensions.

Result: Demonstrated substantial improvements for sharply localized functions and showed efficient computation of bubble diagrams and Bethe-Salpeter equations.

Conclusion: The adaptive patching scheme opens the door to practical large-scale QTT-based computations that were previously beyond reach by significantly reducing computational costs.

Abstract: Quantics Tensor Train (QTT) operations such as matrix product operator contractions are prohibitively expensive for large bond dimensions. We propose an adaptive patching scheme that exploits block-sparse QTT structures to reduce costs through divide-and-conquer, adaptively partitioning tensors into smaller patches with reduced bond dimensions. We demonstrate substantial improvements for sharply localized functions and show efficient computation of bubble diagrams and Bethe-Salpeter equations, opening the door to practical large-scale QTT-based computations previously beyond reach.

</details>


### [30] [Discovery of Interpretable Physical Laws in Materials via Language-Model-Guided Symbolic Regression](https://arxiv.org/abs/2602.22967)
*Yifeng Guan,Chuyi Liu,Dongzhan Zhou,Lei Bai,Wan-jian Yin,Jingyuan Li,Mao Su*

Main category: physics.comp-ph

TL;DR: A framework using large language models to guide symbolic regression for discovering interpretable physical laws from high-dimensional data, validated on perovskite materials.


<details>
  <summary>Details</summary>
Motivation: Traditional symbolic regression methods often produce complex, unphysical formulas when searching vast spaces of possible forms, making it challenging to discover interpretable physical laws from high-dimensional data.

Method: Introduces a framework that leverages the embedded scientific knowledge of large language models to guide the search process, enabling efficient identification of physical laws while mitigating combinatorial explosion.

Result: The method reduces the effective search space by approximately 10^5 times compared to traditional symbolic regression. Novel formulas for perovskite properties (bulk modulus, band gap, oxygen evolution reaction activity) are identified that are more accurate and simpler than previous formulas.

Conclusion: The framework successfully discovers interpretable physical laws by combining symbolic regression with LLM guidance, providing meaningful physical insights while achieving better accuracy and simplicity than traditional approaches.

Abstract: Discovering interpretable physical laws from high-dimensional data is a fundamental challenge in scientific research. Traditional methods, such as symbolic regression, often produce complex, unphysical formulas when searching a vast space of possible forms. We introduce a framework that guides the search process by leveraging the embedded scientific knowledge of large language models, enabling efficient identification of physical laws in the data. We validate our approach by modeling key properties of perovskite materials. Our method mitigates the combinatorial explosion commonly encountered in traditional symbolic regression, reducing the effective search space by a factor of approximately $10^5$. A set of novel formulas for bulk modulus, band gap, and oxygen evolution reaction activity are identified, which not only provide meaningful physical insights but also outperform previous formulas in accuracy and simplicity.

</details>


### [31] [Ceci n'est pas un committor, yet it samples like one: efficient sampling via approximated committor functions](https://arxiv.org/abs/2602.23236)
*Enrico Trizio,Giorgia Rossi,Michele Parrinello*

Main category: physics.comp-ph

TL;DR: Simplified committor-based enhanced sampling method using descriptor-space learning criterion reduces computational cost while maintaining robust sampling performance.


<details>
  <summary>Details</summary>
Motivation: Original committor-based enhanced sampling method requires costly coordinate gradients, limiting practical application to complex reactive processes.

Method: Proposes simplified learning criterion formulated entirely in descriptor space, bypassing explicit coordinate gradients and providing relaxed upper bound to original variational principle.

Result: Retains robust sampling performance while significantly reducing computational costs, enabling study of previously unfeasible processes.

Conclusion: Descriptor-space learning approach offers practical alternative to original gradient-based committor learning, expanding applicability of enhanced sampling methods.

Abstract: Atomistic simulations are widely used to investigate reactive processes but are often limited by the rare event problem due to kinetic bottlenecks. We recently introduced an enhanced sampling approach based on the committor function, machine-learned following a variational principle. This method combines a transition-state-oriented bias potential, expressed as a functional of the committor, with a metadynamics-like bias along a committor-based collective variable, enabling uniform exploration of reaction pathways. In its original formulation, the committor is represented by a neural network that takes physical descriptors as input and is trained by minimizing a functional involving gradients with respect to atomic coordinates, which can be computationally demanding in some cases. Here, we propose a simplified learning criterion formulated entirely in the descriptor space, which bypasses the need for explicit and costly coordinate gradients and provides a relaxed upper bound to the original variational principle. Although this approach does not formally target the exact committor, we show that it retains robust sampling performance while significantly reducing computational costs, thus enabling the study of processes that would be practically unfeasible using the original formulation.

</details>


### [32] [mrfmsim: a modular, extendable, and readable simulation platform for magnetic resonance force microscopy experiments](https://arxiv.org/abs/2602.23337)
*Peter Sun,Corinne E. Isaac,Michael C. Boucher,Eric W. Moore,Zhen Wang,John A. Marohn*

Main category: physics.comp-ph

TL;DR: mrfmsim is an open-source package for designing, simulating, and validating magnetic resonance force microscopy experiments using directed acyclic graphs and a plugin system.


<details>
  <summary>Details</summary>
Motivation: The paper addresses challenges in building simulation packages for experiments undergoing continuous development in graduate research settings, highlighting how one-off simulation approaches can yield erroneous results.

Method: The mrfmsim package uses directed acyclic graphs (DAGs) to model experiments and employs a plugin system that allows adding custom experiments and functionalities. Unlike typical DAG workflow packages, it enables flexible customization of experiments post-definition without rewriting internal models.

Result: The modular, extensible, and readable platform enabled correct results and significantly accelerated development cycles compared to previous one-off simulation approaches that produced erroneous results.

Conclusion: mrfmsim provides an effective solution for magnetic resonance force microscopy experiment simulation that addresses the challenges of continuous development in research settings through its flexible DAG-based architecture and plugin system.

Abstract: We present mrfmsim, an open-source package that facilitates the design, simulation, and signal validation of magnetic resonance force microscopy experiments. The mrfmsim package uses directed acyclic graphs (DAGs) to model experiments and employs a plugin system that enables adding custom experiments and functionalities. Unlike common DAG-powered workflow packages, mrfmsim allows flexible customization of experiments post-definition, such as optimized looping, without requiring rewriting the internal model. In this paper, we highlight the challenges of building simulation packages for experiments that undergo continuous development in a graduate research setting. We demonstrate how a one-off approach to experimental simulation yielded erroneous results, and how the modularity, extendibility, and readability of the new platform enabled correct results and a significantly accelerated development cycle.

</details>


<div id='physics.plasm-ph'></div>

# physics.plasm-ph [[Back]](#toc)

### [33] [The Effect of Magnetization on Electron Heating in Low-Density Ultracold Neutral Plasmas](https://arxiv.org/abs/2602.22370)
*Ryan C. Baker,Bridget O'Mara,Jacob L. Roberts*

Main category: physics.plasm-ph

TL;DR: Study examines electron heating in ultracold magnetized plasmas, finding disorder-induced heating persists through plasma lifetime and achieving record-low electron temperatures of 0.52 K.


<details>
  <summary>Details</summary>
Motivation: Ultracold neutral plasmas enable study of extreme plasma physics regimes in lab settings. Understanding electron heating mechanisms is crucial for achieving lowest possible temperatures and maximum coupling strength.

Method: Used experimentally informed simulations to examine early-lifetime electron heating, focusing on disorder-induced heating and Rydberg atom formation effects in moderately coupled, strongly magnetized plasmas.

Result: Found disorder-induced heating significantly influences electron temperature throughout plasma lifetime. Achieved record-low electron temperature of 0.52±0.10 K at electron density of 6.1×10¹² m⁻³, determining maximum coupling strength.

Conclusion: Disorder-induced heating plays major role in electron temperature evolution in ultracold magnetized plasmas, with implications for achieving extreme coupling regimes in laboratory plasma physics research.

Abstract: Ultracold neutral plasmas provide a useful system for studying extreme parameter regimes plasma physics in an accessible laboratory setting. The parameter space of plasma physics can be characterized in part by coupling strength and degree of magnetization. The range of achievable strong coupling is determined in part by the lowest possible temperatures that can be achieved. This work examines the early-lifetime electron heating of moderately coupled, strongly magnetized plasmas. This heating is dominated by disorder-induced heating and heating due to Rydberg atom formation. By using experimentally informed simulations, it is found that disorder-induced heating has a large influence in electron temperature well into the plasma lifetime. Additionally, the dependence of the minimum achievable electron temperature on magnetization and initial electron energy is examined. In this work, we find electron temperatures as low as $0.52^{+.10}_{-.05}\ \mathrm{K}$ (for electron density, $n_{e}$, of $6.1 \times 10^{12}\ \mathrm{m^{-3}}$), which determines the maximum coupling strength for the measured experimental conditions.

</details>


### [34] [Nonlinear entropy transfer via zonal flows in gyrokinetic plasma turbulence](https://arxiv.org/abs/2602.22653)
*Motoki Nakata,Tomo-Hiko Watanabe,Hideo Sugama*

Main category: physics.plasm-ph

TL;DR: The paper investigates nonlinear entropy transfer processes in toroidal ITG and ETG turbulence using gyrokinetic entropy balance relations, revealing different entropy transfer mechanisms between ITG and ETG turbulence that affect turbulent transport regulation.


<details>
  <summary>Details</summary>
Motivation: To understand how nonlinear entropy transfer processes between zonal and non-zonal modes regulate turbulent transport in toroidal ITG and ETG driven turbulence, which is crucial for plasma confinement in fusion devices.

Method: Based on gyrokinetic entropy balance relations for zonal and non-zonal modes, using spectral analyses of a newly introduced "triad" entropy transfer function to examine nonlinear interactions and their effects on turbulent transport.

Result: Found different entropy transfer mechanisms: In ITG turbulence, substantial transfer from non-zonal to zonal modes during saturation phase, then zonal flows mediate transfer between non-zonal modes in steady state. In ETG turbulence, transfer among low-wavenumber non-zonal modes dominates in both phases.

Conclusion: The study reveals distinct nonlinear entropy transfer pathways in ITG vs ETG turbulence, with zonal flows playing different roles in transport regulation, providing insights into turbulent transport mechanisms in fusion plasmas.

Abstract: Nonlinear entropy transfer processes in toroidal ion temperature gradient (ITG) and electron temperature gradient (ETG) driven turbulence are investigated based on the gyrokinetic entropy balance relations for zonal and non-zonal modes, which are coupled through the entropy transfer function regarded as a kinetic extension of the zonal-flow production due to the Reynolds stress. Spectral analyses of the "triad" entropy transfer function introduced in this study reveal not only the nonlinear interactions among the zonal and non-zonal modes, but also their effects on the turbulent transport level. Different types of the entropy transfer processes between the ITG and ETG turbulence are found: The entropy transfer from non-zonal to zonal modes is substantial in the saturation phase of the ITG instability, while, once the strong zonal flow is generated, the entropy transfer to the zonal modes becomes quite weak in the steady turbulence state. Instead, the zonal flows mediate the entropy transfer from non-zonal modes with low radial-wavenumbers (with contribution to the heat flux) to the other non-zonal modes with higher radial-wavenumbers (but with less contribution to the heat flux) through the triad interaction. The successive entropy transfer processes to the higher radial-wavenumber modes are associated with transport regulation in the steady turbulence state. In contrast, in both the instability-saturation and steady phases of the ETG turbulence, the entropy transfer processes among low-wavenumber non-zonal modes are dominant rather than the transfer via zonal modes.

</details>


### [35] [Isotope Effects on TEM-driven Turbulence and Zonal Flows in Helical and Tokamak Plasmas](https://arxiv.org/abs/2602.22655)
*Motoki Nakata,Masanori Nunami,Hideo Sugama,Tomo-Hiko Watanabe*

Main category: physics.plasm-ph

TL;DR: Isotope ion mass affects TEM turbulence and zonal flows in fusion plasmas, with collisional TEM stabilization and increased zonal flow impacts leading to transport reduction opposite to conventional gyro-Bohm scaling.


<details>
  <summary>Details</summary>
Motivation: To understand how isotope ion mass influences trapped electron mode (TEM) driven turbulence and zonal flows in magnetically confined fusion plasmas, particularly investigating isotope and collisional effects on turbulent transport and zonal-flow generation.

Method: First-ever gyrokinetic simulations of TEM-driven turbulence in 3D LHD plasmas with hydrogen isotope ions and real-mass kinetic electrons, examining both linear and nonlinear isotope and collisional effects on turbulent transport and zonal-flow generation.

Result: Combined effects of collisional TEM stabilization by isotope ions and associated increase in steady zonal flow impacts at near-marginal linear stability lead to significant transport reduction with opposite ion mass dependence compared to conventional gyro-Bohm scaling.

Conclusion: Isotope effects on TEM-driven turbulence and zonal flows show universal nature across various toroidal plasmas (tokamaks and helical/stellarator systems), revealing important transport reduction mechanisms opposite to conventional scaling.

Abstract: Impacts of isotope ion mass on trapped electron mode (TEM) driven turbulence and zonal flows in magnetically confined fusion plasmas are investigated. Gyrokinetic simulations of TEM-driven turbulence in three-dimensional magnetic configuration of LHD plasmas with hydrogen isotope ions and real-mass kinetic electrons are realized for the first time, and the linear and the nonlinear nature of the isotope and collisional effects on the turbulent transport and zonal-flow generation is clarified. It is newly found that combined effects of the collisional TEM stabilization by the isotope ions and the associated increase in the impacts of the steady zonal flows at the near-marginal linear stability lead to the significant transport reduction with the opposite ion mass dependence in comparison to the conventional gyro-Bohm scaling. The universal nature of the isotope effects on the TEM-driven turbulence and zonal flows is verified for a wide variety of toroidal plasmas, e.g., axisymmetric tokamak and non-axisymmetric helical/stellarator systems.

</details>


### [36] [Gyrokinetic turbulent transport simulations on steady burning condition in D-T-He plasmas](https://arxiv.org/abs/2602.22656)
*Motoki Nakata,Mitsuru Honda*

Main category: physics.plasm-ph

TL;DR: Gyrokinetic Vlasov simulations reveal D-T fuel imbalance in turbulent transport for ITER-like plasmas, identifying profile regimes for steady burning with He-ash exhaust.


<details>
  <summary>Details</summary>
Motivation: To investigate turbulent transport driven by ITG and TEM modes in ITER-like plasmas and establish steady burning conditions with proper He-ash exhaust and D-T fuel balance, going beyond conventional zero-dimensional power balance analysis.

Method: Multi-species gyrokinetic Vlasov simulations with D, T, He, and real-mass kinetic electrons including inter-species collisions, evaluating steady burning conditions with He-ash exhaust and D-T fuel inward pinch.

Result: Significant imbalance appears in turbulent particle flux for D and T fuel ions depending on D-T density ratio and He-ash accumulation; several profile regimes satisfying Reiter's steady burning condition are identified for the first time; impacts of zonal flows and nonthermal He-ash are examined.

Conclusion: Gyrokinetic simulations provide crucial insights into turbulent transport imbalances in fusion plasmas, identifying specific profile regimes that can maintain steady burning conditions in ITER-like devices with proper He-ash management.

Abstract: Ion temperature gradient(ITG) and trapped electron modes(TEM) driven turbulent transport in an ITER-like plasma is investigated by means of multi-species gyrokinetic Vlasov simulations with D, T, He, and real-mass kinetic electrons including their inter-species collisions. Beyond the conventional zero-dimensional power balance analysis presuming the global energy and particle confinement times, gyrokinetic-simulation-based evaluation of a steady burning condition with He-ash exhaust and D-T fuel inward pinch is demonstrated. It is clarified that a significant imbalance appears in the turbulent particle flux for the fuel ions of D and T, depending on the D-T density ratio and the He-ash accumulation. Then several profile regimes to satisfy Reiter's steady burning condition are, for the first time, identified by the gyrokinetic simulation. Also, the impacts of zonal flows and nonthermal He-ash on the optimal profile regimes are examined.

</details>


### [37] [Experimental Demonstration of Beam-Driven Wakefield Acceleration in Laser-Plasma Filament](https://arxiv.org/abs/2602.22841)
*M. Galletti,L. Verra,A. Biagioni,M. Carillo,L. Crincoli,R. Demitra,G. Parise,G. Di Pirro,R. Pompili,F. Stocchi,F. Villa,A. Zigler,M. Ferrario*

Main category: physics.plasm-ph

TL;DR: Self-guided femtosecond laser pulses create plasma filaments for wakefield acceleration, enabling high-repetition-rate, tunable stages with improved reliability and control over conventional methods.


<details>
  <summary>Details</summary>
Motivation: To overcome limitations of conventional plasma wakefield acceleration schemes that rely on mechanically confined or preformed plasma channels, which require more energy and have lower reproducibility due to stochastic breakdown processes.

Method: Using self-guided femtosecond laser pulses propagating in low-pressure gas to generate plasma filaments through intrinsic non-linear light-matter interaction, then demonstrating beam-driven wakefield acceleration of electron bunches in these laser-generated filaments.

Result: Experimental demonstration of electron bunch acceleration with accelerating field exceeding 250 MV/m in laser-generated plasma filaments, with excellent agreement between experimental results and numerical simulations.

Conclusion: Laser-based plasma formation offers improved reliability, control, and reproducibility for plasma wakefield acceleration, bridging laser filamentation physics with compact accelerator technologies for sustainable, high-repetition-rate plasma-based facilities.

Abstract: Self-guided femtosecond laser pulses propagating in low-pressure gas can generate plasma filaments, establishing a new framework for plasma wakefield acceleration. Unlike conventional schemes relying on mechanically confined or preformed plasma channels, this method exploits the intrinsic non-linear light-matter interaction, greatly reducing the energy required to generate plasma. This, in turn, allows to realise tunable stages, potentially operating above kHz repetition rate and with meter-scale interaction lengths and transverse sizes down to a few tens of micrometres. Moreover, the laser-plasma filament reproducibility is intrinsically higher than state-of-the-art discharge-plasmas, where the breakdown process is initiated in a stochastic and uncontrolled manner. As a result, laser-based plasma formation offers improved reliability and control over plasma parameters. Here we report a proof-of-principle experimental demonstration of beam-driven wakefield acceleration of electron bunches with an accelerating field exceeding 250 MV/m in a laser-generated plasma filament. The results are cross-checked with numerical simulation, showing an excellent agreement and providing a complete picture of the physical process. Beyond particle acceleration, the concept bridges laser filamentation physics, advanced plasma photonics and compact accelerator technologies, offering a promising route towards sustainable, high-repetition-rate plasma-based facilities.

</details>


### [38] [Merging of zonal flows in gyrofluid resistive drift-wave turbulence](https://arxiv.org/abs/2602.23007)
*Fabian Grander,Tobias Gröfler,Franz Ferdinand Locker,Manuel Rinner,Alexander Kendl*

Main category: physics.plasm-ph

TL;DR: The paper investigates non-linear dynamics of zonal flows in plasma turbulence using the gyrofluid modified Hasegawa-Wakatani model, focusing on zonal flow merging and chaotic development patterns.


<details>
  <summary>Details</summary>
Motivation: To understand the complex non-linear dynamics of zonal flows in plasma turbulence, particularly the merging processes and chaotic development patterns that are crucial for understanding plasma confinement and transport in fusion devices.

Method: Uses the gyrofluid modified Hasegawa-Wakatani model, derives conservation equations for zonal flow momentum and energy with finite Larmor radius effects, and performs quantitative analysis of zonal flow mergers through numerical simulations.

Result: Nonlinear local Reynolds stress transfer (rather than hyperviscous dissipation) is identified as the primary mechanism driving zonal flow merging. The paper also discusses the applicability of phase transition concepts to zonal flow transition hysteresis.

Conclusion: Zonal flow merging is primarily driven by nonlinear Reynolds stress transfer, and the concept of phase transitions in thermodynamics may be applicable to understanding zonal flow transition hysteresis phenomena.

Abstract: Non-linear dynamics of zonal flows is investigated in the context of the gyrofluid modified Hasegawa-Wakatani model. Merging of zonal flows and the chaotic developement of the initial zonal flow pattern is explored. Conservation equations for zonal flow momentum and energy with consistent finite Larmor radius (FLR) effects are derived and used for a quantitative analysis of zonal flow mergers in numerical simulations. The nonlinear local Reynolds stress transfer as opposed to (hyper)viscous dissipation is found to be the main cause of merging. The applicability of the concept of a phase transition in the strict thermodynamical sense is discussed in context of zonal flow transition hysteresis.

</details>


<div id='math.DG'></div>

# math.DG [[Back]](#toc)

### [39] [Calibrations for the Sasaki volume on odd spheres and the no-gap problem](https://arxiv.org/abs/2602.22961)
*Jonas Matuzas*

Main category: math.DG

TL;DR: The paper establishes a universal calibrated lower bound for the Sasaki volume functional on odd-dimensional spheres, analyzes equality cases, and constructs recovery sequences to show no Lavrentiev gap exists.


<details>
  <summary>Details</summary>
Motivation: To study the Sasaki volume functional on unit tangent vector fields of odd-dimensional spheres and establish optimal lower bounds using calibration techniques, while investigating the existence of minimizing fields and potential Lavrentiev phenomena.

Method: Uses the Brito-Chacon-Naveira calibration ω on the unit tangent bundle, analyzes smooth graphs and equality cases, constructs explicit smooth recovery sequences (detailed for S⁵ then extended), and employs polar-shell normalization patching with uniform nonvanishing estimates.

Result: Proves universal lower bound Vol^S(V) ≥ c(m;1)vol(Sⁿ) with explicit constant c(m;1)=4^m/binom(2m,m); shows section-constrained stable mass equals calibration value; demonstrates no smooth ω-calibrated fields exist for m≥2; constructs recovery sequence proving inf Vol^S(V)=c(m;1)vol(Sⁿ) with no Lavrentiev gap.

Conclusion: The Sasaki volume functional on odd spheres has an optimal lower bound achieved via calibration methods, with no Lavrentiev gap despite the absence of smooth minimizing fields for dimensions ≥5, highlighting interesting geometric rigidity phenomena.

Abstract: For each odd sphere $S^{n}$ with $n=2m+1\ge 5$, we consider the Sasaki volume functional $\mathrm{Vol}^S(V)=\int_{S^{n}}\sqrt{\det(I+(\nabla V)^{\top}(\nabla V))}\,d\mathrm{vol}$ on smooth unit tangent vector fields $V$. Using the Brito--Chacon--Naveira calibration $ω=a\wedgeΘ$ on the unit tangent bundle $E=UTS^{n}$, we establish the universal calibrated lower bound $\mathrm{Vol}^S(V)\ge c(m;1)\,\mathrm{vol}(S^{n})$, where $c(m;1)=4^{m}/\binom{2m}{m}$. In the relaxed (integral-current) setting, we show that the section-constrained stable mass in $E$ equals the calibration value and is attained by an $ω$-calibrated mass-minimizing integral $n$-cycle in the section class.
  We also analyze the equality case on smooth graphs. If a smooth graph is $ω$-calibrated on an open set, then it satisfies the rigidity system $\nabla_V V=0$ and $\nabla_X V=λX$ for all $X\perp V$, hence is locally a radial distance-gradient field. In particular, for $m\ge 2$ there is no smooth unit field on $S^n$ whose graph is $ω$-calibrated everywhere.
  Finally, we construct an explicit smooth recovery sequence (presented in detail for $S^5$ and then extended to all odd dimensions) and prove a uniform nonvanishing estimate for the polar-shell normalization in the patching construction. As a consequence, $\inf_{V}\,\mathrm{Vol}^S(V)=c(m;1)\,\mathrm{vol}(S^{n})$, so there is no Lavrentiev gap.

</details>


<div id='astro-ph.SR'></div>

# astro-ph.SR [[Back]](#toc)

### [40] [A Multi-Diagnostic Observational Framework for Magnetosonic Solitary Waves During Geomagnetic Storms in Solar Cycles 24 and 25 using Cluster II Mission](https://arxiv.org/abs/2602.22614)
*Murchana Khusroo,Yimnasangla*

Main category: astro-ph.SR

TL;DR: Study compares magnetosonic soliton signatures during geomagnetic storms in Solar Cycles 24 and 25 using Cluster II data, finding solitons occur early in storms and may serve as precursors.


<details>
  <summary>Details</summary>
Motivation: While solitons are abundant in space plasmas, their observation during geomagnetic storms remains limited. The study aims to investigate these nonlinear plasma waves during storm-time dynamics to understand their occurrence patterns and potential significance.

Method: Used high-resolution in-situ magnetic field measurements from Cluster II mission. Developed comprehensive multi-diagnostic observational framework with state-of-the-art analytical techniques to reliably detect and characterize magnetosonic solitons. Systematically examined plasma conditions favorable for soliton generation during storm-time dynamics.

Result: Solitary structures in both Solar Cycle 24 and 25 storms predominantly occur during early storm intervals, prior to the main phase. This suggests solitons may serve as potential precursor signatures of enhanced geomagnetic activity.

Conclusion: Magnetosonic solitons observed during geomagnetic storms show consistent early occurrence patterns across different solar cycles, indicating they could be valuable precursors for monitoring and predicting geomagnetic storm activity.

Abstract: Solitary structures, commonly known as solitons, are a class of nonlinear plasma waves that are abundantly found in near-Earth plasmas and planetary magnetospheres. They are nonlinear, localized plasma waves that maintain their shape and velocity over time and distance. While their occurrence in various space plasma environments has been extensively reported, their observation during geomagnetic storms, large-scale disturbances driven by interactions between the solar wind and Earth's magnetosphere, remains limited. In this study, we present a comparative investigation of magnetosonic soliton signatures during geomagnetic storms associated with Solar Cycles 24 and 25. Using high-resolution in-situ magnetic field measurements from the Cluster II mission, we systematically examine the plasma conditions favorable for soliton generation and their evolution during storm-time dynamics. A comprehensive multi-diagnostic observational framework, incorporating several state-of-the-art analytical techniques, is developed to reliably detect and characterize magnetosonic solitons. The results demonstrate that solitary structures in both storms predominantly occur during the early storm intervals, prior to the main phase, suggesting that they may serve as potential precursor signatures of enhanced geomagnetic activity.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [41] [Optimizing Doppler laser cooling protocols for quantum sensing with 3D ion crystals in a Penning trap](https://arxiv.org/abs/2602.22541)
*John Zaris,Wes Johnson,Athreya Shankar,John J. Bollinger,Allison L. Carter,Daniel H. E. Dubin,Scott E. Parker*

Main category: quant-ph

TL;DR: A numerical framework for simulating laser cooling of up to 100,000 ions in Penning traps, enabling optimization of 3D ellipsoidal crystal cooling with enhanced pathways and simplified setups.


<details>
  <summary>Details</summary>
Motivation: Large 3D trapped ion crystals improve quantum sensing sensitivity but current numerical techniques are inefficient for studying laser cooling as crystal size increases. There's a need for better simulation tools to prepare large crystals for future quantum science experiments.

Method: Developed a powerful numerical framework to simulate laser cooling of up to 10^5 ions in Penning traps. Applied this framework to characterize and optimize cooling of ellipsoidal 3D crystals, exploring new cooling pathways and beam configurations.

Result: Discovered new enhanced cooling pathways by adding axial components to potential energy-dominated E×B modes. Achieved greatly enhanced cooling of perpendicular kinetic energy below 1 mK in prolate crystals, enabling simplified cooling beam setups. Proposed specific trap and laser parameters for optimal cooling.

Conclusion: The work demonstrates feasibility of preparing large 3D crystals for high-sensitivity quantum science protocols, motivating their implementation in future experiments with optimized cooling parameters.

Abstract: Large, 3D trapped ion crystals offer improved sensitivity in quantum sensing protocols, and are expected to be implemented as platforms in near-future experiments. However, numerical techniques used to study the laser cooling of such crystals are inefficient as the number of ions, $N$, in the crystal increases. Here we develop a powerful numerical framework to simulate laser cooling of up to $10^5$ ions stored in a Penning trap. We apply this framework to characterize and optimize the cooling of ellipsoidal 3D crystals. We document new pathways to enhanced cooling based on the addition of an axial component to the potential energy-dominated $\boldsymbol{E}\times\boldsymbol{B}$ modes. Furthermore, we observe greatly enhanced cooling of the perpendicular kinetic energy to below 1 mK in prolate ion crystals, enabling a simplified cooling beam setup for such crystals. We propose specific values of trap and laser beam parameters which lead to optimal cooling in a variety of examples. This work illustrates the feasibility of preparing large 3D crystals for high-sensitivity quantum science protocols, motivating their use in future experiments.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [42] [Growth-controlled photochromism in yttrium oxyhydride thin films deposited by HiPIMS and pulsed-DC magnetron sputtering](https://arxiv.org/abs/2602.22951)
*M. Zubkins,E. Letko,E. Strods,V. Vibornijs,D. Moldarev,K. Sarakinos,K. Mizohata,K. Kundzins,J. Purans*

Main category: cond-mat.mtrl-sci

TL;DR: HiPIMS vs pulsed-DCMS deposition of YHO photochromic films: HiPIMS has higher critical pressure, lower photochromic contrast, and different microstructure compared to pulsed-DCMS.


<details>
  <summary>Details</summary>
Motivation: To compare photochromic properties of YHO thin films deposited by two different sputtering techniques (HiPIMS vs pulsed-DCMS) and understand how deposition conditions affect film performance.

Method: Deposited YHO thin films using reactive HiPIMS and pulsed-DCMS, analyzed using optical emission spectroscopy, measured critical working pressure, solar transmittance, photochromic contrast, optical band gap, oxygen-to-hydrogen ratio, and structural characterization.

Result: HiPIMS requires higher critical pressure (1.0 Pa vs 0.5 Pa), produces films with lower photochromic contrast (9% vs 34%), higher band gap (2.94 eV vs 2.70 eV), different microstructure (polycrystalline vs <100> preferred orientation), and different plasma composition (strong Y⁺ emission vs Ar⁺ dominated).

Conclusion: Beyond composition, thin-film growth conditions and microstructure significantly influence photochromic performance of YHO, with pulsed-DCMS producing superior photochromic properties compared to HiPIMS.

Abstract: The present study investigates photochromic oxygen-containing yttrium hydride (YHO) thin films deposited by reactive high power impulse magnetron sputtering (HiPIMS) and compares their photochromic, optical, and structural properties with those of films synthesized by reactive pulsed direct current magnetron sputtering (pulsed-DCMS). Optical emission spectroscopy reveals that, unlike pulsed-DCMS where Ar$^{+}$ ions dominate, HiPIMS discharges are characterised by strong Y$^{+}$ emission, evidencing high yttrium ionisation and substantial self-sputter recycling. The critical working pressure (P$_c$) required to obtain transparent and photochromic films is higher for HiPIMS (Pc $\approx$ 1.0 Pa) than for pulsed-DCMS (Pc $\approx$ 0.5 Pa). Although films deposited near Pc exhibit similar solar transmittance (~72 %) and lattice parameters (5.38--5.39 Å), the pulsed-DCMS film shows a substantially higher relative photochromic contrast (34 %) and a lower optical band gap (2.70 eV) compared with the HiPIMS film (9 % contrast and 2.94 eV). This difference is partly attributed to a lower oxygen-to-hydrogen atomic ratio in the pulsed-DCMS film. Structurally, HiPIMS films are largely polycrystalline with random out-of-plane crystallographic orientation, whereas pulsed-DCMS films exhibit a pronounced <100> out-of-plane preferred orientation. These results demonstrate that, beyond composition, thin-film growth conditions and microstructure play a crucial role in governing the photochromic performance of YHO.

</details>


<div id='astro-ph.CO'></div>

# astro-ph.CO [[Back]](#toc)

### [43] [Imprints of primordial magnetic fields on the late-time Universe](https://arxiv.org/abs/2602.23263)
*Jennifer Schober,Molly Abramson,Sayan Mandal,Salome Mtchedlidze,Tina Kahniashvili*

Main category: astro-ph.CO

TL;DR: Primordial magnetic fields can survive structure formation on certain spatial scales, with turbulence during gravitational collapse potentially triggering small-scale dynamo amplification below the Jeans scale.


<details>
  <summary>Details</summary>
Motivation: To understand how primordial magnetic fields evolve during gravitational collapse and determine which spatial scales retain primordial signatures despite nonlinear structure formation processes.

Method: High-resolution direct numerical simulations of self-gravitating, magnetized halos with varying viscosity to probe different Reynolds-number regimes, studying coupled evolution of gravitational collapse and magnetohydrodynamic turbulence.

Result: At high Reynolds numbers, turbulence during collapse triggers small-scale dynamo amplification below the Jeans scale, significantly modifying magnetic energy spectrum. Dynamo dominance depends on competition between dynamo growth time and free-fall time.

Conclusion: Cosmological MHD simulations must resolve Jeans scale and turbulent inertial range to accurately capture interplay between gravitational compression and dynamo amplification, determining which structures retain memory of primordial fields.

Abstract: Primordial magnetic fields (PMFs) generated in the early Universe may leave observable imprints in the present-day large-scale structure. However, it remains unclear on which spatial scales primordial signatures can survive the nonlinear processes accompanying structure formation. The aim of this study is to investigate the evolution of PMFs during gravitational collapse and to determine the spatial scales on which primordial signatures can persist. We perform a suite of high-resolution direct numerical simulations of self-gravitating, magnetized halos. By varying the viscosity, we probe different Reynolds-number regimes and follow the coupled evolution of gravitational collapse and magnetohydrodynamic turbulence. At sufficiently high Reynolds numbers, turbulence generated during collapse triggers the onset of a small-scale dynamo, which amplifies magnetic energy below the Jeans scale and modifies the magnetic energy spectrum significantly. Whether dynamo amplification dominates the magnetic field evolution is determined by the competition between the dynamo growth time and the free-fall time. Our results highlight the importance of resolving the Jeans scale and the associated turbulent inertial range in cosmological MHD simulations to accurately capture the interplay between gravitational compression and dynamo amplification and to assess which structures retain memory of primordial fields.

</details>


<div id='cs.SC'></div>

# cs.SC [[Back]](#toc)

### [44] [Quadratization of Autonomous Partial Differential Equations: Theory and Algorithms](https://arxiv.org/abs/2602.22371)
*Albani Olivieri,Gleb Pogudin,Boris Kramer*

Main category: cs.SC

TL;DR: QuPDE is the first computational algorithm that finds quadratizations (quadratic transformations) for spatially one-dimensional polynomial/rational PDEs by introducing auxiliary variables, outperforming previous manual methods.


<details>
  <summary>Details</summary>
Motivation: Quadratization simplifies analysis, simulation, and control of nonlinear/nonquadratic PDEs, but existing methods are manual and limited. There's a need for automated computational tools to find optimal quadratizations.

Method: Developed QuPDE algorithm based on symbolic computation and discrete optimization that outputs quadratizations for any spatially one-dimensional polynomial or rational PDE. The algorithm uses rigorous mathematical framework with existence and complexity results.

Result: QuPDE successfully found low-order quadratizations for 14 diverse nonquadratic PDEs from fluid mechanics, space physics, chemical engineering, and biological processes. It discovered transformations with fewer auxiliary variables than previous manual methods and quadratized systems not previously transformed.

Conclusion: QuPDE is the first computational tool for PDE quadratization, providing automated, optimal transformations that outperform manual approaches, enabling broader application of quadratic analysis techniques to complex PDE systems.

Abstract: Quadratization for partial differential equations (PDEs) is a process that transforms a nonquadratic PDE into a quadratic form by introducing auxiliary variables. This symbolic transformation has been used in diverse fields to simplify the analysis, simulation, and control of nonlinear and nonquadratic PDE models. This paper presents a rigorous definition of PDE quadratization, theoretical results for the PDE quadratization problem of spatially one-dimensional PDEs-including results on existence and complexity-and introduces QuPDE, an algorithm based on symbolic computation and discrete optimization that outputs a quadratization for any spatially one-dimensional polynomial or rational PDE. This algorithm is the first computational tool to find quadratizations for PDEs to date. We demonstrate QuPDE's performance by applying it to fourteen nonquadratic PDEs in diverse areas such as fluid mechanics, space physics, chemical engineering, and biological processes. QuPDE delivers a low-order quadratization in each case, uncovering quadratic transformations with fewer auxiliary variables than those previously discovered in the literature for some examples, and finding quadratizations for systems that had not been transformed to quadratic form before.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [45] [The AI Research Assistant: Promise, Peril, and a Proof of Concept](https://arxiv.org/abs/2602.22842)
*Tan Bui-Thanh*

Main category: cs.AI

TL;DR: AI can meaningfully accelerate mathematical discovery through human-AI collaboration, as demonstrated by discovering novel error representations and bounds for Hermite quadrature rules, but requires rigorous human verification and oversight.


<details>
  <summary>Details</summary>
Motivation: To investigate whether AI can truly contribute to creative mathematical research beyond just automating routine calculations, and to understand the risks and potential of human-AI collaboration in mathematical discovery.

Method: Conducted a detailed case study using systematic human-AI collaboration with multiple AI assistants to discover novel error representations and bounds for Hermite quadrature rules, documenting the complete research workflow with transparency.

Result: Extended results beyond manual work, formulating and proving several theorems with AI assistance. AI excelled at algebraic manipulation, systematic proof exploration, literature synthesis, and LaTeX preparation, but every step required human verification and strategic direction.

Conclusion: When used with appropriate skepticism and verification protocols, AI tools can meaningfully accelerate mathematical discovery, but demand careful human oversight and deep domain expertise, revealing both remarkable capabilities and critical limitations.

Abstract: Can artificial intelligence truly contribute to creative mathematical research, or does it merely automate routine calculations while introducing risks of error? We provide empirical evidence through a detailed case study: the discovery of novel error representations and bounds for Hermite quadrature rules via systematic human-AI collaboration.
  Working with multiple AI assistants, we extended results beyond what manual work achieved, formulating and proving several theorems with AI assistance. The collaboration revealed both remarkable capabilities and critical limitations. AI excelled at algebraic manipulation, systematic proof exploration, literature synthesis, and LaTeX preparation. However, every step required rigorous human verification, mathematical intuition for problem formulation, and strategic direction.
  We document the complete research workflow with unusual transparency, revealing patterns in successful human-AI mathematical collaboration and identifying failure modes researchers must anticipate. Our experience suggests that, when used with appropriate skepticism and verification protocols, AI tools can meaningfully accelerate mathematical discovery while demanding careful human oversight and deep domain expertise.

</details>


<div id='physics.space-ph'></div>

# physics.space-ph [[Back]](#toc)

### [46] [Fluctuating polytropic processes, turbulence, and heating](https://arxiv.org/abs/2602.22272)
*G. Livadiotis,D. J. McComas*

Main category: physics.space-ph

TL;DR: Fluctuating polytropic processes explain turbulent heating in solar wind plasma, showing how random fluctuations produce net heating even when nonfluctuating processes are adiabatic.


<details>
  <summary>Details</summary>
Motivation: To understand how turbulent heating occurs in solar wind plasma and connect it to thermodynamic principles through fluctuating polytropic processes.

Method: Derived thermodynamic expressions for fluctuating polytropic processes, applied to solar wind plasma, and compared with turbulent heating profiles. Used analytical modeling and observational fitting.

Result: Polytropic fluctuations produce net heating even in adiabatic processes; solar wind cooling is subadiabatic proportional to fluctuation variance; derived heating profiles match turbulent heating; successfully applied to PUI energy transfer.

Conclusion: Turbulence heats plasma by fluctuating polytropic processes; thermodynamic model successfully explains solar wind heating and PUI energy transfer with good observational agreement.

Abstract: This paper explores the thermodynamics of fluctuating polytropic processes and their connection to turbulence. It is shown that random fluctuations of polytropic processes produce a nonzero overall heating of a particle system, e.g., solar wind plasma flowing out through the heliosphere; while any nonturbulent heating can be thermodynamically described by typical nonfluctuating polytropic processes, turbulent heating can be thermodynamically described through fluctuating polytropic processes. First, we derive the expression of the overall process and find that polytropic fluctuations lead to heat entering the system even if the respective nonfluctuating process is adiabatic. The temperature of the solar wind plasma protons decreases with heliospheric distance less than the adiabatic cooling, again, similar to when heating enters the system; this subadiabatic cooling is proportional to the variance of the fluctuations. We derive the heliospheric radial profiles of the thermodynamic expressions of the polytropic index, temperature, and heating rates. Then, we show that the analytical profiles of heating of fluctuating polytropic processes and of turbulent heating are identical, suggesting that turbulence heats plasma particle populations by fluctuating their polytropic processes. We apply the thermodynamics of fluctuating polytropic processes to the energy transfer from pickup ions (PUIs) to solar wind plasma protons, and derive the analytical expressions of PUI turbulent and nonturbulent heating rates, which are well fitted to the respective observations. Finally, we apply the thermodynamic model to the radial profile of PUI energy transfer to the solar wind plasma protons, where we derive the portion of PUI turbulent vs. nonturbulent heating rates.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [47] [Learning geometry-dependent lead-field operators for forward ECG modeling](https://arxiv.org/abs/2602.22367)
*Arsenii Dokuchaev,Francesca Bonizzoni,Stefano Pagani,Francesco Regazzoni,Simone Pezzuto*

Main category: cs.LG

TL;DR: A shape-informed neural surrogate model for ECG forward simulations that combines anatomical fidelity with computational efficiency using latent shape representations.


<details>
  <summary>Details</summary>
Motivation: Current ECG computational models face three key challenges: 1) achieving high anatomical fidelity in torso representation is difficult due to limited imaging data, 2) computational cost scales linearly with electrode count, limiting high-density applications, and 3) no existing approach simultaneously achieves high fidelity, low data requirements, and computational efficiency.

Method: Proposes a two-component framework: 1) a geometry-encoding module that maps anatomical shapes into a low-dimensional latent space, and 2) a geometry-conditioned neural surrogate that predicts lead-field gradients from spatial coordinates, electrode positions, and latent codes. This serves as a drop-in replacement for full-order models in forward ECG simulations.

Result: The method achieves high accuracy in approximating lead fields (mean angular error 5°) and highly accurate ECG simulations (relative mean squared error <2.5%). It consistently outperforms the widely used pseudo lead-field approximation while preserving negligible inference cost. The compact latent representation enables deployment in data-limited settings.

Conclusion: The proposed shape-informed surrogate model successfully addresses the trade-offs between anatomical fidelity, data requirements, and computational efficiency in forward ECG simulations, enabling high-fidelity ECG modeling even with limited torso imaging data.

Abstract: Modern forward electrocardiogram (ECG) computational models rely on an accurate representation of the torso domain. The lead-field method enables fast ECG simulations while preserving full geometric fidelity. Achieving high anatomical accuracy in torso representation is, however, challenging in clinical practice, as imaging protocols are typically focused on the heart and often do not include the entire torso. In addition, the computational cost of the lead-field method scales linearly with the number of electrodes, limiting its applicability in high-density recording settings. To date, no existing approach simultaneously achieves high anatomical fidelity, low data requirements and computational efficiency. In this work, we propose a shape-informed surrogate model of the lead-field operator that serves as a drop-in replacement for the full-order model in forward ECG simulations. The proposed framework consists of two components: a geometry-encoding module that maps anatomical shapes into a low-dimensional latent space, and a geometry-conditioned neural surrogate that predicts lead-field gradients from spatial coordinates, electrode positions and latent codes. The proposed method achieves high accuracy in approximating lead fields both within the torso (mean angular error 5°) and inside the heart, resulting in highly accurate ECG simulations (relative mean squared error <2.5%. The surrogate consistently outperforms the widely used pseudo lead-field approximation while preserving negligible inference cost. Owing to its compact latent representation, the method does not require a fully detailed torso segmentation and can therefore be deployed in data-limited settings while preserving high-fidelity ECG simulations.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [48] [HELIOS: A surface integral equation software for light scattering in homogeneous, periodic, and stratified environments](https://arxiv.org/abs/2602.23097)
*Parmenion S. Mavrikakis,Olivier J. F. Martin*

Main category: physics.optics

TL;DR: HELIOS is an open-source SIE software for modeling light scattering by particles in homogeneous/layered media and periodic structures, implementing PMCHWT formulation with RWG basis functions and efficient computational techniques.


<details>
  <summary>Details</summary>
Motivation: There's a need for reliable, versatile software to model light scattering in complex media (homogeneous/layered) and periodic structures (photonic crystals, metasurfaces) with computational efficiency.

Method: Uses PMCHWT formulation with RWG basis functions on triangular meshes. For periodic structures: Ewald's transformation for 2D lattices. For layered media: matrix-friendly approach with Sommerfeld integrals and tabulation-interpolation acceleration.

Result: HELIOS demonstrates accuracy and versatility through various examples covering all functionalities. The software is implemented in C++ with Python interface for workflow management.

Conclusion: HELIOS provides a comprehensive, efficient open-source solution for light scattering simulations in complex media and periodic structures, validated through diverse examples.

Abstract: We present HELIOS (HomogEneous and Layered medIa Optical Scattering), an open-source surface integral equation (SIE) software designed for modeling light scattering by particles embedded in homogeneous or layered media and periodic backgrounds. The code implements the Poggio-Miller-Chang-Harrington-Wu-Tsai (PMCHWT) formulation that has demonstrated exceptional reliability in solving scattering problems with penetrable objects. Domain boundaries are discretized using triangular meshes, upon which the electric and magnetic surface current densities are expanded using the Rao-Wilton-Glisson (RWG) basis functions. For periodic structures, such as photonic crystals and metasurfaces, HELIOS employs Ewald's transformation to efficiently evaluate the infinite series associated with 2D lattices. Regarding stratified media, the code utilizes a matrix-friendly approach for the layered media Green's tensor, computing Sommerfeld integrals and accelerating calculations through a tabulation-interpolation scheme. The source code is implemented in C++, while a Python interface manages the workflow, including simulation setup, solver run, and post-processing. The accuracy and versatility of HELIOS are demonstrated through various examples that cover all its functionalities.

</details>


<div id='math.PR'></div>

# math.PR [[Back]](#toc)

### [49] [Fluctuations in the weakly coupled 4D Anderson Hamiltonian](https://arxiv.org/abs/2602.22509)
*Simon Gabriel,Tommaso Rosati*

Main category: math.PR

TL;DR: Proves Gaussian fluctuations for Anderson Hamiltonian in critical dimension d=4, with explicit effective variance up to critical coupling constant where phase transition is expected.


<details>
  <summary>Details</summary>
Motivation: Study the weak coupling limit of the Anderson Hamiltonian in the critical dimension d=4, which is important for understanding quantum systems with disorder and their fluctuation behavior near criticality.

Method: Combinatorial analysis of Feynman diagrams and detailed study of BPHZ renormalization of the model. Characterizes limiting distribution in terms of primitive blow-ups.

Result: Proves Gaussian fluctuations about the Green's function of the Laplacian with explicit effective variance. Shows no Laplacian renormalization is present. Identifies critical coupling constant where phase transition is expected.

Conclusion: The approach provides rigorous results for Anderson Hamiltonian in critical dimension and seems applicable to a broad class of equations, offering insights into fluctuation behavior near critical points.

Abstract: We study the weak coupling limit of the Anderson Hamiltonian in the critical dimension $d=4$. In a perturbative sense, we prove Gaussian fluctuations about the Green's function of the Laplacian. The fluctuations are described by an explicit effective variance, up to a critical value of the coupling constant at which we expect a phase transition in the structure of the fluctuations. The proof is based on a combinatorial analysis of Feynman diagrams, and on a detailed study of the BPHZ renormalisation of the model. We characterise the limiting distribution in terms of primitive blow-ups, and prove that no Laplacian renormalisation is present. Our approach seems applicable to a broad class of equations.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [50] [QuadSync: Quadrifocal Tensor Synchronization via Tucker Decomposition](https://arxiv.org/abs/2602.22639)
*Daniel Miao,Gilad Lerman,Joe Kileel*

Main category: cs.CV

TL;DR: Quadrifocal tensors are practical for multi-view camera recovery via Tucker decomposition and synchronization algorithms.


<details>
  <summary>Details</summary>
Motivation: Quadrifocal tensors capture more information than essential matrices but have been considered impractical; this work challenges that belief by showing they can be practically used for camera recovery.

Method: Form block quadrifocal tensor with Tucker decomposition (rank 4×4×4×4), develop synchronization algorithm using Tucker decomposition, ADMM, and iteratively reweighted least squares; also create joint synchronization algorithm for quadrifocal, trifocal, and bifocal tensors.

Result: Numerical experiments show effectiveness on modern datasets, demonstrating potential of higher-order information in synchronization.

Conclusion: Quadrifocal tensors are practical and important for structure from motion, offering advantages over pairwise methods through higher-order information capture.

Abstract: In structure from motion, quadrifocal tensors capture more information than their pairwise counterparts (essential matrices), yet they have often been thought of as impractical and only of theoretical interest. In this work, we challenge such beliefs by providing a new framework to recover $n$ cameras from the corresponding collection of quadrifocal tensors. We form the block quadrifocal tensor and show that it admits a Tucker decomposition whose factor matrices are the stacked camera matrices, and which thus has a multilinear rank of (4,~4,~4,~4) independent of $n$. We develop the first synchronization algorithm for quadrifocal tensors, using Tucker decomposition, alternating direction method of multipliers, and iteratively reweighted least squares. We further establish relationships between the block quadrifocal, trifocal, and bifocal tensors, and introduce an algorithm that jointly synchronizes these three entities. Numerical experiments demonstrate the effectiveness of our methods on modern datasets, indicating the potential and importance of using higher-order information in synchronization.

</details>


### [51] [Multidimensional Task Learning: A Unified Tensor Framework for Computer Vision Tasks](https://arxiv.org/abs/2602.23217)
*Alaa El Ichi,Khalide Jbilou*

Main category: cs.CV

TL;DR: This paper introduces Multidimensional Task Learning (MTL), a unified tensor-based framework using Generalized Einstein MLPs that can express various computer vision tasks (classification, segmentation, detection) as special cases within a larger task space than matrix-based approaches allow.


<details>
  <summary>Details</summary>
Motivation: Current computer vision task formulations are constrained by matrix-based thinking that requires structural flattening, restricting the space of naturally expressible tasks. The authors aim to overcome this limitation by developing a more expressive mathematical framework.

Method: The paper proposes Multidimensional Task Learning (MTL) based on Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via the Einstein product. This allows tensor-valued parameters and explicit control over which dimensions are preserved or contracted without information loss.

Result: The authors demonstrate mathematically that classification, segmentation, and detection are special cases of MTL, differing only in their dimensional configuration. They prove the task space is strictly larger than what matrix-based formulations can express, enabling principled task configurations like spatiotemporal or cross-modal predictions.

Conclusion: This work provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through tensor algebra, offering a more expressive framework than conventional matrix-based approaches.

Abstract: This paper introduces Multidimensional Task Learning (MTL), a unified mathematical framework based on Generalized Einstein MLPs (GE-MLPs) that operate directly on tensors via the Einstein product. We argue that current computer vision task formulations are inherently constrained by matrix-based thinking: standard architectures rely on matrix-valued weights and vectorvalued biases, requiring structural flattening that restricts the space of naturally expressible tasks. GE-MLPs lift this constraint by operating with tensor-valued parameters, enabling explicit control over which dimensions are preserved or contracted without information loss. Through rigorous mathematical derivations, we demonstrate that classification, segmentation, and detection are special cases of MTL, differing only in their dimensional configuration within a formally defined task space. We further prove that this task space is strictly larger than what matrix-based formulations can natively express, enabling principled task configurations such as spatiotemporal or cross modal predictions that require destructive flattening under conventional approaches. This work provides a mathematical foundation for understanding, comparing, and designing computer vision tasks through the lens of tensor algebra.

</details>


<div id='astro-ph.HE'></div>

# astro-ph.HE [[Back]](#toc)

### [52] [A Lorentz-Covariant Spectral Universality of Stochastic Fields](https://arxiv.org/abs/2602.23195)
*Alexander G. Tevzadze*

Main category: astro-ph.HE

TL;DR: Lorentz-covariant spectral universality: temporal power spectrum index is symmetry-protected and offset from spatial index by geometric factor in Minkowski spacetime.


<details>
  <summary>Details</summary>
Motivation: To establish a Lorentz-covariant framework for understanding spectral relationships in relativistic stochastic fields, addressing limitations of non-covariant approaches.

Method: Derivation of Lorentz-covariant spectral universality for stationary stochastic fields in Minkowski spacetime, analyzing constraints on covariant local mappings between temporal and spatial power spectra.

Result: No covariant local mapping can relate temporal and spatial power spectra in >1 spatial dimension. For Lorentz homogeneous spectra, temporal index is symmetry-protected, observer invariant, and offset from spatial index by universal geometric factor determined by effective momentum space dimensionality.

Conclusion: Spectral universality breaks down for anisotropic scaling and dispersion-dominated spectra, establishing necessity of Lorentz-covariant formulation for relativistic spectral inference.

Abstract: We derive a Lorentz-covariant spectral universality for stationary stochastic fields in Minkowski spacetime. We show that no covariant local mapping can relate temporal and spatial power spectra in more than one spatial dimension. For Lorentz homogeneous spectra, the temporal index is symmetry protected, observer invariant, and offset from the spatial index by a universal geometric factor set by effective momentum space dimensionality. We show how spectral universality breaks down for anisotropic scaling and dispersion dominated spectra, establishing the necessity of a Lorentz-covariant formulation of relativistic spectral inference.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [53] [First-principles and tight-binding analysis of thermoelectricity in irradiated WSe$_2$](https://arxiv.org/abs/2602.22789)
*Cynthia Ihuoma Osuala,Tanu Choudhary,Raju K. Biswas,Sudin Ganguly,Santanu K. Maiti*

Main category: cond-mat.mes-hall

TL;DR: Light irradiation modifies electronic transport in WSe2 nanoribbons via Floquet engineering, enhancing thermoelectric performance with ZT > 1 over broad temperature range.


<details>
  <summary>Details</summary>
Motivation: To investigate how monochromatic light irradiation can enhance thermoelectric properties in zigzag monolayer WSe2 nanoribbons by modifying electronic transport through Floquet engineering while leveraging spin-orbit coupling effects.

Method: Combined approach: (1) Six-orbital tight-binding with atomic spin-orbit coupling for electronic structure, (2) Peierls substitution for periodic driving, (3) Floquet Hamiltonian in high-frequency limit, (4) Landauer-Büttiker formalism for coherent transport, (5) DFT perturbation theory with phonon Boltzmann equation for lattice thermal conductivity.

Result: Light-induced hopping renormalization reshapes band dispersion and transmission near Fermi level, modifying electrical/thermal conductances and Seebeck coefficient. Combined with spin-orbit band splitting and reduced lattice thermal conductivity, achieves thermoelectric figure of merit ZT > 1 over broad temperature range.

Conclusion: Monochromatic irradiation enables significant enhancement of thermoelectric performance in WSe2 nanoribbons through Floquet engineering of electronic transport and suppression of lattice thermal conductivity, achieving ZT values exceeding unity.

Abstract: Electronic and thermoelectric transport in zigzag monolayer WSe$_2$ nanoribbons are studied under monochromatic irradiation. The electronic structure is described within a six-orbital tight-binding framework constructed from the relevant tungsten and selenium orbitals, with atomic spin-orbit coupling included explicitly. Periodic driving is incorporated via the Peierls substitution, and in the high-frequency limit the system is mapped onto an effective static Floquet Hamiltonian with polarization-dependent renormalized hoppings. Coherent transport is evaluated using wave-function matching within the Landauer-Büttiker formalism. The lattice thermal conductivity is obtained independently from density functional perturbation theory combined with an iterative solution of the phonon Boltzmann transport equation. Light-induced hopping renormalization reshapes the band dispersion and transmission spectrum near the Fermi level, modifying the Landauer transport integrals that determine electrical and thermal conductances and the Seebeck coefficient. Together with spin-orbit-driven band splitting and reduced lattice thermal conductivity from enhanced anharmonic scattering, this leads to a thermoelectric figure of merit $ZT$ exceeding unity over a broad temperature range.

</details>


<div id='cs.MS'></div>

# cs.MS [[Back]](#toc)

### [54] [TorchLean: Formalizing Neural Networks in Lean](https://arxiv.org/abs/2602.22631)
*Robert Joseph George,Jennifer Cruden,Xiangru Zhong,Huan Zhang,Anima Anandkumar*

Main category: cs.MS

TL;DR: TorchLean is a Lean 4 framework that provides unified semantics for neural network execution and verification, bridging the gap between programming environments and formal analysis.


<details>
  <summary>Details</summary>
Motivation: Neural networks are used in critical applications, but verification results are often produced outside the execution environment, creating semantic gaps that undermine guarantees due to implicit conventions about operator semantics, tensor layouts, preprocessing, and floating-point behavior.

Method: TorchLean integrates: (1) PyTorch-style verified API with eager/compiled modes lowering to shared SSA/DAG IR, (2) explicit Float32 semantics via executable IEEE-754 binary32 kernel and proof-relevant rounding models, (3) verification via IBP and CROWN/LiRPA-style bound propagation with certificate checking.

Result: Validated on certified robustness, physics-informed residual bounds for PINNs, Lyapunov-style neural controller verification, and mechanized theoretical results including universal approximation theorem.

Conclusion: TorchLean demonstrates a semantics-first infrastructure for fully formal, end-to-end verification of learning-enabled systems by treating models as first-class mathematical objects with precise shared semantics.

Abstract: Neural networks are increasingly deployed in safety- and mission-critical pipelines, yet many verification and analysis results are produced outside the programming environment that defines and runs the model. This separation creates a semantic gap between the executed network and the analyzed artifact, so guarantees can hinge on implicit conventions such as operator semantics, tensor layouts, preprocessing, and floating-point corner cases. We introduce TorchLean, a framework in the Lean 4 theorem prover that treats learned models as first-class mathematical objects with a single, precise semantics shared by execution and verification. TorchLean unifies (1) a PyTorch-style verified API with eager and compiled modes that lower to a shared op-tagged SSA/DAG computation-graph IR, (2) explicit Float32 semantics via an executable IEEE-754 binary32 kernel and proof-relevant rounding models, and (3) verification via IBP and CROWN/LiRPA-style bound propagation with certificate checking. We validate TorchLean end-to-end on certified robustness, physics-informed residual bounds for PINNs, and Lyapunov-style neural controller verification, alongside mechanized theoretical results including a universal approximation theorem. These results demonstrate a semantics-first infrastructure for fully formal, end-to-end verification of learning-enabled systems.

</details>
